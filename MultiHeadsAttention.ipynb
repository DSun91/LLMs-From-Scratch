{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b3f3e9",
   "metadata": {},
   "source": [
    "# Multi-Head Attention from Scratch Using CuPy\n",
    "\n",
    "In this notebook, we will implement the **Multi-Head Attention** mechanism from scratch using **CuPy**, a GPU-accelerated library similar to NumPy. The multi-head attention mechanism is a key component of the Transformer model, enabling it to attend to different parts of the input simultaneously.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview of Multi-Head Attention\n",
    "\n",
    "Multi-head attention allows the model to have multiple attention \"heads,\" each of which focuses on different parts of the input sequence. Each head computes its own attention values, and the results are concatenated and transformed into the final output.\n",
    "\n",
    "The steps involved in multi-head attention:\n",
    "- **Linear transformations**: Apply learned weight matrices to the queries (Q), keys (K), and values (V).\n",
    "- **Scaled Dot-Product Attention**: For each head, compute the attention scores and apply them to the values.\n",
    "- **Concatenation**: Concatenate the outputs from all heads.\n",
    "- **Final Linear Transformation**: Apply a final linear transformation to the concatenated output.\n",
    "\n",
    "Mathematically, the output of the multi-head attention mechanism can be written as:\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h)W^O\n",
    "$$\n",
    "where each attention head is computed as:\n",
    "\n",
    "$$\n",
    "\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "$$\n",
    "---\n",
    "\n",
    "## 2. CuPy Setup\n",
    "\n",
    "Before we begin, make sure you have **CuPy** installed. You can install it via:\n",
    "\n",
    "```bash\n",
    "!pip install cupy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db372a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 7, 10), (10, 8), (10, 8), (10, 8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import re\n",
    "import cupy as cp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np \n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x)) \n",
    "def softmax(x, axis=-1):\n",
    "    # Subtract the max value for numerical stability\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "num_classes=2\n",
    "word2vec_len = 10\n",
    "num_phrases = 3\n",
    "words_per_phrase = 7 \n",
    "dk = dv = 8\n",
    " \n",
    "num_heads=4\n",
    " \n",
    " \n",
    "inputs = np.random.rand(num_phrases,words_per_phrase, word2vec_len)\n",
    "target = softmax(np.random.rand(num_phrases,num_classes))\n",
    "\n",
    "Q = np.random.rand(word2vec_len, dk) / jnp.sqrt(word2vec_len)\n",
    "K = np.random.rand(word2vec_len, dk) / jnp.sqrt(word2vec_len)\n",
    "V = np.random.rand(word2vec_len, dv) / jnp.sqrt(word2vec_len)\n",
    "inputs.shape,Q.shape,K.shape,V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26957032",
   "metadata": {},
   "source": [
    "### Consideriamo input formato da 3 frasi composte da 7 parole ciasuna ed ogni parola avente rappresentazione vettoriale di dimensione 10. Mentre vogliamo dopo l'attentione che ogni parola abbia rappresentazione vettoriale di 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dd2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.242, 0.61, 0.0936, 0.483, 0.58, 0.00754, 0.831, 0.137, 0.233, 0.108],\n",
       "        [0.513, 0.817, 0.873, 0.995, 0.745, 0.264, 0.188, 0.815, 0.471, 0.299],\n",
       "        [0.86, 0.0837, 0.148, 0.718, 0.237, 0.302, 0.0181, 0.676, 0.218, 0.335],\n",
       "        [0.459, 0.45, 0.872, 0.321, 0.0168, 0.722, 0.212, 0.253, 0.361, 0.975],\n",
       "        [0.794, 0.717, 0.111, 0.188, 0.639, 0.325, 0.614, 0.125, 0.604, 0.279],\n",
       "        [0.308, 0.828, 0.988, 0.188, 0.773, 0.489, 0.11, 0.477, 0.142, 0.534],\n",
       "        [0.357, 0.0608, 0.438, 0.429, 0.543, 0.907, 0.356, 0.313, 0.3, 0.193]],\n",
       "\n",
       "       [[0.468, 0.332, 0.491, 0.848, 0.0648, 0.44, 0.86, 0.551, 0.621, 0.751],\n",
       "        [0.711, 0.899, 0.689, 0.779, 0.106, 0.275, 0.0318, 0.161, 0.0841, 0.708],\n",
       "        [0.86, 0.581, 0.934, 0.558, 0.138, 0.312, 0.54, 0.751, 0.0094, 0.316],\n",
       "        [0.359, 0.0142, 0.826, 0.763, 0.45, 0.452, 0.509, 0.864, 0.974, 0.738],\n",
       "        [0.192, 0.369, 0.948, 0.0747, 0.749, 0.342, 0.826, 0.925, 0.216, 0.693],\n",
       "        [0.196, 0.668, 0.241, 0.492, 0.477, 0.63, 0.0317, 0.383, 0.538, 0.209],\n",
       "        [0.283, 0.442, 0.79, 0.38, 0.107, 0.00117, 0.971, 0.818, 0.266, 0.693]],\n",
       "\n",
       "       [[0.687, 0.0709, 0.557, 0.231, 0.201, 0.177, 0.125, 0.505, 0.987, 0.349],\n",
       "        [0.145, 0.987, 0.856, 0.906, 0.357, 0.369, 0.211, 0.527, 0.684, 0.717],\n",
       "        [0.642, 0.209, 0.751, 0.822, 0.296, 0.557, 0.821, 0.881, 0.285, 0.702],\n",
       "        [0.0616, 0.493, 0.978, 0.342, 0.97, 0.399, 0.72, 0.978, 0.298, 0.817],\n",
       "        [0.597, 0.722, 0.766, 0.4, 0.51, 0.437, 0.29, 0.72, 0.463, 0.379],\n",
       "        [0.47, 0.198, 0.752, 0.112, 0.312, 0.592, 0.51, 0.956, 0.773, 0.572],\n",
       "        [0.175, 0.245, 0.597, 0.432, 0.63, 0.479, 0.64, 0.945, 0.419, 0.323]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs# each input phrase is made by 13 words having lenght 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de56657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 7, 10), (10, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape,Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed92a667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.387, 0.723, 0.607, 0.492, 0.419, 0.662, 0.492, 0.675],\n",
       "        [0.797, 1.46, 1.05, 0.935, 0.61, 1.01, 0.928, 1.15],\n",
       "        [0.619, 0.877, 0.587, 0.517, 0.513, 0.61, 0.471, 0.626],\n",
       "        [0.591, 0.983, 0.844, 0.96, 0.566, 0.508, 0.675, 0.806],\n",
       "        [0.569, 0.97, 0.749, 0.693, 0.678, 0.715, 0.607, 0.812],\n",
       "        [0.53, 1.11, 0.899, 0.891, 0.411, 0.678, 0.64, 0.914],\n",
       "        [0.422, 0.727, 0.613, 0.641, 0.523, 0.512, 0.59, 0.71]],\n",
       "\n",
       "       [[0.697, 1.15, 0.97, 0.961, 0.749, 0.852, 0.828, 1.01],\n",
       "        [0.731, 1.09, 0.815, 0.806, 0.493, 0.621, 0.704, 0.764],\n",
       "        [0.671, 1.13, 0.907, 0.9, 0.52, 0.777, 0.664, 0.812],\n",
       "        [0.723, 1.33, 1, 1.03, 0.782, 0.899, 0.855, 1.16],\n",
       "        [0.481, 1.14, 1.02, 1.01, 0.496, 0.859, 0.56, 1.04],\n",
       "        [0.444, 0.862, 0.674, 0.597, 0.466, 0.595, 0.693, 0.773],\n",
       "        [0.517, 1.06, 0.943, 0.919, 0.485, 0.816, 0.576, 0.89]],\n",
       "\n",
       "       [[0.546, 0.939, 0.605, 0.666, 0.617, 0.542, 0.548, 0.694],\n",
       "        [0.723, 1.37, 1.06, 1.01, 0.604, 0.881, 0.994, 1.14],\n",
       "        [0.75, 1.27, 1.06, 1.05, 0.723, 0.941, 0.792, 1.08],\n",
       "        [0.58, 1.33, 1.15, 1.09, 0.552, 0.992, 0.708, 1.24],\n",
       "        [0.639, 1.22, 0.947, 0.907, 0.582, 0.817, 0.75, 0.969],\n",
       "        [0.539, 1.13, 0.933, 0.967, 0.659, 0.764, 0.676, 0.972],\n",
       "        [0.47, 1.04, 0.882, 0.814, 0.522, 0.832, 0.647, 0.969]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.matmul(inputs, Q) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fedbac",
   "metadata": {},
   "source": [
    "### Avendo fissato il numero di teste per il attezione ogni matrice Qval, Kval, Vval viene suddivisa in 4 parti uguali di 2 colonne. Otteniamo un array di 4 elementi che per ogni frase riportano le prime due colonne come di seguito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef75667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jnp.array_split(jnp.matmul(inputs, Q),num_heads,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76673db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.387, 0.723],\n",
       "        [0.797, 1.46],\n",
       "        [0.619, 0.877],\n",
       "        [0.591, 0.983],\n",
       "        [0.569, 0.97],\n",
       "        [0.53, 1.11],\n",
       "        [0.422, 0.727]],\n",
       "\n",
       "       [[0.697, 1.15],\n",
       "        [0.731, 1.09],\n",
       "        [0.671, 1.13],\n",
       "        [0.723, 1.33],\n",
       "        [0.481, 1.14],\n",
       "        [0.444, 0.862],\n",
       "        [0.517, 1.06]],\n",
       "\n",
       "       [[0.546, 0.939],\n",
       "        [0.723, 1.37],\n",
       "        [0.75, 1.27],\n",
       "        [0.58, 1.33],\n",
       "        [0.639, 1.22],\n",
       "        [0.539, 1.13],\n",
       "        [0.47, 1.04]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array_split(jnp.matmul(inputs, Q),num_heads,axis=2)[0]# so i have basically num_heads chuncks of the Qval this is a list not array structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b35421",
   "metadata": {},
   "source": [
    "### Ridimensioniamo l'array in modo che ogni frase contenga la lista dei rispettivi attention heads, ottenendo 3 frasi contententi 4 attention heads che hanno dimensione 7 (come il numero di parole per ogni frase) per 2 (fetta di embedding assegnata ad ogni head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34aa11cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 7, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.swapaxes(jnp.array(jnp.array_split(jnp.matmul(inputs, Q),num_heads,axis=2)), 0, 1).shape#  # here i actually transform it to a structure Qval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7464e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.387, 0.723],\n",
       "        [0.797, 1.46],\n",
       "        [0.619, 0.877],\n",
       "        [0.591, 0.983],\n",
       "        [0.569, 0.97],\n",
       "        [0.53, 1.11],\n",
       "        [0.422, 0.727]],\n",
       "\n",
       "       [[0.607, 0.492],\n",
       "        [1.05, 0.935],\n",
       "        [0.587, 0.517],\n",
       "        [0.844, 0.96],\n",
       "        [0.749, 0.693],\n",
       "        [0.899, 0.891],\n",
       "        [0.613, 0.641]],\n",
       "\n",
       "       [[0.419, 0.662],\n",
       "        [0.61, 1.01],\n",
       "        [0.513, 0.61],\n",
       "        [0.566, 0.508],\n",
       "        [0.678, 0.715],\n",
       "        [0.411, 0.678],\n",
       "        [0.523, 0.512]],\n",
       "\n",
       "       [[0.492, 0.675],\n",
       "        [0.928, 1.15],\n",
       "        [0.471, 0.626],\n",
       "        [0.675, 0.806],\n",
       "        [0.607, 0.812],\n",
       "        [0.64, 0.914],\n",
       "        [0.59, 0.71]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.swapaxes(jnp.array(jnp.array_split(jnp.matmul(inputs, Q),num_heads,axis=2)), 0, 1)[0]# refer to cell jnp.matmul(inputs, Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60adc1fc-9393-47c0-a181-ed799c4d3b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qval.shape:  (3, 4, 7, 2)\n",
      "Kval.shape:  (3, 4, 7, 2)\n",
      "Vval.shape:  (3, 4, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "Qval = jnp.swapaxes(jnp.array(jnp.array_split(jnp.matmul(inputs, Q),num_heads,axis=2)), 0, 1)\n",
    "print(\"Qval.shape: \",Qval.shape)\n",
    "\n",
    "Kval = jnp.swapaxes(jnp.array(jnp.array_split(jnp.matmul(inputs, K),num_heads,axis=2)), 0, 1)\n",
    "print(\"Kval.shape: \",Kval.shape)\n",
    "\n",
    "\n",
    "Vval = jnp.swapaxes(jnp.array(jnp.array_split(jnp.matmul(inputs,V),num_heads,axis=2)), 0, 1)\n",
    "print(\"Vval.shape: \",Vval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b98a1d",
   "metadata": {},
   "source": [
    "### Per calcolare ora i pesi dell'attenzione applichiamo la formua \n",
    "\n",
    "$$\n",
    "  \\frac{QK^T}{\\sqrt{d_k}}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c38c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.387, 0.723],\n",
       "        [0.797, 1.46],\n",
       "        [0.619, 0.877],\n",
       "        [0.591, 0.983],\n",
       "        [0.569, 0.97],\n",
       "        [0.53, 1.11],\n",
       "        [0.422, 0.727]], dtype=float32),\n",
       " Array([[0.463, 0.444],\n",
       "        [0.526, 0.699],\n",
       "        [0.321, 0.359],\n",
       "        [0.409, 0.725],\n",
       "        [0.514, 0.61],\n",
       "        [0.395, 0.663],\n",
       "        [0.49, 0.448]], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval[0][0],Kval[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02d8827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.387, 0.723],\n",
       "        [0.797, 1.46],\n",
       "        [0.619, 0.877],\n",
       "        [0.591, 0.983],\n",
       "        [0.569, 0.97],\n",
       "        [0.53, 1.11],\n",
       "        [0.422, 0.727]], dtype=float32),\n",
       " Array([[0.463, 0.526, 0.321, 0.409, 0.514, 0.395, 0.49],\n",
       "        [0.444, 0.699, 0.359, 0.725, 0.61, 0.663, 0.448]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval[0][0],np.transpose(Kval, (0, 1, 3, 2))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bbb725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.177, 0.25, 0.135, 0.241, 0.226, 0.223, 0.182],\n",
       "       [0.36, 0.509, 0.275, 0.49, 0.46, 0.453, 0.37],\n",
       "       [0.239, 0.332, 0.181, 0.314, 0.302, 0.292, 0.246],\n",
       "       [0.251, 0.353, 0.192, 0.337, 0.32, 0.313, 0.258],\n",
       "       [0.246, 0.345, 0.187, 0.331, 0.313, 0.307, 0.252],\n",
       "       [0.261, 0.373, 0.201, 0.361, 0.336, 0.334, 0.268],\n",
       "       [0.183, 0.258, 0.14, 0.247, 0.234, 0.229, 0.188]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval[0][0]@jnp.transpose(Kval, (0, 1, 3, 2))[0][0]/ jnp.sqrt(dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35bec325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 7, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QKscaled = jnp.matmul(Qval, jnp.transpose(Kval, (0, 1, 3, 2))) / jnp.sqrt(dk)\n",
    " \n",
    "QKscaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f39e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.177, 0.25, 0.135, 0.241, 0.226, 0.223, 0.182],\n",
       "       [0.36, 0.509, 0.275, 0.49, 0.46, 0.453, 0.37],\n",
       "       [0.239, 0.332, 0.181, 0.314, 0.302, 0.292, 0.246],\n",
       "       [0.251, 0.353, 0.192, 0.337, 0.32, 0.313, 0.258],\n",
       "       [0.246, 0.345, 0.187, 0.331, 0.313, 0.307, 0.252],\n",
       "       [0.261, 0.373, 0.201, 0.361, 0.336, 0.334, 0.268],\n",
       "       [0.183, 0.258, 0.14, 0.247, 0.234, 0.229, 0.188]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QKscaled[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d505c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_weights shape: (3, 4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "Attention_weights = softmax(QKscaled)\n",
    "print(\"Attention_weights shape:\",Attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a8b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention shape: (3, 4, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "Attention = jnp.matmul(Attention_weights, Vval)\n",
    "print(\"Attention shape:\",Attention.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec19e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0.704, 0.542],\n",
       "        [0.708, 0.546],\n",
       "        [0.705, 0.543],\n",
       "        [0.706, 0.544],\n",
       "        [0.706, 0.543],\n",
       "        [0.706, 0.544],\n",
       "        [0.704, 0.542]],\n",
       "\n",
       "       [[0.635, 0.631],\n",
       "        [0.638, 0.633],\n",
       "        [0.635, 0.631],\n",
       "        [0.637, 0.633],\n",
       "        [0.636, 0.632],\n",
       "        [0.637, 0.633],\n",
       "        [0.635, 0.631]],\n",
       "\n",
       "       [[0.495, 0.587],\n",
       "        [0.496, 0.588],\n",
       "        [0.496, 0.587],\n",
       "        [0.496, 0.586],\n",
       "        [0.496, 0.587],\n",
       "        [0.495, 0.587],\n",
       "        [0.496, 0.586]],\n",
       "\n",
       "       [[0.923, 0.805],\n",
       "        [0.93, 0.811],\n",
       "        [0.923, 0.805],\n",
       "        [0.926, 0.807],\n",
       "        [0.925, 0.807],\n",
       "        [0.926, 0.807],\n",
       "        [0.924, 0.806]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10742435",
   "metadata": {},
   "source": [
    "### Now for tetrieving the attention correct size we need to horizontaly concatenate the attention output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3a9217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[[0.704, 0.542, 0.635, 0.631, 0.495, 0.587, 0.923, 0.805],\n",
       "         [0.708, 0.546, 0.638, 0.633, 0.496, 0.588, 0.93, 0.811],\n",
       "         [0.705, 0.543, 0.635, 0.631, 0.496, 0.587, 0.923, 0.805],\n",
       "         [0.706, 0.544, 0.637, 0.633, 0.496, 0.586, 0.926, 0.807],\n",
       "         [0.706, 0.543, 0.636, 0.632, 0.496, 0.587, 0.925, 0.807],\n",
       "         [0.706, 0.544, 0.637, 0.633, 0.495, 0.587, 0.926, 0.807],\n",
       "         [0.704, 0.542, 0.635, 0.631, 0.496, 0.586, 0.924, 0.806]],\n",
       " \n",
       "        [[0.662, 0.601, 0.754, 0.701, 0.596, 0.711, 0.995, 0.993],\n",
       "         [0.662, 0.601, 0.754, 0.7, 0.595, 0.709, 0.993, 0.992],\n",
       "         [0.662, 0.601, 0.754, 0.701, 0.595, 0.709, 0.993, 0.992],\n",
       "         [0.662, 0.602, 0.755, 0.701, 0.596, 0.711, 0.996, 0.994],\n",
       "         [0.662, 0.601, 0.755, 0.701, 0.595, 0.709, 0.994, 0.992],\n",
       "         [0.662, 0.601, 0.753, 0.699, 0.594, 0.708, 0.993, 0.992],\n",
       "         [0.662, 0.601, 0.754, 0.701, 0.595, 0.709, 0.993, 0.992]],\n",
       " \n",
       "        [[0.716, 0.608, 0.795, 0.739, 0.604, 0.767, 1.11, 1.05],\n",
       "         [0.719, 0.61, 0.797, 0.741, 0.606, 0.767, 1.11, 1.05],\n",
       "         [0.718, 0.61, 0.797, 0.741, 0.606, 0.767, 1.11, 1.05],\n",
       "         [0.718, 0.61, 0.798, 0.741, 0.606, 0.767, 1.11, 1.05],\n",
       "         [0.718, 0.609, 0.797, 0.74, 0.605, 0.767, 1.11, 1.05],\n",
       "         [0.717, 0.609, 0.797, 0.74, 0.605, 0.767, 1.11, 1.05],\n",
       "         [0.717, 0.608, 0.796, 0.74, 0.605, 0.767, 1.11, 1.05]]], dtype=float32),\n",
       " (3, 7, 8),\n",
       " (3, 7, 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention=jnp.array([jnp.concatenate(Attention[i], axis=1) for i in range(num_phrases)])\n",
    "Attention,Attention.shape,inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb48e5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 8, 10), (3, 1, 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearlayer= np.random.rand(num_phrases,dv, word2vec_len)   \n",
    "linear_bias = np.random.rand(num_phrases,1,word2vec_len)\n",
    "linearlayer.shape,linear_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd1665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0534, 0.914, 0.0156, 0.0563, 0.231, 0.763, 0.809, 0.433, 0.738, 0.0148]],\n",
       "\n",
       "       [[0.515, 0.061, 0.161, 0.653, 0.316, 0.501, 0.258, 0.104, 0.198, 0.202]],\n",
       "\n",
       "       [[0.509, 0.00268, 0.58, 0.877, 0.722, 0.909, 0.227, 0.618, 0.321, 0.256]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bebf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.882, 1.06, 0.305, -0.368, 0.975, 0.0722, 1.13, 0.213, -0.137, -2.36],\n",
       "        [-0.864, 0.966, 1, -0.0286, 0.832, 0.0598, -0.119, 0.774, -0.18, -2.44],\n",
       "        [-0.0908, 0.388, 0.448, -0.106, 0.609, 0.574, -0.0363, 1.2, -0.256, -2.73],\n",
       "        [-1.01, 0.871, 1.58, -1.02, 0.029, 1.16, 0.128, 0.254, -0.192, -1.79],\n",
       "        [-0.29, 1.13, 0.197, -0.985, 0.974, 0.387, 0.729, 0.0538, 0.24, -2.44],\n",
       "        [-0.96, 1.11, 1.28, -0.945, 0.995, 0.507, -0.0687, 0.455, -0.455, -1.91],\n",
       "        [-0.828, 0.233, 0.722, -0.537, 0.871, 1.27, 0.409, 0.388, -0.129, -2.4]],\n",
       "\n",
       "       [[1.73, -0.218, 0.687, 0.515, -0.446, 1.12, -1.22, -0.772, 0.227, -1.62],\n",
       "        [1.7, 0.527, 0.842, 0.429, -0.2, 0.802, -1.71, -0.904, -0.283, -1.2],\n",
       "        [1.83, 0.139, 1.06, 0.143, -0.229, 0.799, -1.26, -0.351, -0.428, -1.7],\n",
       "        [1.39, -0.659, 0.983, 0.303, 0.00278, 0.985, -1.63, -0.386, 0.582, -1.57],\n",
       "        [1.39, -0.157, 1.33, -0.525, 0.497, 1.02, -1.28, -0.257, -0.312, -1.71],\n",
       "        [1.26, 0.358, 0.448, 0.196, 0.258, 1.28, -1.71, -0.633, 0.262, -1.72],\n",
       "        [1.75, 0.0228, 1.32, -0.0293, -0.333, 0.697, -1.1, -0.357, -0.18, -1.79]],\n",
       "\n",
       "       [[1.7, -1.55, 0.161, -0.19, -0.16, -0.154, -1.79, 0.905, 0.572, 0.505],\n",
       "        [1.2, -1.01, 0.344, 0.386, -0.24, -0.187, -2.36, 0.921, 0.0887, 0.863],\n",
       "        [1.59, -1.79, 0.161, 0.222, -0.303, 0.0236, -1.42, 1.19, -0.394, 0.721],\n",
       "        [1.01, -1.61, 0.443, -0.357, 0.482, -0.178, -1.68, 1.4, -0.424, 0.913],\n",
       "        [1.69, -1.19, 0.267, -0.183, 0.0138, -0.036, -2.03, 1.13, -0.123, 0.454],\n",
       "        [1.43, -1.67, 0.236, -0.48, -0.199, 0.14, -1.63, 1.31, 0.229, 0.634],\n",
       "        [1.29, -1.77, 0.12, -0.102, 0.21, 0.0622, -1.63, 1.5, -0.131, 0.451]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_norm(x, epsilon=1e-6):\n",
    "    # Calculate the mean and variance\n",
    "        mean = jnp.mean(x, axis=-1, keepdims=True)\n",
    "        var = jnp.var(x, axis=-1, keepdims=True) \n",
    "        # Normalize the output\n",
    "        x_norm = (x - mean) / jnp.sqrt(var + epsilon) \n",
    "        return x_norm\n",
    "\n",
    "\n",
    "output_sublayer_one=layer_norm((Attention@linearlayer +linear_bias)+inputs)\n",
    "output_sublayer_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3963d5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 8, 10), (3, 1, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearlayer= np.random.rand(num_phrases,dv, word2vec_len)   \n",
    "linear_bias = np.random.rand(num_phrases,1,word2vec_len)\n",
    "linearlayer.shape,linear_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8392e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0541, 0.141, 0.0794, 0.126, 0.112, 0.109, 0.141, 0.057, 0.0887, 0.0922],\n",
       "        [0.054, 0.141, 0.0793, 0.126, 0.112, 0.109, 0.141, 0.0567, 0.0887, 0.0922],\n",
       "        [0.054, 0.141, 0.0794, 0.126, 0.112, 0.109, 0.141, 0.057, 0.0888, 0.0923],\n",
       "        [0.054, 0.141, 0.0793, 0.126, 0.112, 0.109, 0.141, 0.0568, 0.0887, 0.0922],\n",
       "        [0.054, 0.141, 0.0793, 0.126, 0.112, 0.109, 0.141, 0.0569, 0.0887, 0.0922],\n",
       "        [0.054, 0.141, 0.0793, 0.126, 0.112, 0.109, 0.141, 0.0568, 0.0887, 0.0922],\n",
       "        [0.0541, 0.141, 0.0794, 0.126, 0.112, 0.109, 0.141, 0.0569, 0.0887, 0.0921]],\n",
       "\n",
       "       [[0.0409, 0.0539, 0.0539, 0.226, 0.341, 0.0867, 0.042, 0.023, 0.0487, 0.0834],\n",
       "        [0.041, 0.054, 0.0539, 0.226, 0.341, 0.0867, 0.0421, 0.0231, 0.0487, 0.0834],\n",
       "        [0.041, 0.054, 0.0539, 0.226, 0.341, 0.0867, 0.0421, 0.023, 0.0487, 0.0834],\n",
       "        [0.0409, 0.0539, 0.0538, 0.226, 0.342, 0.0867, 0.042, 0.023, 0.0486, 0.0834],\n",
       "        [0.041, 0.054, 0.0539, 0.226, 0.341, 0.0867, 0.042, 0.023, 0.0487, 0.0834],\n",
       "        [0.041, 0.054, 0.0539, 0.226, 0.341, 0.0867, 0.0421, 0.0231, 0.0487, 0.0834],\n",
       "        [0.041, 0.054, 0.0539, 0.226, 0.341, 0.0867, 0.042, 0.023, 0.0487, 0.0834]],\n",
       "\n",
       "       [[0.0401, 0.317, 0.0545, 0.0327, 0.2, 0.0445, 0.0132, 0.0615, 0.0881, 0.148],\n",
       "        [0.04, 0.317, 0.0544, 0.0326, 0.201, 0.0444, 0.0132, 0.0614, 0.0881, 0.148],\n",
       "        [0.04, 0.317, 0.0544, 0.0326, 0.201, 0.0444, 0.0132, 0.0614, 0.0881, 0.148],\n",
       "        [0.04, 0.318, 0.0544, 0.0326, 0.201, 0.0444, 0.0132, 0.0614, 0.088, 0.148],\n",
       "        [0.04, 0.317, 0.0544, 0.0327, 0.201, 0.0444, 0.0132, 0.0615, 0.0881, 0.148],\n",
       "        [0.04, 0.317, 0.0544, 0.0327, 0.201, 0.0444, 0.0132, 0.0615, 0.0881, 0.148],\n",
       "        [0.04, 0.317, 0.0544, 0.0327, 0.2, 0.0444, 0.0132, 0.0615, 0.0881, 0.148]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma_Zout=softmax(Attention@linearlayer +linear_bias)\n",
    "Sigma_Zout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11b0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72607f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d2ff37d-f071-4d6d-811b-bf30eff4dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat Phrase Representation: (3, 8)\n",
      "Sigma_Zout:\n",
      " [[0.46 0.54]\n",
      " [0.439 0.561]\n",
      " [0.425 0.575]]\n",
      "target:\n",
      " [[0.58 0.42]\n",
      " [0.592 0.408]\n",
      " [0.419 0.581]]\n",
      "Cross-Entropy Loss:  0.7042346937821095\n"
     ]
    }
   ],
   "source": [
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#phrase_representation = np.mean(Attention, axis=2).reshape(num_phrases,dv)\n",
    "phrase_representation = np.mean(Attention, axis=1).reshape(num_phrases,dv)\n",
    "print(\"Concat Phrase Representation:\",phrase_representation.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "linearlayer= np.random.rand(dv, num_classes)   \n",
    "linear_bias = np.random.rand(num_classes)\n",
    "Sigma_Zout=softmax(np.matmul(phrase_representation, linearlayer) + linear_bias)\n",
    "print(\"Sigma_Zout:\\n\",Sigma_Zout)\n",
    "print(\"target:\\n\",target)\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "def cross_entropy_loss(predictions, target): \n",
    "    batch_loss = -np.sum(target * np.log(predictions + 1e-8), axis=1)\n",
    "    return np.mean(batch_loss) \n",
    " \n",
    "\n",
    "loss = cross_entropy_loss(Sigma_Zout, target)\n",
    "print(\"Cross-Entropy Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a54bdecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.761, 0.39])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0164eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.268, 0.268])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc405f96-fe61-48f5-ba8d-788e4694fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dLoss_dSigma_Zout =Sigma_Zout - np.stack(target)\n",
    "dLoss_dSigma_Zout\n",
    "\n",
    "# Gradient for linear layer and bias\n",
    "d_linear = np.dot(dLoss_dSigma_Zout.T, phrase_representation).T\n",
    "d_bias =  np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "d_linear,d_bias\n",
    "\n",
    "\n",
    "# Gradient for phrase representation\n",
    "d_phrase_rep = np.dot(dLoss_dSigma_Zout, linearlayer.T)\n",
    "d_phrase_rep.shape\n",
    "dL_dA = np.array([np.outer(np.ones(inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])  / inputs.shape[1]\n",
    "dL_dA = np.swapaxes(np.array(np.array_split(dL_dA,num_heads,axis=2)), 0, 1)\n",
    "dL_dA \n",
    "\n",
    "\n",
    "softmax_derivative = Attention_weights*(1 - Attention_weights)\n",
    "\n",
    "\n",
    "# Gradient for V\n",
    "d_Vval=np.matmul(np.transpose(dL_dA,(0,1,3,2)), Attention_weights) \n",
    "dLoss_dV = np.concatenate(np.mean(np.matmul(d_Vval,inputs.reshape(num_phrases, 1, words_per_phrase, inputs.shape[2])),axis=0),axis=0).T\n",
    "dLoss_dV\n",
    "\n",
    "# Gradient for Q\n",
    "dLoss_dQ=np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Kval@np.transpose(Vval,(0,1,3,2))@inputs.reshape(num_phrases, 1, words_per_phrase, inputs.shape[2])\n",
    "dLoss_dQ=np.concatenate(np.mean(dLoss_dQ,axis=0),axis=0).T\n",
    "dLoss_dQ.shape\n",
    "\n",
    "# Gradient for K\n",
    "dLoss_dK=np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Qval@np.transpose(Vval,(0,1,3,2))@inputs.reshape(num_phrases, 1, words_per_phrase, inputs.shape[2])\n",
    "dLoss_dK=np.concatenate(np.mean(dLoss_dK,axis=0),axis=0).T\n",
    "dLoss_dK.shape\n",
    "\n",
    "clip_value = 15.0\n",
    "dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "d_linear = np.clip(d_linear, -clip_value, clip_value)\n",
    "d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "learning_rate=0.001\n",
    "Q -= learning_rate * dLoss_dQ\n",
    "K -= learning_rate * dLoss_dK\n",
    "V -= learning_rate * dLoss_dV\n",
    "linearlayer -= learning_rate * d_linear\n",
    "linear_bias -= learning_rate * d_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d09480-1faf-49d0-8a9e-1f0a17c251fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72a51ee3-bc25-4b45-abad-e4ae9bcfcdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2360157-06e6-4854-8bee-c3593af53387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3bf41-ca57-4132-8cf6-0b8f45974e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fccc24-364a-4d05-9163-531ac64ed86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e7e03-a749-4d8a-b2cb-4bdf89eb3fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07885241-988d-4a5a-9a22-da5b8c361080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_derivative.shape:  (3, 4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "softmax_derivative = Attention_weights*(1 - Attention_weights)\n",
    "print(\"softmax_derivative.shape: \", softmax_derivative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5278948-1ae1-4a4a-9bad-02edced98006",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    " \\frac{Inputs \\cdot K_{val}^T}{\\sqrt{d_k}}\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23bbbee5-21de-460d-9b2a-685c337a0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape:  (3, 7, 10)\n",
      "Kval.shape:  (3, 4, 7, 2)\n",
      "Q.shape:  (10, 8) K.shape:  (10, 8)\n",
      "Vval.shape:  (3, 4, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs.shape: \", inputs.shape)\n",
    "print(\"Kval.shape: \", Kval.shape)\n",
    "print(\"Q.shape: \", Q.shape,\"K.shape: \",K.shape)\n",
    "print(\"Vval.shape: \", Vval.shape ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4e00e-29c8-49e3-a65d-bb680f9bf8d4",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    " K_{val}^T=(Inputs \\cdot K)^T = K^T \\cdot I^T\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c5bdd10-b2ad-448d-ae9d-1ce47957d644",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m I\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrepeat(inputs, \u001b[43mnum_head\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(num_phrases,num_head,words_per_phrase,word2vec_len)\n\u001b[0;32m      2\u001b[0m I\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_head' is not defined"
     ]
    }
   ],
   "source": [
    "I=np.repeat(inputs, num_head, axis=0).reshape(num_phrases,num_head,words_per_phrase,word2vec_len)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab7a77-f3e8-452f-b49a-986ab4c7cf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f7e99b3-0772-4c84-8582-4b990a8299f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dLoss_dQ\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mtranspose(dL_dA,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@softmax_derivative\u001b[39m\u001b[38;5;129m@Kval\u001b[39m,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(Vval,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@I\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(dk)\n\u001b[0;32m      2\u001b[0m dLoss_dQ\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mmean(dLoss_dQ,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'I' is not defined"
     ]
    }
   ],
   "source": [
    "dLoss_dQ=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Kval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dQ=np.transpose(np.mean(dLoss_dQ,axis=0),(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e79186b-3feb-432c-987d-9215c399bcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fead05db-c4b7-433f-a52f-0cb8d09cd1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2, 6, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(I,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70cb3eb0-eaac-4278-acda-bb1848fa420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2, 4, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Vval,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dab612f0-689a-44de-9d77-661850e4f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=np.repeat(inputs, num_head, axis=0).reshape(num_phrases,num_head,words_per_phrase,word2vec_len)\n",
    "\n",
    "dLoss_dQ=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Kval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dQ=np.transpose(np.mean(dLoss_dQ,axis=0),(0,2,1)) \n",
    "\n",
    "dLoss_dK=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Qval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dK=np.transpose(np.mean(dLoss_dK,axis=0),(0,2,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d8bed9f-2b1f-45b1-83cd-c720c538e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "learning_rate=0.001\n",
    "Q -= learning_rate * dLoss_dQ\n",
    "K -= learning_rate * dLoss_dK\n",
    "V -= learning_rate * dLoss_dV\n",
    "linearlayer -= learning_rate * d_linear\n",
    "linear_bias -= learning_rate * d_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e59af831-f34e-41a6-a788-0d8f771ec093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37a52d-62e9-4fb1-8126-7b73b592ad53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f6790c-9d32-4591-9fd8-33708a38f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e5820-f949-4289-a3bc-ec9824c6c555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2fee8-7d02-4b64-89f7-64b3d8e8e2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616864e-2fc7-406d-881e-3dd145f2adbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f372ba9c-0ab6-4038-906c-8bb243abcef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668, 70, 300), (557, 70, 300), (1668, 5), (557, 5))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe5c8a-5601-460d-8da2-d877085e12e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21771a30-40fd-42c7-97f3-cede7d50aecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f527ad40-8f13-4ab7-ad90-7e2877a149c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\python312\\\\lib\\\\site-packages')\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display \n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9fdeade-397e-44c9-85e5-d3d0f8a41105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668, 70, 300), (557, 70, 300), (1668, 5), (557, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/bbc-text.csv\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "with open('data/InputProcessed.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "y = np.array(pd.get_dummies(df[\"category\"], dtype=int))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a1f8f6-7866-4981-99e5-46cb2684c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1668, 70, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead565c-398f-4bcf-900f-7a23e8ebac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4eb9c-04df-4c83-a870-7791e895c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d73db-0422-471d-af36-20dd1fed44a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f916e46f-2964-47fc-9870-fb7a98d2bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVMultiHeadsAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, num_heads, batch_size, dk, dv, num_classes, validation_split=0.0,\n",
    "                 momentum_beta=0.9,\n",
    "                 rmsprop_beta=0.98,\n",
    "                 epsilon=0.00000001):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_heads = num_heads\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "        self.validation_split = validation_split\n",
    "        self.validation_scores = []\n",
    "        self.training_losses = []\n",
    "        self.MomQ = 0\n",
    "        self.MomK = 0\n",
    "        self.MomV = 0\n",
    "        self.MomLy = 0\n",
    "        self.MomB = 0\n",
    "        self.RMSPQ = 0\n",
    "        self.RMSPK = 0\n",
    "        self.RMSPV = 0\n",
    "        self.RMSPLy= 0\n",
    "        self.RMSPB = 0\n",
    "        self.momentum_beta=momentum_beta\n",
    "        self.rmsprop_beta=rmsprop_beta\n",
    "        self.epsilon=epsilon\n",
    "        self.iterations=0\n",
    "        \n",
    "\n",
    "        \n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.randn(self.word_len, self.dv) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.K = np.random.randn(self.word_len, self.dv) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.V = np.random.randn(self.word_len, self.dv) / np.sqrt(self.word_len)  # * 0.01\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dv, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        softmax_result = e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "        # print(\"Softmax result shape:\", softmax_result.shape)\n",
    "        return softmax_result\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        mean_loss = np.mean(batch_loss)\n",
    "        # print(\"Cross-entropy loss:\", mean_loss)\n",
    "        return mean_loss\n",
    "    def load_train_validation_splits(self, X_train, y_train):\n",
    "        X_train_validation = X_train[0:round(self.validation_split * len(X_train))]\n",
    "        y_train_validation = y_train[0:round(self.validation_split * len(y_train))]\n",
    "        X_train = X_train[round(self.validation_split * len(X_train)):]\n",
    "        y_train = y_train[round(self.validation_split * len(y_train)):]\n",
    "        return [X_train, X_train_validation, y_train, y_train_validation]\n",
    "\n",
    "    def pad_sequences(self, sequences, max_len):\n",
    "        padded_sequences = np.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "        for i, seq in enumerate(sequences):\n",
    "            length = min(seq.shape[0], max_len)\n",
    "            padded_sequences[i, :length] = seq[:length]\n",
    "        return padded_sequences\n",
    "\n",
    "    def training_validation(self, X_validation, y_validation, current_loss):\n",
    "        # Pad validation sequences\n",
    "        X_validation = self.pad_sequences(X_validation, self.words_per_phrase)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.predict(X_validation)\n",
    "\n",
    "        # Convert predictions to class labels\n",
    "        y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Convert one-hot encoded true labels to class labels\n",
    "        y_true = np.argmax(y_validation, axis=1)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        print(\"Validation F1 score: \", f1)\n",
    "\n",
    "        # Append current F1 score and loss\n",
    "        self.validation_scores.append(f1)\n",
    "        self.training_losses.append(current_loss)\n",
    "\n",
    "        # Create an Epoch column\n",
    "        epochs = list(range(1, len(self.validation_scores) + 1))\n",
    "\n",
    "        # Create DataFrame for plotting\n",
    "        data = pd.DataFrame({\n",
    "            'Epoch': epochs,\n",
    "            'F1 Score': self.validation_scores,\n",
    "            'Loss': self.training_losses\n",
    "        })\n",
    "\n",
    "        # Plot F1 score and Loss\n",
    "        self.image = plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # F1 score line plot\n",
    "        sns.lineplot(x='Epoch', y='F1 Score', data=data, label='F1 Score', marker='o')\n",
    "\n",
    "        # Loss line plot on the same axes\n",
    "        sns.lineplot(x='Epoch', y='Loss', data=data, label='Loss', marker='o')\n",
    "\n",
    "        # Set plot labels and title\n",
    "        plt.title('F1 Score and Loss over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score / Loss')\n",
    "\n",
    "        # Show legend and grid\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Load the image from BytesIO object into a PIL Image\n",
    "        self.image = Image.open(buf)\n",
    "\n",
    "        plt.close()\n",
    "        # Display the plot\n",
    "        # self.image.show()\n",
    "\n",
    "    \n",
    "    def MultiHeadsAttention(self, Inputs):\n",
    "        self.Qval = np.swapaxes(np.array_split(np.matmul(Inputs, self.Q),self.num_heads,axis=2), 0, 1)\n",
    "        self.Kval = np.swapaxes(np.array_split(np.matmul(Inputs, self.K),self.num_heads,axis=2), 0, 1)\n",
    "        self.Vval = np.swapaxes(np.array_split(np.matmul(Inputs, self.V),self.num_heads,axis=2), 0, 1)\n",
    "        # print(\"Qval shape:\", self.Qval.shape)\n",
    "        # print(\"Kval shape:\", self.Kval.shape)\n",
    "        # print(\"Vval shape:\", self.Vval.shape)\n",
    "\n",
    "        QKscaled = np.matmul(self.Qval, np.transpose(self.Kval, (0, 1, 3, 2))) / np.sqrt(self.dk)\n",
    "        # print(\"QKscaled shape:\", QKscaled.shape)\n",
    "\n",
    "        self.Attention_weights = self.softmax(QKscaled)\n",
    "        # print(\"Attention_weights shape:\", self.Attention_weights.shape)\n",
    "\n",
    "        Attention_output = np.matmul(self.Attention_weights, self.Vval)\n",
    "        # print(\"Attention output shape:\", Attention_output.shape)\n",
    "\n",
    "        return Attention_output\n",
    "\n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        # print(\"Linear layer output shape:\", output.shape)\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "\n",
    "        Attention = self.MultiHeadsAttention(Inputs)\n",
    "\n",
    "        #print(\"Attention shape:\", Attention.shape)\n",
    "        #print(\"Attention mean shape:\", np.mean(Attention, axis=2).shape)\n",
    "        self.phrase_representation = np.mean(Attention, axis=2).reshape(Inputs.shape[0],self.dv)\n",
    "        \n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "        # print(\"Sigma_Zout shape:\", Sigma_Zout.shape)\n",
    "\n",
    "        return Sigma_Zout\n",
    "\n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, Inputs):\n",
    "\n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(dLoss_dSigma_Zout.T, self.phrase_representation).T\n",
    "        # print(\"dlinear_dW shape:\", dlinear_dW.shape)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        # print(\"d_bias shape:\", d_bias.shape)\n",
    "\n",
    "        # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "        # print(\"d_phrase_rep shape:\", d_phrase_rep.shape)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array(\n",
    "            [np.outer(np.ones(Inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])]) / \\\n",
    "                Inputs.shape[1]\n",
    "        dL_dA = np.swapaxes(np.array(np.array_split(dL_dA, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"dL_dA shape:\", dL_dA.shape)\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval = np.matmul(np.transpose(dL_dA, (0, 1, 3, 2)), self.Attention_weights)\n",
    "        dLoss_dV = np.concatenate(np.mean(np.matmul(d_Vval,Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])),axis=0),axis=0).T\n",
    "        # print(\"dLoss_dV shape:\", dLoss_dV.shape)\n",
    "\n",
    "        # Gradient of softmax\n",
    "        dAttention_dSoftmax = self.Attention_weights * (1 - self.Attention_weights)\n",
    "        # print(\"dAttention_dSoftmax shape:\", dAttention_dSoftmax.shape)\n",
    "\n",
    "\n",
    "        # Compute dLoss_dQ\n",
    "        dLoss_dQ = np.transpose(dL_dA, (0, 1, 3, 2)) @ dAttention_dSoftmax @ self.Kval @ np.transpose(self.Vval, (\n",
    "        0, 1, 3, 2)) @ Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])\n",
    "        dLoss_dQ = np.concatenate(np.mean(dLoss_dQ, axis=0), axis=0).T\n",
    "        # print(\"dLoss_dQ shape:\", dLoss_dQ.shape)\n",
    "\n",
    "        # Gradient of K\n",
    "        dLoss_dK = np.transpose(dL_dA, (0, 1, 3, 2)) @ dAttention_dSoftmax @ self.Qval @ np.transpose(self.Vval, (\n",
    "            0, 1, 3, 2)) @ Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])\n",
    "        dLoss_dK = np.concatenate(np.mean(dLoss_dK, axis=0), axis=0).T\n",
    "        # print(\"dLoss_dK shape:\", dLoss_dK.shape)\n",
    "\n",
    "        # Gradient clipping\n",
    "        clip_value = 150.0\n",
    "        dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = np.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "\n",
    "        self.UpdateParams(dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias)\n",
    "\n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.iterations += 1\n",
    "           # Set a minimum learning rate to avoid it going too low\n",
    "        # Linear learning rate decay\n",
    "        \n",
    "        lr = self.learning_rate * (1 - self.iterations / self.total_iterations)\n",
    "        self.learning_rate = max(lr, 0.001)  # Prevent learning rate from becoming too small\n",
    "        \n",
    "        \n",
    "        # Update biased first moments (momentum)\n",
    "        self.MomQ = (self.momentum_beta * self.MomQ + (1 - self.momentum_beta) * dLoss_dQ)\n",
    "        self.MomK = (self.momentum_beta * self.MomK + (1 - self.momentum_beta) * dLoss_dK)\n",
    "        self.MomV = (self.momentum_beta * self.MomV + (1 - self.momentum_beta) * dLoss_dV)\n",
    "        self.MomLy = (self.momentum_beta * self.MomLy + (1 - self.momentum_beta) * dlinear_dW)\n",
    "        self.MomB = (self.momentum_beta * self.MomB + (1 - self.momentum_beta) * d_bias)\n",
    "    \n",
    "        # Update biased second moments (variance)\n",
    "        self.RMSPQ = (self.rmsprop_beta * self.RMSPQ + (1 - self.rmsprop_beta) * dLoss_dQ * dLoss_dQ)\n",
    "        self.RMSPK = (self.rmsprop_beta * self.RMSPK + (1 - self.rmsprop_beta) * dLoss_dK * dLoss_dK)\n",
    "        self.RMSPV = (self.rmsprop_beta * self.RMSPV + (1 - self.rmsprop_beta) * dLoss_dV * dLoss_dV)\n",
    "        self.RMSPLy = (self.rmsprop_beta * self.RMSPLy + (1 - self.rmsprop_beta) * dlinear_dW * dlinear_dW)\n",
    "        self.RMSPB = (self.rmsprop_beta * self.RMSPB + (1 - self.rmsprop_beta) * d_bias * d_bias)\n",
    "    \n",
    "        # Bias correction for first moments\n",
    "        MomQ_corrected = self.MomQ / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomK_corrected = self.MomK / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomV_corrected = self.MomV / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomLy_corrected = self.MomLy / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomB_corrected = self.MomB / (1 - self.momentum_beta ** self.iterations)\n",
    "    \n",
    "        # Bias correction for second moments\n",
    "        RMSPQ_corrected = self.RMSPQ / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPK_corrected = self.RMSPK / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPV_corrected = self.RMSPV / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPLy_corrected = self.RMSPLy / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPB_corrected = self.RMSPB / (1 - self.rmsprop_beta ** self.iterations)\n",
    "    \n",
    "        # Update parameters using bias-corrected moments\n",
    "        self.Q -= self.learning_rate * MomQ_corrected / (np.sqrt(RMSPQ_corrected) + self.epsilon)\n",
    "        self.K -= self.learning_rate * MomK_corrected / (np.sqrt(RMSPK_corrected) + self.epsilon)\n",
    "        self.V -= self.learning_rate * MomV_corrected / (np.sqrt(RMSPV_corrected) + self.epsilon)\n",
    "        self.linearlayer -= self.learning_rate * MomLy_corrected / (np.sqrt(RMSPLy_corrected) + self.epsilon)\n",
    "        self.linear_bias -= self.learning_rate * MomB_corrected / (np.sqrt(RMSPB_corrected) + self.epsilon)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        X_train = self.pad_sequences(X_train, self.words_per_phrase)\n",
    "\n",
    "        if self.validation_split > 0:\n",
    "            X_train, X_train_validation, y_train, y_train_validation = train_test_split(\n",
    "                X_train, y_train, test_size=self.validation_split, random_state=42)\n",
    "            print(\"Training starting:\")\n",
    "            print(\"X_train samples: \", X_train.shape[0])\n",
    "            print(\"X_train_validation samples\", X_train_validation.shape[0], \"\\n\")\n",
    "\n",
    "        \n",
    "        self.total_iterations = num_epochs*(len(X_train) // self.batch_size)\n",
    "        for epoch in range(num_epochs):\n",
    "            self.iterations=0\n",
    "            total_loss = 0\n",
    "\n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "\n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                \n",
    "                \n",
    "                \n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "                \n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                yi = self.forward(X_batch)\n",
    "\n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "\n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "\n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "\n",
    "                \n",
    "            \n",
    "            if self.validation_split > 0:\n",
    "                self.training_validation(X_train_validation, y_train_validation, Loss)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}, learning rate: {self.learning_rate}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.pad_sequences(X, self.words_per_phrase)\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dc61562-feda-429a-bc15-db2b31b73639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting:\n",
      "X_train samples:  1501\n",
      "X_train_validation samples 167 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|| 23/23 [00:08<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.827796045884579\n",
      "Epoch 1/10, Loss: 1.3080, learning rate: 0.002884903119896506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|| 23/23 [00:09<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9043912175648703\n",
      "Epoch 2/10, Loss: 0.4610, learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|| 23/23 [00:08<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.8864349998999885\n",
      "Epoch 3/10, Loss: 0.3722, learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|| 23/23 [00:08<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9102065717247307\n",
      "Epoch 4/10, Loss: 0.3311, learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|| 23/23 [00:08<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9221089846450888\n",
      "Epoch 5/10, Loss: 0.3048, learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|| 23/23 [00:08<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.8911004793416258\n",
      "Epoch 6/10, Loss: 0.2939, learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   9%|                                                                | 2/23 [00:01<00:10,  1.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#validation_split\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m QKVMultiHeadsAttentionClassifier(word_len, max_words_per_phrase,num_head, batch_size, dk, dv, num_classes,validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 308\u001b[0m, in \u001b[0;36mQKVMultiHeadsAttentionClassifier.train\u001b[1;34m(self, X_train, y_train, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m    304\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Loss\n\u001b[0;32m    306\u001b[0m     dLoss_dSigma_Zout \u001b[38;5;241m=\u001b[39m yi \u001b[38;5;241m-\u001b[39m y_batch\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBackPropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLoss_dSigma_Zout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_split \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_validation(X_train_validation, y_train_validation, Loss)\n",
      "Cell \u001b[1;32mIn[8], line 202\u001b[0m, in \u001b[0;36mQKVMultiHeadsAttentionClassifier.BackPropagation\u001b[1;34m(self, dLoss_dSigma_Zout, Inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m dAttention_dSoftmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAttention_weights \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAttention_weights)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# print(\"dAttention_dSoftmax shape:\", dAttention_dSoftmax.shape)\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Compute dLoss_dQ\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m dLoss_dQ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL_dA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m dAttention_dSoftmax \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mKval \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVval, (\n\u001b[0;32m    203\u001b[0m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m@\u001b[39m Inputs\u001b[38;5;241m.\u001b[39mreshape(Inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_per_phrase, Inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    204\u001b[0m dLoss_dQ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(np\u001b[38;5;241m.\u001b[39mmean(dLoss_dQ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# print(\"dLoss_dQ shape:\", dLoss_dQ.shape)\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Gradient of K\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:584\u001b[0m, in \u001b[0;36m_transpose_dispatcher\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m    Interchange two axes of an array.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m \n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswapaxes\u001b[39m\u001b[38;5;124m'\u001b[39m, axis1, axis2)\n\u001b[1;32m--> 584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transpose_dispatcher\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "word_len = 300\n",
    "max_words_per_phrase=100\n",
    "dk = 32\n",
    "dv = 32\n",
    "batch_size = 64\n",
    "num_classes = 5\n",
    "num_head=8\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#validation_split\n",
    "model = QKVMultiHeadsAttentionClassifier(word_len, max_words_per_phrase,num_head, batch_size, dk, dv, num_classes,validation_split=0.1)\n",
    "model.train(X_train, y_train, num_epochs=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80e04cd-5c4b-4dda-87cf-69b2f97d95e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting:\n",
      "X_train samples:  1501\n",
      "X_train_validation samples 167 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|| 11/11 [00:02<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.6560568752962681\n",
      "Epoch 1/30, Loss: 12.3813, learning rate: 0.7234459346666596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|| 11/11 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.8518788095169474\n",
      "Epoch 2/30, Loss: 3.8153, learning rate: 0.654217525482146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|| 11/11 [00:01<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.915268179138575\n",
      "Epoch 3/30, Loss: 2.2904, learning rate: 0.5916137614971753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|| 11/11 [00:01<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9053079376188341\n",
      "Epoch 4/30, Loss: 1.6124, learning rate: 0.5350007133099778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|| 11/11 [00:01<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9201442919671335\n",
      "Epoch 5/30, Loss: 1.3595, learning rate: 0.4838051138598331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|| 11/11 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.8995031542988575\n",
      "Epoch 6/30, Loss: 1.1644, learning rate: 0.4375085534910458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|| 11/11 [00:01<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9187539683149747\n",
      "Epoch 7/30, Loss: 1.0545, learning rate: 0.39564223050623487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|| 11/11 [00:01<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.8990985392678249\n",
      "Epoch 8/30, Loss: 1.1950, learning rate: 0.3577822040527314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|| 11/11 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9148177373479189\n",
      "Epoch 9/30, Loss: 0.8390, learning rate: 0.32354510127253233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|| 11/11 [00:01<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9056676263789637\n",
      "Epoch 10/30, Loss: 0.9655, learning rate: 0.2925842352461577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|| 11/11 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9288767941720755\n",
      "Epoch 11/30, Loss: 0.4681, learning rate: 0.264586094420483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|| 11/11 [00:01<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9348191568449384\n",
      "Epoch 12/30, Loss: 0.3753, learning rate: 0.2392671679722843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|| 11/11 [00:01<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.922765163074019\n",
      "Epoch 13/30, Loss: 0.5204, learning rate: 0.21637107496094235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|| 11/11 [00:01<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9227325708573739\n",
      "Epoch 14/30, Loss: 0.4293, learning rate: 0.19566596819993604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|| 11/11 [00:01<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9288732476567333\n",
      "Epoch 15/30, Loss: 0.3866, learning rate: 0.17694218655857452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|| 11/11 [00:01<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.928927599346761\n",
      "Epoch 16/30, Loss: 0.3415, learning rate: 0.16001013192103802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|| 11/11 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9404767586256192\n",
      "Epoch 17/30, Loss: 0.2375, learning rate: 0.1446983493046886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|| 11/11 [00:01<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9405925366342207\n",
      "Epoch 18/30, Loss: 0.2678, learning rate: 0.13085179069681657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|| 11/11 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9292409415411251\n",
      "Epoch 19/30, Loss: 0.3394, learning rate: 0.11833024502933073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|| 11/11 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9345121644921252\n",
      "Epoch 20/30, Loss: 0.2853, learning rate: 0.10700691839322377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|| 11/11 [00:01<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9352271907709234\n",
      "Epoch 21/30, Loss: 0.2075, learning rate: 0.09676715011598093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|| 11/11 [00:01<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9405565760995855\n",
      "Epoch 22/30, Loss: 0.1055, learning rate: 0.08750725170085596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|| 11/11 [00:01<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9345930898376406\n",
      "Epoch 23/30, Loss: 0.1177, learning rate: 0.0791334568710455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|| 11/11 [00:01<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.934804113480528\n",
      "Epoch 24/30, Loss: 0.0599, learning rate: 0.07156097208684666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|| 11/11 [00:01<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9287862271717989\n",
      "Epoch 25/30, Loss: 0.0599, learning rate: 0.06471311792127941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|| 11/11 [00:01<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9404965899675408\n",
      "Epoch 26/30, Loss: 0.0741, learning rate: 0.05852055259969218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|| 11/11 [00:01<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9288121232929948\n",
      "Epoch 27/30, Loss: 0.0304, learning rate: 0.052920569840867154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|| 11/11 [00:01<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9349314710034345\n",
      "Epoch 28/30, Loss: 0.0152, learning rate: 0.04785646388952297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|| 11/11 [00:01<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9349314710034345\n",
      "Epoch 29/30, Loss: 0.0157, learning rate: 0.04327695531049648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|| 11/11 [00:01<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score:  0.9409177202332328\n",
      "Epoch 30/30, Loss: 0.0005, learning rate: 0.03913567173016173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "\n",
    "class QKVMultiHeadsAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, num_heads, batch_size, dk, dv, num_classes, validation_split=0.0,\n",
    "                 momentum_beta=0.9,\n",
    "                 rmsprop_beta=0.98,\n",
    "                 epsilon=0.00000001):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_heads = num_heads\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "        self.validation_split = validation_split\n",
    "        self.validation_scores = []\n",
    "        self.training_losses = []\n",
    "        self.MomQ = 0\n",
    "        self.MomK = 0\n",
    "        self.MomV = 0\n",
    "        self.MomLy = 0\n",
    "        self.MomB = 0\n",
    "        self.RMSPQ = 0\n",
    "        self.RMSPK = 0\n",
    "        self.RMSPV = 0\n",
    "        self.RMSPLy = 0\n",
    "        self.RMSPB = 0\n",
    "        self.momentum_beta = momentum_beta\n",
    "        self.rmsprop_beta = rmsprop_beta\n",
    "        self.epsilon = epsilon\n",
    "        self.iterations = 0\n",
    "\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = cupy.random.randn(self.word_len, self.dv) / cupy.sqrt(self.word_len)  # * 0.01\n",
    "        self.K = cupy.random.randn(self.word_len, self.dv) / cupy.sqrt(self.word_len)  # * 0.01\n",
    "        self.V = cupy.random.randn(self.word_len, self.dv) / cupy.sqrt(self.word_len)  # * 0.01\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = cupy.random.randn(self.dv, self.num_classes) / cupy.sqrt(self.dk)\n",
    "        self.linear_bias = cupy.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = cupy.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = cupy.exp(x - cupy.max(x, axis=axis, keepdims=True))\n",
    "        softmax_result = e_x / cupy.sum(e_x, axis=axis, keepdims=True)\n",
    "        # print(\"Softmax result shape:\", softmax_result.shape)\n",
    "        return softmax_result\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -cupy.sum(target * cupy.log(predictions + 1e-9), axis=1)\n",
    "        mean_loss = cupy.mean(batch_loss)\n",
    "        # print(\"Cross-entropy loss:\", mean_loss)\n",
    "        return mean_loss\n",
    "\n",
    "    def load_train_validation_splits(self, X_train, y_train):\n",
    "        X_train_validation = X_train[0:round(self.validation_split * len(X_train))]\n",
    "        y_train_validation = y_train[0:round(self.validation_split * len(y_train))]\n",
    "        X_train = X_train[round(self.validation_split * len(X_train)):]\n",
    "        y_train = y_train[round(self.validation_split * len(y_train)):]\n",
    "        return [X_train, X_train_validation, y_train, y_train_validation]\n",
    "\n",
    "    def pad_sequences(self, sequences, max_len):\n",
    "        padded_sequences = cupy.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "        for i, seq in enumerate(sequences):\n",
    "            length = min(seq.shape[0], max_len)\n",
    "            padded_sequences[i, :length] = seq[:length]\n",
    "        return padded_sequences\n",
    "\n",
    "    def training_validation(self, X_validation, y_validation, current_loss):\n",
    "        # Pad validation sequences\n",
    "        X_validation = self.pad_sequences(X_validation, self.words_per_phrase)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.predict(X_validation)\n",
    "\n",
    "        # Convert predictions to class labels\n",
    "        y_pred = cupy.argmax(predictions, axis=1)\n",
    "\n",
    "        # Convert one-hot encoded true labels to class labels\n",
    "        y_true = cupy.argmax(y_validation, axis=1)\n",
    "\n",
    "        #print(\"y_true\",np.array(y_true.get()))\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_true.get(), y_pred.get(), average=\"weighted\")\n",
    "        print(\"Validation F1 score: \", f1)\n",
    "\n",
    "        # Append current F1 score and loss\n",
    "        self.validation_scores.append(float(f1))\n",
    "        self.training_losses.append(float(current_loss))\n",
    "\n",
    "        # Create an Epoch column\n",
    "        epochs = list(range(1, len(self.validation_scores) + 1))\n",
    "\n",
    "        # Create DataFrame for plotting\n",
    "        data = pd.DataFrame({\n",
    "            'Epoch': epochs,\n",
    "            'F1 Score': self.validation_scores,\n",
    "            'Loss': self.training_losses\n",
    "        })\n",
    "\n",
    "        # Plot F1 score and Loss\n",
    "        self.image = plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # F1 score line plot\n",
    "        sns.lineplot(x='Epoch', y='F1 Score', data=data, label='F1 Score', marker='o')\n",
    "\n",
    "        # Loss line plot on the same axes\n",
    "        sns.lineplot(x='Epoch', y='Loss', data=data, label='Loss', marker='o')\n",
    "\n",
    "        # Set plot labels and title\n",
    "        plt.title('F1 Score and Loss over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score / Loss')\n",
    "\n",
    "        # Show legend and grid\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Load the image from BytesIO object into a PIL Image\n",
    "        self.image = Image.open(buf)\n",
    "\n",
    "        plt.close()\n",
    "        # Display the plot\n",
    "        # self.image.show()\n",
    "\n",
    "    def MultiHeadsAttention(self, Inputs):\n",
    "        #print(\"cupy.matmul(Inputs, self.Q)\", cupy.matmul(Inputs, self.Q).shape)\n",
    "        #print(\"cupy.array_split:\",cupy.array(cupy.array_split(cupy.matmul(Inputs, self.Q), self.num_heads, axis=2)).shape)\n",
    "        # print(\"Kval shape:\", self.Kval.shape)\n",
    "        # print(\"Vval shape:\", self.Vval.shape)\n",
    "        self.Qval = cupy.swapaxes(cupy.array(cupy.array_split(cupy.matmul(Inputs, self.Q), self.num_heads, axis=2)), 0, 1)\n",
    "        self.Kval = cupy.swapaxes(cupy.array(cupy.array_split(cupy.matmul(Inputs, self.K), self.num_heads, axis=2)), 0, 1)\n",
    "        self.Vval = cupy.swapaxes(cupy.array(cupy.array_split(cupy.matmul(Inputs, self.V), self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Qval shape:\", self.Qval.shape)\n",
    "        # print(\"Kval shape:\", self.Kval.shape)\n",
    "        # print(\"Vval shape:\", self.Vval.shape)\n",
    "\n",
    "        QKscaled = cupy.matmul(self.Qval, cupy.transpose(self.Kval, (0, 1, 3, 2))) / cupy.sqrt(self.dk)\n",
    "        # print(\"QKscaled shape:\", QKscaled.shape)\n",
    "\n",
    "        self.Attention_weights = self.softmax(QKscaled)\n",
    "        # print(\"Attention_weights shape:\", self.Attention_weights.shape)\n",
    "\n",
    "        Attention_output = cupy.matmul(self.Attention_weights, self.Vval)\n",
    "        # print(\"Attention output shape:\", Attention_output.shape)\n",
    "\n",
    "        return Attention_output\n",
    "\n",
    "    def LinearLayer(self):\n",
    "        output = cupy.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        # print(\"Linear layer output shape:\", output.shape)\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "\n",
    "        Attention = self.MultiHeadsAttention(Inputs)\n",
    "\n",
    "        # print(\"Attention shape:\", Attention.shape)\n",
    "        # print(\"Attention mean shape:\", cupy.mean(Attention, axis=2).shape)\n",
    "        self.phrase_representation = cupy.mean(Attention, axis=2).reshape(Inputs.shape[0], self.dv)\n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "        # print(\"Sigma_Zout shape:\", Sigma_Zout.shape)\n",
    "\n",
    "        return Sigma_Zout\n",
    "\n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, Inputs):\n",
    "\n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = cupy.dot(dLoss_dSigma_Zout.T, self.phrase_representation).T\n",
    "        # print(\"dlinear_dW shape:\", dlinear_dW.shape)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = cupy.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        # print(\"d_bias shape:\", d_bias.shape)\n",
    "\n",
    "        # Gradient for phrase representation\n",
    "        d_phrase_rep = cupy.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "        # print(\"d_phrase_rep shape:\", d_phrase_rep.shape)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = cupy.array(\n",
    "            [cupy.outer(cupy.ones(Inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])]) / \\\n",
    "                Inputs.shape[1]\n",
    "        dL_dA = cupy.swapaxes(cupy.array(cupy.array_split(dL_dA, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"dL_dA shape:\", dL_dA.shape)\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval = cupy.matmul(cupy.transpose(dL_dA, (0, 1, 3, 2)), self.Attention_weights)\n",
    "        dLoss_dV = cupy.concatenate(\n",
    "            cupy.mean(cupy.matmul(d_Vval, Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])),\n",
    "                    axis=0), axis=0).T\n",
    "        # print(\"dLoss_dV shape:\", dLoss_dV.shape)\n",
    "\n",
    "        # Gradient of softmax\n",
    "        dAttention_dSoftmax = self.Attention_weights * (1 - self.Attention_weights)\n",
    "        # print(\"dAttention_dSoftmax shape:\", dAttention_dSoftmax.shape)\n",
    "\n",
    "        # Compute dLoss_dQ\n",
    "        dLoss_dQ = cupy.transpose(dL_dA, (0, 1, 3, 2)) @ dAttention_dSoftmax @ self.Kval @ cupy.transpose(self.Vval, (\n",
    "            0, 1, 3, 2)) @ Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])\n",
    "        dLoss_dQ = cupy.concatenate(cupy.mean(dLoss_dQ, axis=0), axis=0).T\n",
    "        # print(\"dLoss_dQ shape:\", dLoss_dQ.shape)\n",
    "\n",
    "        # Gradient of K\n",
    "        dLoss_dK = cupy.transpose(dL_dA, (0, 1, 3, 2)) @ dAttention_dSoftmax @ self.Qval @ cupy.transpose(self.Vval, (\n",
    "            0, 1, 3, 2)) @ Inputs.reshape(Inputs.shape[0], 1, self.words_per_phrase, Inputs.shape[2])\n",
    "        dLoss_dK = cupy.concatenate(cupy.mean(dLoss_dK, axis=0), axis=0).T\n",
    "        # print(\"dLoss_dK shape:\", dLoss_dK.shape)\n",
    "\n",
    "        # Gradient clipping\n",
    "        clip_value = 150.0\n",
    "        dLoss_dQ = cupy.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = cupy.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = cupy.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = cupy.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = cupy.clip(d_bias, -clip_value, clip_value)\n",
    "\n",
    "        self.UpdateParams(dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias)\n",
    "\n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.iterations += 1\n",
    "        # Set a minimum learning rate to avoid it going too low\n",
    "        # Linear learning rate decay\n",
    "\n",
    "        lr = self.learning_rate * (1 - self.iterations / (self.total_iterations*2))\n",
    "        self.learning_rate = max(lr, 0.001)  # Prevent learning rate from becoming too small\n",
    "\n",
    "        # Update biased first moments (momentum)\n",
    "        self.MomQ = (self.momentum_beta * self.MomQ + (1 - self.momentum_beta) * dLoss_dQ)\n",
    "        self.MomK = (self.momentum_beta * self.MomK + (1 - self.momentum_beta) * dLoss_dK)\n",
    "        self.MomV = (self.momentum_beta * self.MomV + (1 - self.momentum_beta) * dLoss_dV)\n",
    "        self.MomLy = (self.momentum_beta * self.MomLy + (1 - self.momentum_beta) * dlinear_dW)\n",
    "        self.MomB = (self.momentum_beta * self.MomB + (1 - self.momentum_beta) * d_bias)\n",
    "\n",
    "        # Update biased second moments (variance)\n",
    "        self.RMSPQ = (self.rmsprop_beta * self.RMSPQ + (1 - self.rmsprop_beta) * dLoss_dQ * dLoss_dQ)\n",
    "        self.RMSPK = (self.rmsprop_beta * self.RMSPK + (1 - self.rmsprop_beta) * dLoss_dK * dLoss_dK)\n",
    "        self.RMSPV = (self.rmsprop_beta * self.RMSPV + (1 - self.rmsprop_beta) * dLoss_dV * dLoss_dV)\n",
    "        self.RMSPLy = (self.rmsprop_beta * self.RMSPLy + (1 - self.rmsprop_beta) * dlinear_dW * dlinear_dW)\n",
    "        self.RMSPB = (self.rmsprop_beta * self.RMSPB + (1 - self.rmsprop_beta) * d_bias * d_bias)\n",
    "\n",
    "        # Bias correction for first moments\n",
    "        MomQ_corrected = self.MomQ / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomK_corrected = self.MomK / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomV_corrected = self.MomV / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomLy_corrected = self.MomLy / (1 - self.momentum_beta ** self.iterations)\n",
    "        MomB_corrected = self.MomB / (1 - self.momentum_beta ** self.iterations)\n",
    "\n",
    "        # Bias correction for second moments\n",
    "        RMSPQ_corrected = self.RMSPQ / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPK_corrected = self.RMSPK / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPV_corrected = self.RMSPV / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPLy_corrected = self.RMSPLy / (1 - self.rmsprop_beta ** self.iterations)\n",
    "        RMSPB_corrected = self.RMSPB / (1 - self.rmsprop_beta ** self.iterations)\n",
    "\n",
    "        # Update parameters using bias-corrected moments\n",
    "        self.Q -= self.learning_rate * MomQ_corrected / (cupy.sqrt(RMSPQ_corrected) + self.epsilon)\n",
    "        self.K -= self.learning_rate * MomK_corrected / (cupy.sqrt(RMSPK_corrected) + self.epsilon)\n",
    "        self.V -= self.learning_rate * MomV_corrected / (cupy.sqrt(RMSPV_corrected) + self.epsilon)\n",
    "        self.linearlayer -= self.learning_rate * MomLy_corrected / (cupy.sqrt(RMSPLy_corrected) + self.epsilon)\n",
    "        self.linear_bias -= self.learning_rate * MomB_corrected / (cupy.sqrt(RMSPB_corrected) + self.epsilon)\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        X_train = self.pad_sequences(X_train, self.words_per_phrase)\n",
    "\n",
    "        if self.validation_split > 0:\n",
    "            X_train, X_train_validation, y_train, y_train_validation = train_test_split(\n",
    "                X_train, y_train, test_size=self.validation_split, random_state=42)\n",
    "            print(\"Training starting:\")\n",
    "            print(\"X_train samples: \", X_train.shape[0])\n",
    "            print(\"X_train_validation samples\", X_train_validation.shape[0], \"\\n\")\n",
    "\n",
    "        self.total_iterations = num_epochs * (len(X_train) // self.batch_size)\n",
    "        for epoch in range(num_epochs):\n",
    "            self.iterations = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "\n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                yi = self.forward(X_batch)\n",
    "\n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "\n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "\n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "\n",
    "            if self.validation_split > 0:\n",
    "                self.training_validation(X_train_validation, y_train_validation, Loss)\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}, learning rate: {self.learning_rate}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.pad_sequences(X, self.words_per_phrase)\n",
    "        return self.forward(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"data/bbc-text.csv\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "with open('data/InputProcessed.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "y = np.array(pd.get_dummies(df[\"category\"], dtype=int))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "X_train=cp.array(X_train)\n",
    "X_test=cp.array(X_test)\n",
    "y_train=cp.array(y_train)\n",
    "y_test=cp.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "word_len = 300\n",
    "max_words_per_phrase=150\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "num_head=8\n",
    "\n",
    "attention_matrix_size=10\n",
    "dk = num_head*attention_matrix_size\n",
    "dv = num_head*attention_matrix_size\n",
    "\n",
    "\n",
    "#validation_split\n",
    "model = QKVMultiHeadsAttentionClassifier(word_len, max_words_per_phrase,num_head, batch_size, dk, dv, num_classes,validation_split=0.1)\n",
    "model.train(X_train, y_train, num_epochs=30, learning_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d64d351-f15e-4502-932d-a11408d87655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fa011e-9e20-49a2-b966-3339de40a86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x600>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15df5a1e-2aca-44ac-9181-0afa79bfe51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_len):\n",
    "        padded_sequences = cupy.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "        for i, seq in enumerate(sequences):\n",
    "            length = min(seq.shape[0], max_len)\n",
    "            padded_sequences[i, :length] = seq[:length]\n",
    "        return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250dd30b-012a-46c0-bf5d-d529f69044c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test= pad_sequences(X_test, max_words_per_phrase)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "y_true = np.argmax(y_test, axis=1) \n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true.get(), y_pred.get(), labels=np.arange(5))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(5), yticklabels=np.arange(5))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8c1177-b396-4077-b1c6-0187fb5e66dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315994518146911"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred.get(),y_true.get(),average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ca2fb80-bac8-4f4b-909f-955195588a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.891, 0.936, 0.904, 0.964, 0.912])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred.get(),y_true.get(),average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9f2c27d1-7d09-4d44-87d6-d5fd796f377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.808     , 0.76190476, 0.8       , 0.88311688, 0.81052632])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7aa2e429-18b8-4569-9b67-5d0c92932d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82071713, 0.7816092 , 0.83937824, 0.89686099, 0.80874317])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0d45d6f8-be94-4652-9b97-4ff464f258b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83464567, 0.82634731, 0.78974359, 0.88596491, 0.88888889])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3f1d1-6461-4c95-bfce-3b54a020f5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
