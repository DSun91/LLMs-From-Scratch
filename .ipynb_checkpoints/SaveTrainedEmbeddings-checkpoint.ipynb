{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e369085c-ed60-44b8-9930-9dd98baf8858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 6, 3), (2, 6, 3), (2, 6, 4))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Phrase 1\n",
    "word1 = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.3])\n",
    "word2 = np.array([0.5, 0.4, 0.7, 0.3, 0.2, 0.3])\n",
    "word3 = np.array([0.2, 0.7, 0.3, 0.5, 0.4, 0.4])\n",
    "word4 = np.array([0.4, 0.1, 0.7, 0.2, 0.5, 0.7])\n",
    "\n",
    "# Phrase 2\n",
    "word5 = np.array([0.1, 0.9, 0.3, 0.4, 0.5, 0.2])\n",
    "word6 = np.array([0.4, 0.4, 0.7, 0.3, 0.4, 0.6])\n",
    "word7 = np.array([0.2, 0.7, 0.4, 0.5, 0.4, 0.2])\n",
    "word8 = np.array([0.4, 0.5, 0.7, 0.7, 0.5, 0.1])\n",
    "\n",
    "# Phrase 3\n",
    "word9 = np.array([0.1, 0.2, 0.3, 0.8, 0.5, 0.2])\n",
    "word10 = np.array([0.4, 0.5, 0.7, 0.3, 0.8, 0.4])\n",
    "word11 = np.array([0.9, 0.7, 0.3, 0.5, 0.4, 0.6])\n",
    "word12 = np.array([0.4, 0.5, 0.1, 0.7, 0.4, 0.4])\n",
    "\n",
    "word13 = np.array([0.9, 0.7, 0.2, 0.5, 0.3, 0.6])\n",
    "word14 = np.array([0.5, 0.5, 0.1, 0.4, 0.1, 0.4])\n",
    "\n",
    "inputs = np.stack([[word1, word2, word3, word4], \n",
    "                   [word5, word6, word7, word8], \n",
    "                   [word9, word10, word11, word12]])\n",
    "\n",
    "\n",
    "inputs = np.stack([[word1, word2, word6, word2, word3], \n",
    "                   [word3, word4, word11, word12, word2],\n",
    "                   [word5, word6, word2, word3, word4],\n",
    "                   [word7, word8, word7, word8, word4],\n",
    "                   [word9, word10, word3, word4, word1],\n",
    "                   [word11, word12, word7, word8, word7],\n",
    "                   [word13, word14, word10, word3, word4],\n",
    "                   [word7, word8,word14, word10,word3],\n",
    "                   [word9, word10,word8,word14,word1]])\n",
    "\n",
    "num_head = 2\n",
    "dk = 3\n",
    "dv = 4\n",
    "words_per_phrase = 5\n",
    "word2vec_len = 6 \n",
    "num_prases = 9\n",
    " \n",
    "\n",
    "Q = np.random.rand(num_head, word2vec_len, dk) / np.sqrt(word2vec_len)\n",
    "K = np.random.rand(num_head, word2vec_len, dk) / np.sqrt(word2vec_len)\n",
    "V = np.random.rand(num_head, word2vec_len, dv) / np.sqrt(word2vec_len)\n",
    "Q.shape,K.shape,V.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d3c8acac-2647-4cd5-b13a-8fb86441a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qval.shape:  (9, 2, 5, 3)\n",
      "Kval.shape:  (9, 2, 5, 3)\n",
      "Vval.shape:  (9, 2, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "Qval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@Q\n",
    "print(\"Qval.shape: \",Qval.shape)\n",
    "\n",
    "Kval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@K\n",
    "print(\"Kval.shape: \",Kval.shape)\n",
    "\n",
    "\n",
    "Vval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@V\n",
    "print(\"Vval.shape: \",Vval.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3f8a5c60-8aff-4f7f-b674-cf614f8a07fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_weights shape: (9, 2, 5, 5)\n",
      "Attention shape: (9, 2, 5, 4)\n",
      "Concat Phrase Representation: (9, 8)\n"
     ]
    }
   ],
   "source": [
    "QKscaled = np.matmul(Qval, np.transpose(Kval, (0, 1, 3, 2))) / np.sqrt(dk)\n",
    "QKscaled\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    # Subtract the max value for numerical stability\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "Attention_weights = softmax(QKscaled)\n",
    "Attention_weights\n",
    "print(\"Attention_weights shape:\",Attention_weights.shape)\n",
    "Attention = np.matmul(Attention_weights, Vval)\n",
    "  \n",
    "print(\"Attention shape:\",Attention.shape)\n",
    "phrase_representation = np.mean(Attention, axis=2).reshape(num_prases, dv * num_head)\n",
    "print(\"Concat Phrase Representation:\",phrase_representation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667d9f3-653d-4363-a533-42e396d2911e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7514fc22-3bed-4d44-8ac2-09779961c47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss:  0.9860394846954631\n",
      "dL_dA.shape:  (9, 2, 5, 4)\n",
      "A.shape:  (9, 2, 5, 4)\n",
      "dLoss_dV.shape:  (2, 6, 4)\n",
      "Attention_weights.shape:  (9, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2  # Example number of classes (binary classification)\n",
    "linearlayer = np.random.rand(dv * num_head, num_classes)\n",
    "linear_bias = np.random.rand(num_classes)\n",
    "Sigma_Zout = softmax(np.matmul(phrase_representation, linearlayer) + linear_bias)\n",
    "Sigma_Zout\n",
    "import numpy as np\n",
    "\n",
    "target = [np.array([0, 1]), np.array([1, 0]), np.array([1, 1]),np.array([0, 1]), np.array([1, 1]), np.array([1, 0]),np.array([1, 0]), np.array([1, 0]), np.array([1, 1])]\n",
    "\n",
    "\n",
    "def cross_entropy_loss(predictions, target):\n",
    "    batch_loss = -np.sum(target * np.log(predictions + 1e-8), axis=1)\n",
    "    return np.mean(batch_loss)\n",
    "\n",
    "\n",
    "loss = cross_entropy_loss(Sigma_Zout, target)\n",
    "print(\"Cross-Entropy Loss: \", loss)\n",
    "\n",
    "# Gradient of loss with respect to output probabilities\n",
    "dLoss_dSigma_Zout = Sigma_Zout - np.stack(target)\n",
    "dLoss_dSigma_Zout\n",
    "# Gradient for linear layer and bias\n",
    "d_linear = np.dot(dLoss_dSigma_Zout.T, phrase_representation).T\n",
    "d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "d_linear, d_bias\n",
    "\n",
    "# Gradient for phrase representation\n",
    "d_phrase_rep = np.dot(dLoss_dSigma_Zout, linearlayer.T)\n",
    "d_phrase_rep\n",
    "\n",
    "# Gradient for attention\n",
    "dL_dA = np.array([np.outer(np.ones(inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])]) / \\\n",
    "        inputs.shape[1]\n",
    "dL_dA =dL_dA.reshape(num_prases, num_head, words_per_phrase, dv) \n",
    "dL_dA.shape\n",
    "print(\"dL_dA.shape: \", dL_dA.shape)\n",
    "print(\"A.shape: \",Attention.shape)\n",
    "# Gradient for V\n",
    "d_Vval = np.matmul(np.transpose(dL_dA,(0,1,3,2)), Attention_weights) \n",
    "dLoss_dV = np.transpose(\n",
    "    np.mean(np.matmul(d_Vval, inputs.reshape(num_prases, 1, words_per_phrase, inputs.shape[2])), axis=0), (0, 2, 1))\n",
    "\n",
    "print(\"dLoss_dV.shape: \", dLoss_dV.shape)\n",
    "print(\"Attention_weights.shape: \", Attention_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf5854-7cfd-4530-a383-d8efd33bcbfa",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{Q}} =\\frac{\\partial Loss}{\\partial A} \\cdot [\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})]] \\cdot \\frac{Inputs \\cdot K_{val}^T}{\\sqrt{d_k}} \\cdot V_{val}\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6e049-9a90-461a-8feb-50c8a0d109e1",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    "[\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})]]\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "07885241-988d-4a5a-9a22-da5b8c361080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_derivative.shape:  (9, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "softmax_derivative = Attention_weights*(1 - Attention_weights)\n",
    "print(\"softmax_derivative.shape: \", softmax_derivative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5278948-1ae1-4a4a-9bad-02edced98006",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    " \\frac{Inputs \\cdot K_{val}^T}{\\sqrt{d_k}}\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "23bbbee5-21de-460d-9b2a-685c337a0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape:  (9, 5, 6)\n",
      "Kval.shape:  (9, 2, 5, 3)\n",
      "Q.shape:  (2, 6, 3) K.shape:  (2, 6, 3)\n",
      "Vval.shape:  (9, 2, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs.shape: \", inputs.shape)\n",
    "print(\"Kval.shape: \", Kval.shape)\n",
    "print(\"Q.shape: \", Q.shape,\"K.shape: \",K.shape)\n",
    "print(\"Vval.shape: \", Vval.shape ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4e00e-29c8-49e3-a65d-bb680f9bf8d4",
   "metadata": {},
   "source": [
    "\\\\[ \n",
    " K_{val}^T=(Inputs \\cdot K)^T = K^T \\cdot I^T\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3c5bdd10-b2ad-448d-ae9d-1ce47957d644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2, 5, 6)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I=np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab7a77-f3e8-452f-b49a-986ab4c7cf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7f7e99b3-0772-4c84-8582-4b990a8299f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dLoss_dQ=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Kval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dQ=np.transpose(np.mean(dLoss_dQ,axis=0),(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0e79186b-3feb-432c-987d-9215c399bcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fead05db-c4b7-433f-a52f-0cb8d09cd1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2, 6, 5)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(I,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "70cb3eb0-eaac-4278-acda-bb1848fa420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2, 4, 5)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Vval,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e7ef12f7-dfc8-4bf5-b513-313884b7afa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.04483918,  0.04765099,  0.06119899,  0.04765099,\n",
       "           0.05888704],\n",
       "         [ 0.06164859,  0.06551446,  0.08414102,  0.06551446,\n",
       "           0.08096256],\n",
       "         [ 0.04674712,  0.04967851,  0.06380234,  0.04967851,\n",
       "           0.06139238]],\n",
       "\n",
       "        [[ 0.07564711,  0.08706407,  0.10866893,  0.08706407,\n",
       "           0.09794627],\n",
       "         [ 0.06125771,  0.07050274,  0.08799808,  0.07050274,\n",
       "           0.07931507],\n",
       "         [ 0.07889673,  0.09080425,  0.11333715,  0.09080425,\n",
       "           0.10215387]]],\n",
       "\n",
       "\n",
       "       [[[-0.03783132, -0.03741229, -0.04711875, -0.03827536,\n",
       "          -0.03061274],\n",
       "         [-0.04855243, -0.04801466, -0.06047184, -0.04912229,\n",
       "          -0.03928816],\n",
       "         [-0.04253822, -0.04206754, -0.05298123, -0.04303681,\n",
       "          -0.03442132]],\n",
       "\n",
       "        [[-0.06516863, -0.06831582, -0.07362426, -0.05729565,\n",
       "          -0.05792805],\n",
       "         [-0.05129823, -0.05377566, -0.05795364, -0.04510075,\n",
       "          -0.04559854],\n",
       "         [-0.06709721, -0.0703375 , -0.07580326, -0.0589913 ,\n",
       "          -0.05964242]]],\n",
       "\n",
       "\n",
       "       [[[-0.36434911, -0.39005859, -0.30959551, -0.37345975,\n",
       "          -0.3689041 ],\n",
       "         [-0.53452265, -0.57224021, -0.45419594, -0.54788856,\n",
       "          -0.54120522],\n",
       "         [-0.39844255, -0.42655773, -0.33856544, -0.4084057 ,\n",
       "          -0.40342375]],\n",
       "\n",
       "        [[-0.47593614, -0.50795413, -0.43187816, -0.46494832,\n",
       "          -0.46861892],\n",
       "         [-0.38072164, -0.40633425, -0.34547766, -0.37193202,\n",
       "          -0.37486844],\n",
       "         [-0.49721577, -0.53066532, -0.45118794, -0.48573668,\n",
       "          -0.48957137]]],\n",
       "\n",
       "\n",
       "       [[[ 0.06826988,  0.07868539,  0.06826988,  0.07868539,\n",
       "           0.07262586],\n",
       "         [ 0.09060111,  0.1044219 ,  0.09060111,  0.1044219 ,\n",
       "           0.09638347],\n",
       "         [ 0.05837563,  0.06727945,  0.05837563,  0.06727945,\n",
       "           0.06210233]],\n",
       "\n",
       "        [[ 0.10607373,  0.1238479 ,  0.10607373,  0.1238479 ,\n",
       "           0.11330645],\n",
       "         [ 0.07860731,  0.09177913,  0.07860731,  0.09177913,\n",
       "           0.08396716],\n",
       "         [ 0.11948424,  0.13950571,  0.11948424,  0.13950571,\n",
       "           0.12763107]]],\n",
       "\n",
       "\n",
       "       [[[-0.35377244, -0.49655858, -0.40823312, -0.40325273,\n",
       "          -0.30588459],\n",
       "         [-0.44812388, -0.62899019, -0.51710797, -0.5107983 ,\n",
       "          -0.38746419],\n",
       "         [-0.31691514, -0.44482463, -0.36570106, -0.36123889,\n",
       "          -0.27401635]],\n",
       "\n",
       "        [[-0.36751088, -0.5917013 , -0.45615996, -0.45976887,\n",
       "          -0.33022007],\n",
       "         [-0.26657306, -0.42917262, -0.33085645, -0.3334859 ,\n",
       "          -0.23952486],\n",
       "         [-0.41890628, -0.67445011, -0.51995377, -0.52406668,\n",
       "          -0.37640042]]],\n",
       "\n",
       "\n",
       "       [[[-0.05059394, -0.04109826, -0.03776089, -0.04352033,\n",
       "          -0.03776089],\n",
       "         [-0.06694956, -0.05438455, -0.04996811, -0.05758984,\n",
       "          -0.04996811],\n",
       "         [-0.0496192 , -0.04030636, -0.03703335, -0.0426817 ,\n",
       "          -0.03703335]],\n",
       "\n",
       "        [[-0.07262366, -0.05651694, -0.06308552, -0.07365627,\n",
       "          -0.06308552],\n",
       "         [-0.05206022, -0.04051441, -0.0452233 , -0.05280094,\n",
       "          -0.0452233 ],\n",
       "         [-0.07842891, -0.06103474, -0.06812844, -0.07954417,\n",
       "          -0.06812844]]],\n",
       "\n",
       "\n",
       "       [[[-0.04254125, -0.02681498, -0.04370003, -0.036473  ,\n",
       "          -0.03607007],\n",
       "         [-0.05670617, -0.03574352, -0.05825082, -0.04861738,\n",
       "          -0.04808033],\n",
       "         [-0.04944225, -0.03116501, -0.0507887 , -0.04238965,\n",
       "          -0.04192094]],\n",
       "\n",
       "        [[-0.0648238 , -0.03970101, -0.08484148, -0.06379159,\n",
       "          -0.06687297],\n",
       "         [-0.05171728, -0.03167432, -0.0676943 , -0.05089892,\n",
       "          -0.05335832],\n",
       "         [-0.06773116, -0.04148244, -0.08866339, -0.06666563,\n",
       "          -0.06988781]]],\n",
       "\n",
       "\n",
       "       [[[-0.03479096, -0.04010081, -0.02751602, -0.04483865,\n",
       "          -0.03742539],\n",
       "         [-0.04859302, -0.05600821, -0.03843213, -0.06262782,\n",
       "          -0.05227298],\n",
       "         [-0.03344047, -0.03854049, -0.0264483 , -0.0431015 ,\n",
       "          -0.03597397]],\n",
       "\n",
       "        [[-0.05780746, -0.06749406, -0.03666308, -0.07834202,\n",
       "          -0.05890451],\n",
       "         [-0.04241016, -0.04951714, -0.02689954, -0.05747506,\n",
       "          -0.04321476],\n",
       "         [-0.06370835, -0.07438567, -0.04041354, -0.08633826,\n",
       "          -0.06491634]]],\n",
       "\n",
       "\n",
       "       [[[-0.3687474 , -0.51751199, -0.4589932 , -0.32017286,\n",
       "          -0.31881964],\n",
       "         [-0.44932888, -0.63060206, -0.55929503, -0.39013877,\n",
       "          -0.38849045],\n",
       "         [-0.31014013, -0.4352612 , -0.3860434 , -0.26928647,\n",
       "          -0.26814778]],\n",
       "\n",
       "        [[-0.36122097, -0.58153036, -0.51754537, -0.33391938,\n",
       "          -0.32459234],\n",
       "         [-0.25520722, -0.41085457, -0.365647  , -0.2359096 ,\n",
       "          -0.22932876],\n",
       "         [-0.41638549, -0.67033598, -0.5965781 , -0.3849062 ,\n",
       "          -0.37416318]]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax@Kval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@inputs/np.sqrt(dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab612f0-689a-44de-9d77-661850e4f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)\n",
    "\n",
    "dLoss_dQ=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Kval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dQ=np.transpose(np.mean(dLoss_dQ,axis=0),(0,2,1)).shape\n",
    "\n",
    "dLoss_dK=np.transpose(np.transpose(dL_dA,(0,1,3,2))@softmax_derivative@Qval,(0,1,3,2))@np.transpose(Vval,(0,1,3,2))@I/np.sqrt(dk)\n",
    "dLoss_dK=np.transpose(np.mean(dLoss_dK,axis=0),(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e221f-b40e-4b6c-87bc-c33783aea24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e59af831-f34e-41a6-a788-0d8f771ec093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2375a181-798d-4cb1-b14a-ccd84db5e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dQKscaled_dK shape: (9, 2, 5, 6, 3)\n",
      "dQKscaled_dQ shape: (9, 2, 5, 6, 3)\n",
      "dLoss_dQ shape: (2, 6, 3)\n",
      "dLoss_dK shape: (2, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dQKscaled_dK = np.einsum('nwi,nhwk->nhwik', inputs, Qval) / np.sqrt(dk)\n",
    "dQKscaled_dQ = np.einsum('nwi,nhwk->nhwik', inputs, Kval) / np.sqrt(dk)\n",
    "\n",
    "# Calculate dAttention_dSoftmax\n",
    "dAttention_dSoftmax = Attention_weights * (1 - Attention_weights)\n",
    "\n",
    "# Calculate dLoss_dQ\n",
    "dLoss_dQ = np.einsum('nhwv,nhwx,nhwik,nhwv->nhik', \n",
    "                     dL_dA, \n",
    "                     dAttention_dSoftmax, \n",
    "                     dQKscaled_dQ, \n",
    "                     Vval) / np.sqrt(dk)\n",
    "\n",
    "# Average over the batch dimension\n",
    "dLoss_dQ = np.mean(dLoss_dQ, axis=0)\n",
    "\n",
    "print(\"dQKscaled_dK shape:\", dQKscaled_dK.shape)\n",
    "print(\"dQKscaled_dQ shape:\", dQKscaled_dQ.shape)\n",
    "print(\"dLoss_dQ shape:\", dLoss_dQ.shape)\n",
    "# Gradient of QKscaled with respect to K\n",
    "dQKscaled_dK = np.einsum('nwi,nhwk->nhwik', inputs, Qval) / np.sqrt(dk)\n",
    "\n",
    "# Calculate dAttention_dSoftmax\n",
    "dAttention_dSoftmax = Attention_weights * (1 - Attention_weights)\n",
    "\n",
    "# Calculate dLoss_dK\n",
    "dLoss_dK = np.einsum('nhwv,nhwx,nhwik,nhwv->nhik', \n",
    "                     dL_dA, \n",
    "                     dAttention_dSoftmax, \n",
    "                     dQKscaled_dK, \n",
    "                     Vval) / np.sqrt(dk)\n",
    "\n",
    "# Average over the batch dimension\n",
    "dLoss_dK = np.mean(dLoss_dK, axis=0)\n",
    "\n",
    "print(\"dLoss_dK shape:\", dLoss_dK.shape)\n",
    "learning_rate = 0.001\n",
    "Q -= learning_rate * dLoss_dQ\n",
    "K -= learning_rate * dLoss_dK\n",
    "V -= learning_rate * dLoss_dV\n",
    "linearlayer -= learning_rate * d_linear\n",
    "linear_bias -= learning_rate * d_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f6790c-9d32-4591-9fd8-33708a38f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1713,), (512,), (1713, 5), (512, 5))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\python312\\\\lib\\\\site-packages')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "df=pd.read_csv(\"data/bbc-text.csv\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "with open('data/InputProcessed.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "y = np.array(pd.get_dummies(df[\"category\"], dtype=int))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.23, random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ecf65905-8a08-4d34-9890-d4944fa33225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape[0]/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24d1fc-4977-4af2-9dd8-e141d7f0ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@Q\n",
    "print(\"Qval.shape: \",Qval.shape)\n",
    "\n",
    "Kval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@K\n",
    "print(\"Kval.shape: \",Kval.shape)\n",
    "\n",
    "\n",
    "Vval = np.repeat(inputs, num_head, axis=0).reshape(num_prases,num_head,words_per_phrase,word2vec_len)@V\n",
    "print(\"Vval.shape: \",Vval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afd0a1b-1bb8-4ef9-8afc-65ddd56ce31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVMultiHeadsAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase,num_heads, batch_size, dk, dv, num_classes):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_heads = num_heads\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.randn(self.num_heads, self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.K = np.random.randn(self.num_heads, self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.V = np.random.randn(self.num_heads, self.word_len, self.dv) / np.sqrt(self.word_len)  # * 0.01\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dv*self.num_heads, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        softmax_result= e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "        #print(\"Softmax result shape:\", softmax_result.shape)\n",
    "        return softmax_result\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        mean_loss = np.mean(batch_loss)\n",
    "        #print(\"Cross-entropy loss:\", mean_loss)\n",
    "        return mean_loss\n",
    "\n",
    "    def MultiHeadsAttention(self, Inputs):\n",
    "        self.Qval = np.repeat(Inputs, self.num_heads, axis=0).reshape(self.batch_size,self.num_heads,self.words_per_phrase,self.word_len)@self.Q\n",
    "        self.Kval = np.repeat(Inputs, self.num_heads, axis=0).reshape(self.batch_size,self.num_heads,self.words_per_phrase,self.word_len)@self.K\n",
    "        self.Vval = np.repeat(Inputs, self.num_heads, axis=0).reshape(self.batch_size,self.num_heads,self.words_per_phrase,self.word_len)@self.V\n",
    "        #print(\"Qval shape:\", self.Qval.shape)\n",
    "        #print(\"Kval shape:\", self.Kval.shape)\n",
    "        #print(\"Vval shape:\", self.Vval.shape)\n",
    "\n",
    "        QKscaled = np.matmul(self.Qval, np.transpose(self.Kval, (0, 1, 3, 2))) / np.sqrt(self.dk)\n",
    "        #print(\"QKscaled shape:\", QKscaled.shape)\n",
    "\n",
    "        self.Attention_weights = self.softmax(QKscaled)\n",
    "        #print(\"Attention_weights shape:\", self.Attention_weights.shape)\n",
    "\n",
    "        Attention_output = np.matmul(self.Attention_weights, self.Vval)\n",
    "        #print(\"Attention output shape:\", Attention_output.shape)\n",
    "\n",
    "        return Attention_output\n",
    "\n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        #print(\"Linear layer output shape:\", output.shape)\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "\n",
    "        Attention = self.MultiHeadsAttention(Inputs)\n",
    "        \n",
    "        self.phrase_representation = np.mean(Attention, axis=2)\n",
    "        #print(\"Phrase representation shape before reshaping:\", self.phrase_representation.shape)\n",
    "\n",
    "        self.phrase_representation = self.phrase_representation.reshape(self.batch_size, self.dv * self.num_heads)\n",
    "        #print(\"Phrase representation shape after reshaping:\", self.phrase_representation.shape)\n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "        #print(\"Sigma_Zout shape:\", Sigma_Zout.shape)\n",
    "\n",
    "        return Sigma_Zout\n",
    "       \n",
    "\n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "\n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(dLoss_dSigma_Zout.T, self.phrase_representation).T\n",
    "        #print(\"dlinear_dW shape:\", dlinear_dW.shape)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        #print(\"d_bias shape:\", d_bias.shape)\n",
    "\n",
    "        # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "        #print(\"d_phrase_rep shape:\", d_phrase_rep.shape)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array([np.outer(np.ones(inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])]) / inputs.shape[1]\n",
    "        dL_dA = dL_dA.reshape(self.batch_size, self.num_heads, self.words_per_phrase, self.dv)\n",
    "        #print(\"dL_dA shape:\", dL_dA.shape)\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval = np.matmul(np.transpose(dL_dA, (0, 1, 3, 2)), self.Attention_weights)\n",
    "        dLoss_dV = np.transpose(np.mean(np.matmul(d_Vval, inputs.reshape(self.batch_size, 1, self.words_per_phrase, inputs.shape[2])), axis=0), (0, 2, 1))\n",
    "        #print(\"dLoss_dV shape:\", dLoss_dV.shape)\n",
    "\n",
    "        # Gradient of softmax\n",
    "        dAttention_dSoftmax = self.Attention_weights * (1 - self.Attention_weights)\n",
    "        #print(\"dAttention_dSoftmax shape:\", dAttention_dSoftmax.shape)\n",
    "\n",
    "\n",
    " \n",
    "        I=np.repeat(inputs, self.num_heads, axis=0).reshape(self.batch_size,self.num_heads,self.words_per_phrase,self.word_len)\n",
    "        # Compute dLoss_dQ\n",
    "        dLoss_dQ=np.transpose(np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax@self.Kval,(0,1,3,2))@np.transpose(self.Vval,(0,1,3,2))@I/np.sqrt(self.dk)\n",
    "        dLoss_dQ=np.transpose(np.mean(dLoss_dQ,axis=0),(0,2,1)) \n",
    "        #print(\"dLoss_dQ shape:\", dLoss_dQ.shape)\n",
    "\n",
    "        # Gradient of K\n",
    "        dLoss_dK=np.transpose(np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax@self.Qval,(0,1,3,2))@np.transpose(self.Vval,(0,1,3,2))@I/np.sqrt(self.dk)\n",
    "        dLoss_dK=np.transpose(np.mean(dLoss_dK,axis=0),(0,2,1)) \n",
    "        #print(\"dLoss_dK shape:\", dLoss_dK.shape)\n",
    "\n",
    "        # Gradient clipping\n",
    "        clip_value = 15.0\n",
    "        dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = np.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "\n",
    "        self.UpdateParams(dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias)\n",
    "\n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.Q -= self.learning_rate * dLoss_dQ\n",
    "        self.K -= self.learning_rate * dLoss_dK\n",
    "        self.V -= self.learning_rate * dLoss_dV\n",
    "        self.linearlayer -= self.learning_rate * dlinear_dW\n",
    "        self.linear_bias -= self.learning_rate * d_bias\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "\n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "                \n",
    "                yi = self.forward(X_batch)\n",
    "\n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "\n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "\n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916e46f-2964-47fc-9870-fb7a98d2bc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843acf5a-5068-4332-8093-e9680c7993d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc61562-feda-429a-bc15-db2b31b73639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 2.7495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 1.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:03<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(sequences, max_len):\n",
    "    padded_sequences = np.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = min(seq.shape[0], max_len)\n",
    "        padded_sequences[i, :length] = seq[:length]\n",
    "    return padded_sequences\n",
    "\n",
    "word_len = 300\n",
    "max_words_per_phrase=50\n",
    "dk = 16\n",
    "dv = 32\n",
    "batch_size = 64\n",
    "num_classes = 5\n",
    "num_head=3\n",
    "\n",
    "# padding and truncating phrases to max phrase lenght\n",
    "X_train_padded = pad_sequences(X_train, max_words_per_phrase)\n",
    "\n",
    "\n",
    "\n",
    "model = QKVAttentionClassifier(word_len, max_words_per_phrase,num_head, batch_size, dk, dv, num_classes)\n",
    "model.train(X_train_padded, y_train, num_epochs=10, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2912968d-4d61-402e-ad80-2befbfff6956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.8667\n",
      "F1 Score for class 0: 0.8571\n",
      "F1 Score for class 1: 0.8642\n",
      "F1 Score for class 2: 0.8187\n",
      "F1 Score for class 3: 0.9292\n",
      "F1 Score for class 4: 0.8543\n",
      "Number of predictions: 512\n",
      "Number of true labels: 512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X_test is already padded\n",
    "X_test = pad_sequences(X_test, max_words_per_phrase)\n",
    "\n",
    "# Initialize an empty array for predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Process X_test in batches of 64\n",
    "batch_size = 64\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    batch = X_test[i:i+batch_size]\n",
    "   \n",
    "    batch_predictions = model.predict(batch)\n",
    "    all_predictions.append(batch_predictions)\n",
    "\n",
    "# Concatenate all batch predictions\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# Get the predicted classes\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels for the entire y_test\n",
    "y_true = np.argmax(y_test[0:len(predictions)], axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=np.arange(5))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(5), yticklabels=np.arange(5))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "\n",
    "# If you want to see individual F1 scores for each class\n",
    "f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "for i, score in enumerate(f1_per_class):\n",
    "    print(f\"F1 Score for class {i}: {score:.4f}\")\n",
    "\n",
    "# Print the number of predictions to verify\n",
    "print(f\"Number of predictions: {len(y_pred)}\")\n",
    "print(f\"Number of true labels: {len(y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8c1177-b396-4077-b1c6-0187fb5e66dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85714286, 0.86419753, 0.81871345, 0.92920354, 0.85427136])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4ca2fb80-bac8-4f4b-909f-955195588a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76806084, 0.74025974, 0.73626374, 0.89380531, 0.7638191 ])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9f2c27d1-7d09-4d44-87d6-d5fd796f377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.808     , 0.76190476, 0.8       , 0.88311688, 0.81052632])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7aa2e429-18b8-4569-9b67-5d0c92932d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82071713, 0.7816092 , 0.83937824, 0.89686099, 0.80874317])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0d45d6f8-be94-4652-9b97-4ff464f258b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83464567, 0.82634731, 0.78974359, 0.88596491, 0.88888889])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3f1d1-6461-4c95-bfce-3b54a020f5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
