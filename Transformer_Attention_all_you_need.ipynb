{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89336dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "import cupy as cp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "\n",
    "def log_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Execute the wrapped function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        # print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Helper: \n",
    "    \n",
    "    def get_positional_encoding(self,seq_len, d_model):\n",
    "        \"\"\"\n",
    "        Returns a non-learnable (sinusoidal) positional encoding.\n",
    "\n",
    "\n",
    "        seq_len: Length of the input sequence.\n",
    "        d_model: Dimension of the embeddings.\n",
    "        \"\"\"\n",
    "        pos = cp.arange(seq_len)[:, cp.newaxis]  # Shape: [seq_len, 1]\n",
    "        i = cp.arange(d_model)[cp.newaxis, :]  # Shape: [1, d_model]\n",
    "\n",
    "        angle_rates = 1 / cp.power(10000, (2 * (i // 2)) / cp.float32(d_model))\n",
    "\n",
    "        # Apply sine to even indices, cosine to odd indices\n",
    "        pos_encoding = cp.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = cp.sin(pos * angle_rates[:, 0::2])  # sine on even indices\n",
    "        pos_encoding[:, 1::2] = cp.cos(pos * angle_rates[:, 1::2])  # cosine on odd indices\n",
    "\n",
    "        return pos_encoding\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Subtract the max value for numerical stability\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp(x - max_logits)\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "\n",
    " \n",
    "    # @log_time\n",
    "    def pad_sequence(self,seq, max_len, pad_value=0):\n",
    "        \"\"\"Pad a sequence with a given value up to max_len.\"\"\"\n",
    "        current_len = seq.shape[0]\n",
    "        pad_width = max_len - current_len\n",
    "        if pad_width > 0:\n",
    "            # Pad sequence with zeros (or any pad_value you provide)\n",
    "            seq = cp.pad(seq, ((0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n",
    "        return seq\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_timestaped_input(self,input_d, words_per_phrase):\n",
    "        input_translation = []\n",
    "        for j in range(input_d.shape[0]):\n",
    "            # Create padded sequences\n",
    "            padded_sequences = [self.pad_sequence(input_d[j][0:i], words_per_phrase) for i in range(1, input_d.shape[1] + 1)]\n",
    "            input_translation.append(padded_sequences)\n",
    "        return cp.array(input_translation)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    def redimension(self,X):\n",
    "        return cp.concatenate(cp.swapaxes(X, 0, 1), axis=-1)\n",
    "    \n",
    "    @log_time\n",
    "    def create_vocabulary(self,complete_text, name, nlp):\n",
    "        vocabulary_file = f\"data/{name}.pkl\"\n",
    "        try:\n",
    "            with open(vocabulary_file, 'rb') as handle:\n",
    "                vocabulary = pickle.load(handle)\n",
    "                print(\"Vocabulary loaded from file.\")\n",
    "                return vocabulary\n",
    "        except FileNotFoundError:\n",
    "            print(\"Vocabulary file not found, creating a new one.\")\n",
    "        # Use re.findall to split considering punctuation\n",
    "        text = re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', complete_text)\n",
    "\n",
    "        words_list = list(set(text))\n",
    "\n",
    "        vocabulary = dict()\n",
    "\n",
    "        for i, j in enumerate(words_list):\n",
    "            # vocabulary[j]=(jax.random.uniform(jax.random.key(cp.random.randint(10000)),embedding_size),i)\n",
    "            vocabulary[j] = (cp.array(nlp(j).vector), i)\n",
    "            # print(j,len(cp.array(nlp(j).vector)))\n",
    "\n",
    "        # print(vocabulary)\n",
    "        # print(\"Vocabulary size: \", len(vocabulary))\n",
    "        with open(vocabulary_file, 'wb') as handle:\n",
    "            pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def pad_sequences(self,sentences, lenght, pad_token='[PAD]', target_type=None):\n",
    "        \"\"\"\n",
    "        Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n",
    "        \"\"\"\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        if target_type == \"encoder\":\n",
    "            # Split each sentence into words\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        elif target_type == \"decoder\":\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) for sentence in sentences]\n",
    "        elif target_type == \"target\":\n",
    "            tokenized_sentences = [re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        # print(tokenized_sentences)\n",
    "        if lenght == 0:\n",
    "            # Find the maximum sentence length\n",
    "            max_len = max(len(sentence) for sentence in tokenized_sentences)\n",
    "        else:\n",
    "            max_len = lenght\n",
    "\n",
    "        # Pad each sentence with the [PAD] token to make them of equal length\n",
    "        padded_sentences = [\" \".join(sentence + [pad_token] * (max_len - len(sentence))) for sentence in\n",
    "                            tokenized_sentences]\n",
    "\n",
    "        return padded_sentences\n",
    "\n",
    "    def print_matrix(self,text=\"\",X=None):\n",
    "        for i in X:\n",
    "            print(text,i)\n",
    "    \n",
    "    def create_padding_mask(self,seq):\n",
    "    # Create a mask with 0 for padded tokens and 1 for real tokens\n",
    "        return (seq != 0).astype(cp.float32)[..., None]\n",
    "\n",
    "    @log_time\n",
    "    def generate_input_encoder(self,x_batch, vocabulary_encoder, max_words_per_phrase):\n",
    "\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")# here are string\n",
    "        \n",
    "        #print_matrix(x_train) \n",
    "        \n",
    "        xi = []\n",
    "        # print(x_batch)\n",
    "        phrase_vectors_x_i = [re.findall(regex_str, x) for x in x_train]\n",
    "        \n",
    "        phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x_i]\n",
    "\n",
    "\n",
    "        indices = cp.array([[vocabulary_encoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "        mask = (indices != vocabulary_encoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        #print(phrase_vectors_x) \n",
    "       \n",
    "        # print(\"input_encoder:\")\n",
    "        # self.print_matrix(phrase_vectors_x)\n",
    "        xi = cp.array([[vocabulary_encoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "        return xi,phrase_vectors_x_i,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_input_encoder(self,X, vocabulary_encoder, max_words_per_phrase, embedding_size):\n",
    "\n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        #print(pos_encoding)\n",
    "        inputs_e,input_e_words,mask = self.generate_input_encoder(X, vocabulary_encoder, max_words_per_phrase)\n",
    "        \n",
    "        #print(inputs_e)\n",
    "\n",
    "        inputs_e =inputs_e + pos_encoding\n",
    "        return inputs_e,input_e_words,mask\n",
    "    \n",
    "    def generate_target(self,x_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "        target_vector = cp.array([[self.get_one_hot(i,vocabulary) for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    def generate_target_sparse_categorical(self,y_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(y_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "\n",
    "        target_vector = cp.array([[vocabulary[i][1] for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target_sparse(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target_sparse_categorical(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    @log_time\n",
    "    def create_decoder_input(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        indices = cp.array([[vocabulary_decoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        mask = (indices != vocabulary_decoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "   \n",
    "        yi = yi + pos_encoding\n",
    "      \n",
    "        return yi,phrase_vectors_y,mask\n",
    "    @log_time\n",
    "    def create_decoder_input_teacher_forcing(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        # for sentence in phrase_vectors_y:\n",
    "        #     print(sentence)\n",
    "        #print_matrix(phrase_vectors_y)\n",
    "        \n",
    "       \n",
    "\n",
    "        # print(\"decoder_input:\")\n",
    "        # self.print_matrix(decoder_input)\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        # print(pos_encoding.shape,yi.shape)\n",
    "        yi = yi + pos_encoding\n",
    "        #print_matrix(yi)\n",
    "        # decoder_inputs = cp.array(cp.swapaxes(self.create_timestaped_input(yi, max_words_per_phrase), 0, 1))\n",
    "        \n",
    "        # # decoder_inputs[zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "        # for i in range(decoder_inputs.shape[0]):\n",
    "        #     for j in range(decoder_inputs[i].shape[0]):\n",
    "        #         zero_rows = cp.all(decoder_inputs[i][j] == 0, axis=1)\n",
    "\n",
    "        #         decoder_inputs[i][j][zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "\n",
    "        # decoder_inputs = cp.array(decoder_inputs)\n",
    "        #print(decoder_inputs[2])\n",
    "        #print(decoder_inputs)\n",
    "        return yi,phrase_vectors_y\n",
    "    # @log_time\n",
    "    def update_wembedding_encoder(self,learning_rate, x_batch, dLoss_dWemb_encoder, vocabulary, max_words_per_phrase):\n",
    "        \n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n",
    "\n",
    "        phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n",
    "        phrase_vectors_x = [i[:max_words_per_phrase] for i in phrase_vectors_x]\n",
    "\n",
    "        for phrase in range(dLoss_dWemb_encoder.shape[0]):\n",
    "            for position, word in enumerate(phrase_vectors_x[phrase]):\n",
    "                # Retrieve current embedding\n",
    "                current_embedding, index = vocabulary[word]\n",
    "\n",
    "                # Calculate the updated embedding using the gradient\n",
    "                updated_embedding = current_embedding - learning_rate * dLoss_dWemb_encoder[phrase][position]\n",
    "\n",
    "                # Update the vocabulary with the new embedding\n",
    "                vocabulary[word] = (updated_embedding, index)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "\n",
    "    # @log_time\n",
    "    def update_wembedding_decoder(self, learning_rate,y_batch, dLoss_dWemb_decoder, vocabulary,max_words_per_phrase):\n",
    "        decoder_input = self.pad_sequences(y_batch, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        decoder_input = [i.split() for i in decoder_input]\n",
    "\n",
    "        if max_words_per_phrase is None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[:max_words_per_phrase] for i in decoder_input]\n",
    "\n",
    "        for phrase in range(dLoss_dWemb_decoder.shape[0]):\n",
    "            for position, word in enumerate(phrase_vectors_y[phrase]):\n",
    "                # Retrieve current embedding for the word\n",
    "                current_embedding, index = vocabulary[word]\n",
    "\n",
    "                # Apply the gradient update\n",
    "                updated_embedding = current_embedding - learning_rate * dLoss_dWemb_decoder[phrase][position]\n",
    "\n",
    "                # Update the vocabulary with the new embedding\n",
    "                vocabulary[word] = (updated_embedding, index)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "  \n",
    "    # @log_time\n",
    "    def get_one_hot(self,word, vocabulary_decoder):\n",
    "        # print(word)\n",
    "        vocab_size = len(vocabulary_decoder)\n",
    "        one_hot_vector = cp.zeros(vocab_size)\n",
    "        one_hot_vector[vocabulary_decoder[word][1]] = 1\n",
    "        # print(vocabulary_decoder[word][1])\n",
    "        # print(np.where(one_hot_vector== 1))\n",
    "        # print(cp.sum(one_hot_vector))\n",
    "        return one_hot_vector\n",
    " \n",
    "    \n",
    "    def log_sparse_entropy(self,ans,target,y_batch,step):\n",
    "        #print(\"target\",target)\n",
    "        #print(\"ans\",ans)\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans)\n",
    "        print(f\"----DECODER--step {step}---\")\n",
    "        self.print_matrix(y_batch)\n",
    "        print(\"target\",target)\n",
    "        indexes=[]\n",
    "        yy=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in y_batch] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values)\n",
    "            indexes.append(max_index)\n",
    "             \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "            print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {max_index}\")\n",
    "        print(\"indexes\",indexes)\n",
    "        print(\"accuracy batch:\",round(counter_found/total_lenght,2))\n",
    "        \n",
    "    def accruacy_sparse_entropy(self,ans,target):\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans) \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values) \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "             \n",
    "        accuracy_batch_on_step=round(counter_found/total_lenght,2)\n",
    "        return accuracy_batch_on_step\n",
    "    \n",
    "\n",
    "    def print_target_vs_prediction_sparce_loss(self,ans,target): \n",
    "        indexes=[] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = np.argmax(values).item()\n",
    "            indexes.append(max_index) \n",
    "        print(\"target\",target)\n",
    "        print(\"indexes\",indexes)\n",
    "        \n",
    "  \n",
    "def clip_gradient(gradient,threshold):\n",
    "    return cp.clip(gradient, -threshold, threshold)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class layer_dropout: \n",
    "\n",
    "    def __init__(self,dropout_rate=0.1):\n",
    "        self.dropout_rate=dropout_rate \n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self,X):   \n",
    "        self.mask = (cp.random.rand(*X.shape) > self.dropout_rate)#.astype(cp.float64)\n",
    "        result = X * self.mask \n",
    "        #print(self.mask )\n",
    "        return result\n",
    "    #\n",
    "    def grad(self, X):\n",
    "        # Only pass gradients through neurons that were not dropped out\n",
    "        grad_input = X * self.mask\n",
    "        grad_input = clip_gradient(grad_input, 1)\n",
    "        return grad_input\n",
    "\n",
    "class layer_normalization:\n",
    "    def __init__(self, threshold, epsilon=0.0001):\n",
    "        self.epsilon = epsilon\n",
    "        self.mu = 0\n",
    "        self.var = 0\n",
    "        self.N = None\n",
    "        self.beta = None\n",
    "        self.alpha = None\n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilonopt = 1e-8\n",
    "        self.t = 0 \n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.N = x.shape[-1]\n",
    "        \n",
    "        # Initialize parameters if not done\n",
    "        if self.alpha is None:\n",
    "            self.alpha = cp.ones(self.N)\n",
    "            self.beta = cp.zeros(self.N)\n",
    "            self.m_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.v_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.m_Walpha = cp.zeros_like(self.alpha)\n",
    "            self.v_Walpha = cp.zeros_like(self.alpha)\n",
    "\n",
    "        # Forward computation\n",
    "        self.mu = cp.mean(x, axis=-1, keepdims=True)\n",
    "        self.var = cp.var(x, axis=-1, keepdims=True)\n",
    "        self.std = cp.sqrt(self.var + self.epsilon)\n",
    "        self.x_norm = (x - self.mu) / self.std\n",
    "        \n",
    "        return self.alpha * self.x_norm + self.beta\n",
    "\n",
    "    def dL_dNorm(self):\n",
    "        self.dL_dnorm_ = self.dLoss_dy * self.alpha\n",
    "        return self.dL_dnorm_\n",
    "\n",
    "    def dL_dsigma(self):\n",
    "        self.dL_dsigma_ = (-0.5)*cp.sum(self.dx_norm*(self.x-self.mu)*((self.var+self.epsilon)**(-1.5)),axis=-1,keepdims=True)\n",
    "        return self.dL_dsigma_\n",
    "    \n",
    "    def dSigma_dmu(self):\n",
    "        return (-2/self.N)*(self.x-self.mu)\n",
    "    \n",
    "    def dL_dmu(self):\n",
    "        a = -1*cp.sum(self.dx_norm*(1/cp.sqrt(self.var+self.epsilon)),axis=-1,keepdims=True)\n",
    "        b = -2*self.dL_dsigma_*cp.sum((1/self.N)*(self.x-self.mu),axis=-1,keepdims=True)\n",
    "        self.dL_dmu_=a+b\n",
    "        return self.dL_dmu_\n",
    "         \n",
    "    def dL_dx(self): \n",
    "        self.dL_dx_=self.dx_norm*self.dNorm_dx()+self.dL_dsigma()*self.dSigma_dx()+self.dL_dmu()*(1/self.N)\n",
    "        return self.dL_dx_\n",
    "    \n",
    "    def dNorm_dx(self):\n",
    "        return 1/cp.sqrt(self.var+self.epsilon)\n",
    "\n",
    "    def dSigma_dx(self):\n",
    "        return (2/self.N)*(self.x-self.mu)\n",
    "         \n",
    "    def backpropagation(self, dLoss_dy):\n",
    "        self.dLoss_dy = dLoss_dy\n",
    "        self.dx_norm = dLoss_dy * self.alpha \n",
    "        return self.dL_dx()\n",
    "    \n",
    "   \n",
    "    def dL_dalpha(self):\n",
    "        result = self.dLoss_dy * self.x_norm\n",
    "        result=cp.sum(cp.sum(result,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.alpha.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "\n",
    "    def dL_dbeta(self):\n",
    "        result = cp.sum(cp.sum(self.dLoss_dy,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.beta.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "     \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    def params_update(self, learning_rate):\n",
    "\n",
    "         \n",
    "        self.t += 1\n",
    "        \n",
    "        # Update beta\n",
    "        dbeta = self.dL_dbeta()\n",
    "        self.m_Wbeta = self.beta1 * self.m_Wbeta + (1 - self.beta1) * dbeta\n",
    "        self.v_Wbeta = self.beta2 * self.v_Wbeta + (1 - self.beta2) * cp.square(dbeta)\n",
    "        \n",
    "        m_W_hat = self.m_Wbeta / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wbeta / (1 - self.beta2 ** self.t)\n",
    "        self.beta -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "        \n",
    "        # Update alpha\n",
    "        dalpha = self.dL_dalpha()\n",
    "        self.m_Walpha = self.beta1 * self.m_Walpha + (1 - self.beta1) * dalpha\n",
    "        self.v_Walpha = self.beta2 * self.v_Walpha + (1 - self.beta2) * cp.square(dalpha)\n",
    "        \n",
    "        m_W_hat = self.m_Walpha / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Walpha / (1 - self.beta2 ** self.t)\n",
    "        self.alpha -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "\n",
    "       \n",
    "        \n",
    "class linear_layer: \n",
    "    def __init__(self,input_size,output_size,out=False,only_weights=False,threshold=1):\n",
    "\n",
    "        variance = 2 / (input_size + output_size)  # Variance for Glorot normal initializer\n",
    "       \n",
    "        self.W = cp.random.normal(0, cp.sqrt(variance), (input_size, output_size))\n",
    "          \n",
    "        if not only_weights:\n",
    "            self.b = cp.random.normal(0, cp.sqrt(variance), (output_size,))\n",
    "        \n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0  # Time step for Adam updates\n",
    "        \n",
    "        # Initialize first (m) and second (v) moment vectors for weights and biases\n",
    "        self.m_W = cp.zeros_like(self.W)\n",
    "        self.v_W = cp.zeros_like(self.W)\n",
    "        if not only_weights:\n",
    "            self.m_b = cp.zeros_like(self.b)\n",
    "            self.v_b = cp.zeros_like(self.b)\n",
    "      \n",
    "    def forward(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) + self.b \n",
    "        return Xout\n",
    "    \n",
    "    def forward_weights_only(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) \n",
    "        return Xout\n",
    "     \n",
    "    def grad(self,dL_dy):\n",
    "        self.dL_dy = dL_dy\n",
    "        # print(\"self.dL_dy\",self.dL_dy)\n",
    "        return self.dL_dy@self.W.T\n",
    "    \n",
    "    def dLoss_dW(self):\n",
    "        return cp.mean(cp.transpose(self.dL_dy,(0,2,1))@self.x,axis=0).T\n",
    "    \n",
    "    def dLoss_db(self):\n",
    "        return cp.mean(cp.mean(self.dL_dy,axis=0))\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "        db = self.dLoss_db()  \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_b = self.beta1 * self.m_b + (1 - self.beta1) * db\n",
    "        self.v_b = self.beta2 * self.v_b + (1 - self.beta2) * cp.square(db)\n",
    "        # Correct bias in first and second moment for biases\n",
    "        m_b_hat = self.m_b / (1 - self.beta1 ** self.t)\n",
    "        v_b_hat = self.v_b / (1 - self.beta2 ** self.t)\n",
    "        # Update biases using Adam\n",
    "         \n",
    "        #print(up.shape,self.b.shape,db.shape)\n",
    "        self.b -= learning_rate * m_b_hat / (cp.sqrt(v_b_hat) + self.epsilon)\n",
    "\n",
    "    def update_weights_only(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights only\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "class AdamOptimize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_block:\n",
    "    def __init__(self,embedding_size,hidden_size,clipping_threshold):\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.linear_layer_1=linear_layer(self.embedding_size,self.hidden_size,threshold=clipping_threshold)\n",
    "        self.linear_layer_2=linear_layer(self.hidden_size,self.embedding_size,threshold=clipping_threshold)\n",
    "        self.dropout=layer_dropout()\n",
    "        self.ReLu=ReLu_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_1=self.linear_layer_1.forward(x)\n",
    "        x_1_r=self.ReLu.forward(x_1)\n",
    "        #x_1_rd=self.dropout.forward(x_1_r)\n",
    "        x_2=self.linear_layer_2.forward(x_1_r)\n",
    "        return x_2\n",
    "    \n",
    "    def grad(self,dL_dy):\n",
    "        dL_dx_1_rd=self.linear_layer_2.grad(dL_dy)\n",
    "        #dL_dx_1_r=self.dropout.grad(dL_dx_1_rd)\n",
    "        dL_dx_1=self.ReLu.backward(dL_dx_1_rd)\n",
    "        dL_dx=self.linear_layer_1.grad(dL_dx_1)\n",
    "        return dL_dx\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.linear_layer_1.update_weights(learning_rate)\n",
    "        self.linear_layer_2.update_weights(learning_rate)\n",
    "        \n",
    " \n",
    "class ReLu_layer:\n",
    "    def __init__(self,alpha=0.0001):\n",
    "        self.alpha=alpha \n",
    "    def forward_leaky(self,X):\n",
    "        self.X=X\n",
    "        return cp.where(X > 0, X, self.alpha * X)\n",
    "\n",
    "    def forward(self,X): \n",
    "        self.X=X\n",
    "        return cp.maximum(0,self.X)\n",
    "    \n",
    "    def backward(self, dLoss): \n",
    "        # Gradient of ReLU is 1 for x > 0, else 0\n",
    "        dx = dLoss * (self.X > 0)  # Only propagate gradients for inputs > 0\n",
    "        return dx\n",
    "    \n",
    "    def backward_leaky(self, dLoss): \n",
    "        dx = dLoss * cp.where(self.X > 0, 1, self.alpha)  # Gradient: 1 for x > 0, else alpha\n",
    "        return dx\n",
    "\n",
    "class residual_layer:\n",
    "    def __init__(self,threshold):\n",
    "        self.dropout=layer_dropout()\n",
    "        self.normalization=layer_normalization(threshold=threshold)\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "\n",
    "    def forward(self,x,sublayer_output): \n",
    "        residual=self.dropout.forward(sublayer_output)+x\n",
    "        result=self.normalization.forward(residual)\n",
    "        return result\n",
    "    \n",
    "    def grad(self, dL_dy):\n",
    "        dl_dNorm = self.normalization.backpropagation(dL_dy)\n",
    "        \n",
    "        # Optional: Scale gradients by 1/sqrt(2) to help with training stability\n",
    "        scaling_factor = 1.0 / np.sqrt(2.0)\n",
    "        sublayer_grad = self.dropout.grad(dl_dNorm) * scaling_factor\n",
    "        residual_grad = dl_dNorm * scaling_factor\n",
    "        \n",
    "        return sublayer_grad, residual_grad\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.normalization.params_update(learning_rate)\n",
    "\n",
    "\n",
    "      \n",
    "class multihead_attention: \n",
    "    def __init__(self,embedding_size,num_heads,batch_size,threshold):\n",
    "        self.num_heads=num_heads\n",
    "        self.dk=embedding_size//num_heads\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.q=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.k=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.v=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.projection_layer=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold) \n",
    "        self.helper=Helper()\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0 \n",
    "        self.m_Wq = cp.zeros_like(self.q.W)\n",
    "        self.v_Wq = cp.zeros_like(self.q.W)\n",
    "\n",
    "        self.m_Wk = cp.zeros_like(self.k.W)\n",
    "        self.v_Wk = cp.zeros_like(self.k.W)\n",
    "\n",
    "        self.m_Wv = cp.zeros_like(self.v.W)\n",
    "        self.v_Wv = cp.zeros_like(self.v.W)\n",
    "         \n",
    "    def reshape_heads(self,Q,K,V):\n",
    "        self.Q = cp.swapaxes(cp.array(np.array_split(Q, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Qval.shape: \",Q_E.shape)\n",
    "        self.K = cp.swapaxes(cp.array(np.array_split(K, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Kval.shape: \",K_E.shape)\n",
    "        self.V = cp.swapaxes(cp.array(np.array_split(V, self.num_heads, axis=2)), 0, 1)\n",
    "        #return self.Q,self.K,self.V\n",
    "\n",
    "    def QKV(self,input_q,input_k,input_v): \n",
    "        Q=self.q.forward_weights_only(input_q)\n",
    "        K=self.k.forward_weights_only(input_k)\n",
    "        V=self.v.forward_weights_only(input_v) \n",
    "        self.reshape_heads(Q,K,V)\n",
    "        \n",
    "\n",
    "    def attention_weights(self): \n",
    "        QKscaled =cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])  \n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "         \n",
    "\n",
    "    def forward_attention(self,input_q,input_k,input_v): \n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v\n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights()\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def forward_masked_attention(self,input_q,input_k,input_v,mask_size):\n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v \n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights_masked(mask_size)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def attention_weights_masked(self,mask_size):\n",
    "        #mask_size =  words_per_phrase \n",
    "\n",
    "        QKscaled = cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])\n",
    "        mask = cp.tril(cp.ones((mask_size, mask_size)))  # (9, 9) lower triangular matrix\n",
    "        mask[mask == 0]=-cp.inf  # Set future tokens to -inf\n",
    "        mask[mask == 1]=0  # Set allowed tokens to 0\n",
    "        self.mask = mask.reshape(1, 1, mask_size, mask_size)\n",
    "        QKscaled = QKscaled + self.mask\n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "        \n",
    "    \n",
    "    def diffQi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_dX=cp.transpose(dAttention, (0, 2, 1)) @ (self.helper.redimension(dAttention_weights @ (self.K * self.V) / cp.sqrt(self.K.shape[-1]))*self.input_q)\n",
    "        self.dLoss_Qi= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffKi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        X = cp.swapaxes(cp.array(cp.array_split(self.input_k, self.num_heads, axis=2)), 0, 1) \n",
    "         \n",
    "        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ self.helper.redimension(\n",
    "            (dAttention_weights * (self.Q @ cp.transpose(self.V, (0, 1, 3, 2))) @ X) / cp.sqrt(self.K.shape[-1])) \n",
    "        self.dLoss_Ki= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffVi(self,dAttention):\n",
    "        self.dLoss_Vi = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ (\n",
    "                self.Attention_weights @ cp.expand_dims(self.input_v, axis=1)), axis=1), axis=0)\n",
    "       \n",
    "\n",
    "\n",
    "    def diffKInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "         \n",
    "        \n",
    "        A = self.helper.redimension(self.V)@self.k.W\n",
    "         \n",
    "        B = self.helper.redimension(dAttention_weights@self.K)\n",
    "         \n",
    "        C=cp.transpose(dAttention,(0,2,1))@B\n",
    "       \n",
    "        dLoss_KI=cp.transpose((C@cp.transpose(A,(0,2,1))),(0,2,1))\n",
    "        #print(\"dLoss_KI.shape\",dLoss_KI.shape)\n",
    "        \n",
    "        return dLoss_KI\n",
    "    \n",
    "    def diffVInput(self,dAttention):\n",
    "        dLoss_V_E = cp.transpose(\n",
    "        cp.mean(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ self.Attention_weights, axis=1), (0, 2, 1))\n",
    "        dLossVI = dLoss_V_E @ self.v.W\n",
    "        #print(\"dLossVI.shape\",dLossVI.shape)\n",
    "        return dLossVI\n",
    "    \n",
    "    def diffQInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        \n",
    "         \n",
    "        A1=self.helper.redimension(dAttention_weights @ (self.K*self.V / cp.sqrt(self.K.shape[-1])))@self.q.W\n",
    "   \n",
    "        dLoss_QI=dAttention*A1\n",
    "        #print(\"dLoss_QI.shape\",dLoss_QI.shape)\n",
    "        return dLoss_QI\n",
    "    \n",
    "    def grad(self,dL_dy): \n",
    "        self.dLoss_dAcr=self.projection_layer.grad(dL_dy)\n",
    "        self.diffQi(self.dLoss_dAcr)\n",
    "        self.diffVi(self.dLoss_dAcr)\n",
    "        self.diffKi(self.dLoss_dAcr)\n",
    "\n",
    "        dLoss_KI=self.diffKInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_QI=self.diffQInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_VI=self.diffVInput(self.dLoss_dAcr)\n",
    "       \n",
    "        return dLoss_QI,dLoss_KI,dLoss_VI\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_Wq = self.beta1 * self.m_Wq + (1 - self.beta1) * self.dLoss_Qi\n",
    "        self.v_Wq = self.beta2 * self.v_Wq + (1 - self.beta2) * cp.square(self.dLoss_Qi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wq / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wq / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.q.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_Wk = self.beta1 * self.m_Wk + (1 - self.beta1) * self.dLoss_Ki\n",
    "        self.v_Wk = self.beta2 * self.v_Wk + (1 - self.beta2) * cp.square(self.dLoss_Ki)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wk / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wk / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.k.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "        self.m_Wv = self.beta1 * self.m_Wv + (1 - self.beta1) * self.dLoss_Vi\n",
    "        self.v_Wv = self.beta2 * self.v_Wv + (1 - self.beta2) * cp.square(self.dLoss_Vi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wv / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wv / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.v.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "\n",
    "        self.projection_layer.update_weights_only(learning_rate)\n",
    "        # self.q.W= self.q.W-self.dLoss_Qi*learning_rate\n",
    "        # self.k.W= self.k.W-self.dLoss_Ki*learning_rate\n",
    "        # self.v.W= self.v.W-self.dLoss_Vi*learning_rate\n",
    "        # print(\"self.q.W\",self.q.W)\n",
    "        # print(\"self.k.W\",self.k.W)\n",
    "        # print(\"self.v.W\",self.v.W)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_punctuation(input_str):\n",
    "    return re.sub(r'[^\\w\\s]', '', input_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73351bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2627 Olivia and Olivier are voting for liberals in this election\n",
      "Vocabulary loaded from file.\n",
      "vocabulary size 12491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "min_v = 10\n",
    "max_v = 13\n",
    "helper=Helper()\n",
    "def load_x_y_train_plain():\n",
    "    with open('corpus/train.json', 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            dataset = json.load(f)  # Load the JSON data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # #Loop through the list and process each dialogue and summary\n",
    "    for data in dataset:\n",
    "        dialogue = data['dialogue']  # Split dialogue into a list of lines\n",
    "        summary = data['summary']\n",
    "\n",
    "        X_train.append(remove_punctuation(dialogue))\n",
    "        y_train.append(remove_punctuation(summary))\n",
    "    return X_train, y_train\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# with open('data/vocabolary_full.pkl', 'rb') as f:\n",
    "#     vocabulary=pickle.load(f)\n",
    "def filter_train_data(X_train, y_train, to_eliminate):\n",
    "    filtered_X_train = []\n",
    "    filtered_y_train = []\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if not any(to_eliminate_str in x for to_eliminate_str in to_eliminate):\n",
    "             \n",
    "            filtered_X_train.append(remove_punctuation(x))\n",
    "            filtered_y_train.append(remove_punctuation(y))\n",
    "\n",
    "    return filtered_X_train, filtered_y_train\n",
    "\n",
    "\n",
    "def create_complete_vocabulary(X_train, y_train,max_v):\n",
    "    nlp_model = spacy.load('en_core_web_lg')\n",
    "    nlp_model.disable_pipes([\"parser\", \"ner\"])\n",
    "    complete_text_target = ' '.join(y_train)\n",
    "    complete_text_origin = ' '.join(X_train)\n",
    "    complete_text = complete_text_target + \" [START] [PAD] [END] \" + complete_text_origin\n",
    "\n",
    "    vocabulary = helper.create_vocabulary(complete_text, f\"vocabolary_full{max_v}\", nlp_model)\n",
    "    print(\"vocabulary size\", len(vocabulary))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "X_train, y_train = load_x_y_train_plain()\n",
    "# to_eliminate = [\n",
    "#     \"[I hope I'm not coming off as rude - If I am, I'm sorry. I just thought it would be beneficial for the both of us...]\",\n",
    "#     \"[pulls back the curtain and checks out the window]\",\n",
    "#     \"[hopefully, masses of]\"]\n",
    "# X_train, y_train = filter_train_data(X_train, y_train, to_eliminate)\n",
    "\n",
    "\n",
    "sample = [i for i in range(0,len(y_train))]\n",
    "\n",
    "\n",
    "X_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n",
    "y_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n",
    "\n",
    "\n",
    "X_train = [X_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "y_train = [y_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "\n",
    "\n",
    "# Calculate lengths of the tokenized phrases\n",
    "\n",
    "\n",
    "def plot_lenghts(X_train,y_train):\n",
    "    X_lengths = [len(x) for x in X_train]\n",
    "    y_lengths = [len(y) for y in y_train]\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for X_train lengths\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(X_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of X_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for y_train lengths\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(y_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of y_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#X_train=[i[::-1] for i in y_train]\n",
    "plot_lenghts(X_train,y_train)\n",
    " \n",
    "\n",
    "X_train=[\" \".join(x) for x in X_train]\n",
    "y_train=[\" \".join(y) for y in y_train]\n",
    "\n",
    "print(len(y_train),y_train[0])\n",
    "\n",
    "vocabulary=create_complete_vocabulary(X_train, y_train,max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e4a140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olivia and Olivier are voting for liberals in this election',\n",
       " 'Olivia Who are you voting for in this election \\n Oliver Liberals as always \\n Olivia Me too \\n Oliver Great')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0],X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c7d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.batch_size=batch_size\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.num_heads=num_heads\n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        self.multihead_attention_encoder=multihead_attention(num_heads=2,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.residual_layer_1=residual_layer(clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "         \n",
    "        self.helper=Helper()\n",
    "     \n",
    "\n",
    "    def forward(self,inputs_e):\n",
    "        self.inputs_e=inputs_e \n",
    "\n",
    "        PrjAe=self.multihead_attention_encoder.forward_attention(inputs_e,inputs_e,inputs_e)\n",
    "        \n",
    "        Ect1=self.residual_layer_1.forward(PrjAe,inputs_e) \n",
    "\n",
    "        FLe2=self.fully_connected_block.forward(Ect1) \n",
    "\n",
    "        Ecout=self.residual_layer_2.forward(FLe2,Ect1)\n",
    "\n",
    "        return Ecout\n",
    "    \n",
    "    def backpropagation(self,dL_Ecout): \n",
    "        \n",
    "        dL_dFLe2,dL_dEct1_residual=self.residual_layer_2.grad(dL_Ecout)\n",
    "        \n",
    "        #print(\"dL_dFLe2\",dL_dFLe2)\n",
    "        #print(\"dL_dEct1_residual\",dL_dFLe2)\n",
    "        \n",
    "\n",
    "        dL_dEct1=self.fully_connected_block.grad(dL_dFLe2)+dL_dEct1_residual\n",
    "        #print(\"dL_dEct1\",dL_dEct1)\n",
    "        \n",
    "        dL_dPrjAe,dL_inputs_e_residual=self.residual_layer_1.grad(dL_dEct1)\n",
    "        #print(\"dL_dPrjAe\",dL_dPrjAe)\n",
    "        #print(\"dL_inputs_e_residual\",dL_inputs_e_residual)\n",
    "        dL_inputs_e_q,dL_inputs_e_k,dL_inputs_e_v=self.multihead_attention_encoder.grad(dL_dPrjAe)\n",
    "        \n",
    "        dL_inputs_e=dL_inputs_e_residual+dL_inputs_e_q+dL_inputs_e_k+dL_inputs_e_v\n",
    "\n",
    "        #dL_inputs_e=clip_gradient(dL_inputs_e,self.clipping_threshold)\n",
    "        #print(\"dL_inputs_e\",dL_inputs_e_residual)\n",
    "        dLoss_dWemb_encoder = dL_inputs_e * self.inputs_e\n",
    "        return dL_inputs_e,dLoss_dWemb_encoder\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate,vocabulary):\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_encoder.update_weights(learning_rate)\n",
    "        \n",
    "        # input_e=self.inputs_e-learning_rate*dLoss_dWemb_encoder\n",
    "        # vocabulary=self.helper.update_wembedding_encoder(X_batch,input_e,vocabulary,self.words_per_phrase)\n",
    "        return vocabulary\n",
    "        \n",
    "\n",
    "  \n",
    "      \n",
    "     \n",
    "class Decoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.batch_size=batch_size\n",
    "        self.num_heads=num_heads \n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size  \n",
    "        self.multihead_cross_attention=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.multihead_attention_decoder=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "        self.helper=Helper() \n",
    "        self.residual_layer_1=residual_layer(threshold=clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(threshold=clipping_threshold) \n",
    "        self.residual_layer_3=residual_layer(threshold=clipping_threshold) \n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        \n",
    "\n",
    "    def forward(self,inputs_decoder,Ecout):\n",
    "        self.inputs_decoder=inputs_decoder \n",
    "        \n",
    "        PrjA_mask=self.multihead_attention_decoder.forward_masked_attention(inputs_decoder,inputs_decoder,inputs_decoder,mask_size=inputs_decoder.shape[1])\n",
    " \n",
    "        Dt1=self.residual_layer_1.forward(self.inputs_decoder,PrjA_mask)\n",
    " \n",
    "        PrjAcr=self.multihead_cross_attention.forward_attention(Dt1,Ecout,Ecout)\n",
    "   \n",
    "        Dt2=self.residual_layer_2.forward(PrjAcr,Dt1)\n",
    " \n",
    "        FLd2=self.fully_connected_block.forward(Dt2)\n",
    "      \n",
    "        Dout=self.residual_layer_3.forward(FLd2,Dt2)  \n",
    "\n",
    "        return Dout\n",
    "    \n",
    "    # def output(self,Dout):\n",
    "    #     SigmaZout=self.helper.softmax(self.final_projection_layer.forward(Dout))\n",
    "    #     return SigmaZout\n",
    "\n",
    "\n",
    "    def backpropagation(self,dL_dDout): \n",
    "\n",
    "        dL_FLd2,dL_Dt2_residual=self.residual_layer_3.grad(dL_dDout)\n",
    "\n",
    "        dL_Dt2=self.fully_connected_block.grad(dL_FLd2)+dL_Dt2_residual\n",
    "\n",
    "        dL_PrjAcr,dL_Dt1_residual=self.residual_layer_2.grad(dL_Dt2)\n",
    "\n",
    "        dL_Dt1_q,dL_DEcout_k,dL_DEcout_v=self.multihead_cross_attention.grad(dL_PrjAcr)\n",
    "\n",
    "        dL_Dt1=dL_Dt1_residual+dL_Dt1_q\n",
    "\n",
    "        dL_PrjA_mask,dL_inputs_decoder_residual=self.residual_layer_1.grad(dL_Dt1)\n",
    "\n",
    "        dL_inputs_decoder_q,dL_inputs_decoder_k,dL_inputs_decoder_v=self.multihead_attention_decoder.grad(dL_PrjA_mask)\n",
    "\n",
    "        dL_inputs_decoder=dL_inputs_decoder_residual+dL_inputs_decoder_q+dL_inputs_decoder_k+dL_inputs_decoder_v\n",
    "        \n",
    "        dL_Ecout=dL_DEcout_k+dL_DEcout_v\n",
    "        #dL_inputs_decoder=clip_gradient(dL_inputs_decoder,self.clipping_threshold)\n",
    "        dLoss_dWemb_decoder= dL_inputs_decoder * self.inputs_decoder\n",
    "        \n",
    "        return dL_Ecout,dL_inputs_decoder,dLoss_dWemb_decoder\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate,vocabulary):\n",
    "        self.residual_layer_3.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.multihead_cross_attention.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_decoder.update_weights(learning_rate)\n",
    "        #dLoss_dWemb_decoder=clip_gradient(dLoss_dWemb_decoder,self.clipping_threshold)\n",
    "        # input_d=self.inputs_decoder-learning_rate*dLoss_dWemb_decoder\n",
    "        # vocabulary=self.helper.update_wembedding_decoder(y_batch,input_d,self.words_per_phrase,vocabulary) \n",
    "        return vocabulary\n",
    "\n",
    "class output_stack:\n",
    "    def __init__(self,embedding_size,vocabulary_size,threshold,temperature=1):\n",
    "        self.final_projection_layer=linear_layer(embedding_size,vocabulary_size,threshold=threshold,out=True)\n",
    "        self.clipping_threshold=threshold\n",
    "        self.temperature=temperature\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp((x - max_logits) / self.temperature)  # Apply temperature\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        SoftmaxOutput=self.softmax(self.final_projection_layer.forward(x)) \n",
    "        return SoftmaxOutput\n",
    "\n",
    "    \n",
    "    # def cross_entropy_loss(self,SigmaZout, target):\n",
    "    #     epsilon = 1e-12  # Small constant to avoid log(0)\n",
    "    #     SigmaZout = cp.clip(SigmaZout, epsilon, 1 - epsilon)  # Clipping predictions\n",
    "    #     return -cp.sum(target * cp.log(SigmaZout), axis=1).mean() \n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        epsilon = 1e-12\n",
    "        return -np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=-1))\n",
    "    \n",
    "    def grad_cross_entropy(self,softmax_output,target):\n",
    "        dL_dZ =softmax_output-target\n",
    "        dL_dDout=self.final_projection_layer.grad(dL_dZ)  \n",
    "        #dL_dDout=clip_gradient(dL_dDout,self.clipping_threshold)\n",
    "        return dL_dDout\n",
    "    \n",
    "    def sparse_categorical_crossentropy(self, probabilities, labels): \n",
    "        #print(\"probabilities.shape\", probabilities.shape)\n",
    "        #print(\"labels.shape\", labels.shape)\n",
    "        \n",
    "        # Unpack batch and sequence dimensions\n",
    "        batch_size, seq_length = labels.shape\n",
    "        \n",
    "        # Gather correct class probabilities for each position in the batch and sequence\n",
    "        correct_class_probs = probabilities[np.arange(batch_size)[:, None], np.arange(seq_length), labels] \n",
    "        \n",
    "        # Calculate the log loss and average it\n",
    "        loss = -np.log(correct_class_probs + 1e-8)\n",
    "        return np.mean(loss)\n",
    "    \n",
    "    def grad(self,dl_dy):\n",
    "        return self.final_projection_layer.grad(dl_dy)\n",
    "\n",
    "\n",
    "    def grad_sparse_cross_entropy(self, softmax_output, target):\n",
    "        dL_dZ = softmax_output.copy()  # Create a copy of the softmax output\n",
    "        \n",
    "        # Adjust indexing to handle both batch and sequence dimensions\n",
    "        batch_size, seq_length = target.shape\n",
    "        dL_dZ[np.arange(batch_size)[:, None], np.arange(seq_length), target] -= 1\n",
    "        \n",
    "        # Compute gradient through final projection layer\n",
    "        dL_dDout = self.final_projection_layer.grad(dL_dZ)  \n",
    "        # dL_dDout = clip_gradient(dL_dDout, self.clipping_threshold)\n",
    "        return dL_dDout\n",
    " \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.final_projection_layer.update_weights(learning_rate)  \n",
    "\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "    def __init__(self,num_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,words_per_phrase_decoder,clipping_threshold,vocabulary):\n",
    "        self.vocabulary=vocabulary\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.EncoderStack = [Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.DecoderStack = [Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_decoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.outout_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "\n",
    "    def forward(self,inputs_e,inputs_decoder,X_batch,y_batch):\n",
    "\n",
    "        self.X_batch=X_batch\n",
    "        self.y_batch=y_batch\n",
    "        Ecout=self.forward_encoder(inputs_e)\n",
    "        Dout=self.forward_decoder(Ecout,inputs_decoder)\n",
    "        #SigmaZout=self.outout_stack.forward(Dout) \n",
    "        return Dout\n",
    "    \n",
    "\n",
    "    def Loss(self,SigmaZout,target):\n",
    "        Loss=self.outout_stack.cross_entropy_loss(SigmaZout,target)\n",
    "        return Loss\n",
    "\n",
    "\n",
    "    def backpropagation(self,dL_dDout):\n",
    "        dL_Ecout,dLoss_dWemb_decoder_tot=self.backpropagation_decoder(dL_dDout)\n",
    "        dL_Ecout,dLoss_dWemb_encoder_tot=self.backpropagation_encoder(dL_Ecout)\n",
    "        return dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot\n",
    "\n",
    "    def forward_encoder(self,inputs_e):\n",
    "        for encoder_i in self.EncoderStack:\n",
    "            inputs_e=encoder_i.forward(inputs_e)\n",
    "        return inputs_e\n",
    "    \n",
    "    def forward_decoder(self,Ecout,inputs_decoder):\n",
    "        for decoder_i in self.DecoderStack:\n",
    "            inputs_decoder=decoder_i.forward(inputs_decoder,Ecout)\n",
    "        return inputs_decoder\n",
    "    \n",
    "    def backpropagation_decoder(self,dL_dDout):\n",
    "        tot_dL_dEcout=0\n",
    "        dLoss_dWemb_decoder_tot=0\n",
    "        for decoder_i in reversed(self.DecoderStack):\n",
    "            dL_Ecout_i,dL_dDout,dLoss_dWemb_decoder=decoder_i.backpropagation(dL_dDout)\n",
    "            tot_dL_dEcout+=dL_Ecout_i\n",
    "            dLoss_dWemb_decoder_tot+=dLoss_dWemb_decoder\n",
    "            self.vocabulary=decoder_i.update_weights(decoder_i.learning_rate,self.vocabulary)\n",
    "        return tot_dL_dEcout,dLoss_dWemb_decoder_tot\n",
    "    \n",
    "    def backpropagation_encoder(self,dL_Ecout): \n",
    "        dLoss_dWemb_encoder_tot=0\n",
    "        for encoder_i in reversed(self.EncoderStack):\n",
    "            dL_Ecout,dLoss_dWemb_encoder=encoder_i.backpropagation(dL_Ecout) \n",
    "            dLoss_dWemb_encoder_tot+=dLoss_dWemb_encoder \n",
    "            self.vocabulary=encoder_i.update_weights(encoder_i.learning_rate,self.vocabulary)\n",
    "        return dL_Ecout,dLoss_dWemb_encoder_tot\n",
    "   \n",
    " \n",
    "    #     self.inputs_decoder=self.inputs_decoder-self.learning_rate*dLoss_dWemb_decoder\n",
    "    #     vocabulary=self.helper.update_wembedding_decoder(y_batch,self.inputs_decoder,self.words_per_phrase,vocabulary) \n",
    "    #     return vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107b0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55dae219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Olivia Who are you voting for in this election \\n Oliver Liberals as always \\n Olivia Me too \\n Oliver Great',\n",
       " 'Olivia and Olivier are voting for liberals in this election')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9350b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2627, 12491)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a882c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "embedding_size=300\n",
    "fl1_size=2048\n",
    "batch_size=64\n",
    "num_heads=5\n",
    "dropout_rate=0.1\n",
    "words_per_phrase_encoder = 50\n",
    "words_per_phrase_decoder=max_v\n",
    "num_batches_per_epoch = len(X_train) // batch_size\n",
    "num_epochs=550\n",
    "tot_loss_epoch=0\n",
    "learning_rate=0.0001\n",
    "clipping_threshold=1e10\n",
    "tot_loss_epoch=0\n",
    "temperature=1\n",
    "encoder_seq_len=25\n",
    "decoder_seq_len=max_v\n",
    "\n",
    "\n",
    "n_layers=1\n",
    "Output_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "#encoder=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase,clipping_threshold)\n",
    "#decoder=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase,clipping_threshold)\n",
    "MyTransformer=Transformer(n_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,decoder_seq_len,clipping_threshold,vocabulary)\n",
    "output_linear_layer=linear_layer(embedding_size,len(vocabulary),out=True) \n",
    "accuracies=[0,0]\n",
    "mean_acc=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1d29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_from_vocabulary(word_index,vocabulary): \n",
    "    for word,(vector,position), in vocabulary.items():\n",
    "        if position==word_index:\n",
    "            return word\n",
    "        \n",
    "def training_accuracy_cross_entropy(SigmaZout,target_decoder):\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==np.argmax(target_decoder[n][l]): \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(target_decoder[n][l]),np.argmax(SigmaZout[n][l]))\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "    return np.mean(np.array(taccuracies))\n",
    "\n",
    "def training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder,vocabulary):\n",
    "    #print(SigmaZout.shape)\n",
    "    #print(target_decoder.shape)\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==target_decoder[n][l]: \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(SigmaZout[n][l]),target_decoder[n][l],print_word_from_vocabulary(np.argmax(SigmaZout[n][l]),vocabulary))\n",
    "            #print(\"-------------------------\")\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "    return np.mean(np.array(taccuracies))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbf5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0 mean accuracy 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550: 100%|| 41/41 [00:25<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 9.072595519520728 mean accuracy 0.09597795497185743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/550: 100%|| 41/41 [00:25<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 8.340985318112828 mean accuracy 0.11494488742964351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/550: 100%|| 41/41 [00:25<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.742099145819383 mean accuracy 0.11500351782363978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/550: 100%|| 41/41 [00:25<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.26651114241863 mean accuracy 0.1152673545966229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/550: 100%|| 41/41 [00:25<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 6.901987520469945 mean accuracy 0.11746599437148217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/550: 100%|| 41/41 [00:25<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 6.635415165065519 mean accuracy 0.12456027204502813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/550: 100%|| 41/41 [00:32<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 6.443397571956321 mean accuracy 0.13921787054409007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/550:  61%|    | 25/41 [00:22<00:14,  1.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m SigmaZout\u001b[38;5;241m=\u001b[39mOutput_stack\u001b[38;5;241m.\u001b[39mforward(Dout)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(SigmaZout.shape)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m batch_accuracy\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_accuracy_sparse_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSigmaZout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(batch_accuracy) \n\u001b[0;32m     34\u001b[0m Loss \u001b[38;5;241m=\u001b[39m Output_stack\u001b[38;5;241m.\u001b[39msparse_categorical_crossentropy(SigmaZout,target_decoder) \n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mtraining_accuracy_sparse_cross_entropy\u001b[1;34m(SigmaZout, target_decoder, vocabulary)\u001b[0m\n\u001b[0;32m     25\u001b[0m counter_beccate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(SigmaZout\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]): \n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSigmaZout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m==\u001b[39mtarget_decoder[n][l]: \n\u001b[0;32m     28\u001b[0m         counter_beccate\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m#print(np.argmax(SigmaZout[n][l]),target_decoder[n][l],print_word_from_vocabulary(np.argmax(SigmaZout[n][l]),vocabulary))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print(\"-------------------------\")\u001b[39;00m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:1719\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__array_function__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dials\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\cupy\\_sorting\\search.py:37\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the indices of the maximum along an axis.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# TODO(okuta): check type\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:1006\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.argmax\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:1023\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.argmax\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\_routines_statistics.pyx:107\u001b[0m, in \u001b[0;36mcupy._core._routines_statistics._ndarray_argmax\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\cub.pyx:499\u001b[0m, in \u001b[0;36mcupy.cuda.cub.cub_reduction\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\cub.pyx:548\u001b[0m, in \u001b[0;36mcupy.cuda.cub.cub_reduction\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\cub.pyx:200\u001b[0m, in \u001b[0;36mcupy.cuda.cub.device_reduce\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:518\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.astype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:586\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.astype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\_kernel.pyx:1350\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\_kernel.pyx:657\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_out_args_from_optionals\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\_dtype.pyx:112\u001b[0m, in \u001b[0;36mcupy._core._dtype._raise_if_invalid_cast\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dials\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\numpy\\core\\multiarray.py:503\u001b[0m, in \u001b[0;36mcan_cast\u001b[1;34m(from_, to, casting)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (keys,)\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mcan_cast)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcan_cast\u001b[39m(from_, to, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    505\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;124;03m    can_cast(from_, to, casting='safe')\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    613\u001b[0m \n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (from_,)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(550):\n",
    "    print(\"Loss\",tot_loss_epoch/num_batches_per_epoch,\"mean accuracy\",np.mean(np.array(accuracies)))#np.mean(np.array(accuracies))\n",
    "    tot_loss_epoch=0\n",
    "    total_accuracy_epoch=0\n",
    "    mean_acc=0\n",
    "    accuracies=[]\n",
    "    for i in tqdm(range(0,num_batches_per_epoch),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        #try: \n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]  \n",
    "        \n",
    "        inputs_e,input_e_words,mask_e=helper.create_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n",
    "        inputs_decoder,inputs_decoder_words,mask_d=helper.create_decoder_input(y_batch,embedding_size,decoder_seq_len,vocabulary) \n",
    "        target_decoder,target_decoder_words,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len) \n",
    "        # helper.print_matrix(\"input_e_words\",input_e_words)\n",
    "        # helper.print_matrix(\"mask_e\",mask_e)\n",
    "        # helper.print_matrix(\"inputs_decoder_words\",inputs_decoder_words)\n",
    "        # helper.print_matrix(\"mask_d\",mask_d)\n",
    "        # helper.print_matrix(\"target_decoder_words\",target_decoder_words)\n",
    "        # helper.print_matrix(\"mask_t\",mask_t)\n",
    "        #Ecout=encoder.forward(inputs_e)\n",
    "        #Dout=decoder.forward(inputs_decoder,Ecout) \n",
    "\n",
    "        Dout=MyTransformer.forward(inputs_decoder,inputs_decoder,X_batch,y_batch) \n",
    "\n",
    "        SigmaZout=Output_stack.forward(Dout)\n",
    "        #print(SigmaZout.shape)\n",
    "        batch_accuracy=training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder,vocabulary)\n",
    "        accuracies.append(batch_accuracy) \n",
    "        \n",
    " \n",
    "        Loss = Output_stack.sparse_categorical_crossentropy(SigmaZout,target_decoder) \n",
    "        #print(\"Loss\",Loss,\"Batch accuracy\",batch_accuracy)\n",
    "        tot_loss_epoch+=Loss\n",
    " \n",
    "        dL_dDout = Output_stack.grad_sparse_cross_entropy(SigmaZout,target_decoder) \n",
    "        \n",
    "        dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot=MyTransformer.backpropagation(dL_dDout)\n",
    "        #dL_Ecout,dL_inputs_decoder,dLoss_dWemb_decoder=decoder.backpropagation(dL_dDout)\n",
    "        #dL_inputs_e,dLoss_dWemb_encoder=encoder.backpropagation(dL_Ecout)\n",
    "      \n",
    "        \n",
    "        #_=decoder.update_weights(learning_rate,vocabulary) \n",
    "        #_=encoder.update_weights(learning_rate,vocabulary) \n",
    "        Output_stack.update_weights(learning_rate)\n",
    "        #vocabulary=helper.update_wembedding_decoder(0.00001,y_batch, dLoss_dWemb_decoder_tot,vocabulary, decoder_seq_len)\n",
    "        #vocabulary=helper.update_wembedding_encoder(0.00001,X_batch, dLoss_dWemb_encoder_tot,vocabulary,encoder_seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426995db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(j,k) in vocabulary.items():\n",
    "    #print(i,k)\n",
    "    if k==775:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "3,50,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 15, 300 #dAttention.shape \n",
    "3, 10, 15, 50 #dAttention_weights\n",
    "3, 10, 50, 30 #self.K\n",
    "3, 10, 50, 30 #self.V\n",
    "300, 300#k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebeffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)\n",
    "300, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)@self.k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36268ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 30#dAttention_weights@self.K\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 15, 300\n",
    "3, 15, 300#self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "3, 300, 300#dAttention*self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
