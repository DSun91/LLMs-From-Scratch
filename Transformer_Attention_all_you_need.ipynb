{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89336dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "import cupy as cp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "\n",
    "def log_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Execute the wrapped function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        # print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Helper: \n",
    "    \n",
    "    def get_positional_encoding(self,seq_len, d_model):\n",
    "        \"\"\"\n",
    "        Returns a non-learnable (sinusoidal) positional encoding.\n",
    "\n",
    "\n",
    "        seq_len: Length of the input sequence.\n",
    "        d_model: Dimension of the embeddings.\n",
    "        \"\"\"\n",
    "        pos = cp.arange(seq_len)[:, cp.newaxis]  # Shape: [seq_len, 1]\n",
    "        i = cp.arange(d_model)[cp.newaxis, :]  # Shape: [1, d_model]\n",
    "\n",
    "        angle_rates = 1 / cp.power(10000, (2 * (i // 2)) / cp.float32(d_model))\n",
    "\n",
    "        # Apply sine to even indices, cosine to odd indices\n",
    "        pos_encoding = cp.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = cp.sin(pos * angle_rates[:, 0::2])  # sine on even indices\n",
    "        pos_encoding[:, 1::2] = cp.cos(pos * angle_rates[:, 1::2])  # cosine on odd indices\n",
    "\n",
    "        return pos_encoding\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Subtract the max value for numerical stability\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp(x - max_logits)\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "\n",
    " \n",
    "    # @log_time\n",
    "    def pad_sequence(self,seq, max_len, pad_value=0):\n",
    "        \"\"\"Pad a sequence with a given value up to max_len.\"\"\"\n",
    "        current_len = seq.shape[0]\n",
    "        pad_width = max_len - current_len\n",
    "        if pad_width > 0:\n",
    "            # Pad sequence with zeros (or any pad_value you provide)\n",
    "            seq = cp.pad(seq, ((0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n",
    "        return seq\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_timestaped_input(self,input_d, words_per_phrase):\n",
    "        input_translation = []\n",
    "        for j in range(input_d.shape[0]):\n",
    "            # Create padded sequences\n",
    "            padded_sequences = [self.pad_sequence(input_d[j][0:i], words_per_phrase) for i in range(1, input_d.shape[1] + 1)]\n",
    "            input_translation.append(padded_sequences)\n",
    "        return cp.array(input_translation)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    def redimension(self,X):\n",
    "        return cp.concatenate(cp.swapaxes(X, 0, 1), axis=-1)\n",
    "    \n",
    "    @log_time\n",
    "    def create_vocabulary(self,complete_text, name, nlp):\n",
    "        vocabulary_file = f\"data/{name}.pkl\"\n",
    "        try:\n",
    "            with open(vocabulary_file, 'rb') as handle:\n",
    "                vocabulary = pickle.load(handle)\n",
    "                print(\"Vocabulary loaded from file.\")\n",
    "                return vocabulary\n",
    "        except FileNotFoundError:\n",
    "            print(\"Vocabulary file not found, creating a new one.\")\n",
    "        # Use re.findall to split considering punctuation\n",
    "        text = re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', complete_text)\n",
    "\n",
    "        words_list = list(set(text))\n",
    "\n",
    "        vocabulary = dict()\n",
    "\n",
    "        for i, j in enumerate(words_list):\n",
    "            # vocabulary[j]=(jax.random.uniform(jax.random.key(cp.random.randint(10000)),embedding_size),i)\n",
    "            vocabulary[j] = (cp.array(nlp(j).vector), i)\n",
    "             # print(j,len(cp.array(nlp(j).vector)))\n",
    "\n",
    "        # print(vocabulary)\n",
    "        # print(\"Vocabulary size: \", len(vocabulary))\n",
    "        with open(vocabulary_file, 'wb') as handle:\n",
    "            pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def pad_sequences(self,sentences, lenght, pad_token='[PAD]', target_type=None):\n",
    "        \"\"\"\n",
    "        Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n",
    "        \"\"\"\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        if target_type == \"encoder\":\n",
    "            # Split each sentence into words\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        elif target_type == \"decoder\":\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) for sentence in sentences]\n",
    "        elif target_type == \"target\":\n",
    "            tokenized_sentences = [re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        # print(tokenized_sentences)\n",
    "        if lenght == 0:\n",
    "            # Find the maximum sentence length\n",
    "            max_len = max(len(sentence) for sentence in tokenized_sentences)\n",
    "        else:\n",
    "            max_len = lenght\n",
    "\n",
    "        # Pad each sentence with the [PAD] token to make them of equal length\n",
    "        padded_sentences = [\" \".join(sentence + [pad_token] * (max_len - len(sentence))) for sentence in\n",
    "                            tokenized_sentences]\n",
    "\n",
    "        return padded_sentences\n",
    "\n",
    "    def print_matrix(self,text=\"\",X=None):\n",
    "        for i in X:\n",
    "            print(text,i)\n",
    "    \n",
    "    def create_padding_mask(self,seq):\n",
    "    # Create a mask with 0 for padded tokens and 1 for real tokens\n",
    "        return (seq != 0).astype(cp.float32)[..., None]\n",
    "\n",
    "   \n",
    "    \n",
    "    @log_time\n",
    "    def create_input_encoder(self,X, vocabulary_encoder, max_words_per_phrase, embedding_size):\n",
    "\n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        #print(pos_encoding)\n",
    "        #inputs_e,input_e_words,mask = self.generate_input_encoder(X, vocabulary_encoder, max_words_per_phrase)\n",
    "        \n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        x_train = self.pad_sequences(X, max_words_per_phrase, target_type=\"encoder\")# here are string\n",
    "        \n",
    "       \n",
    "        xi = []\n",
    "        \n",
    "        input_e_words = [re.findall(regex_str, x) for x in x_train]\n",
    "        \n",
    "        phrase_vectors_x = [i[0:max_words_per_phrase] for i in input_e_words]\n",
    "\n",
    "\n",
    "        indices = cp.array([[vocabulary_encoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "        mask = (indices != vocabulary_encoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        #print(phrase_vectors_x) \n",
    "       \n",
    "        # print(\"input_encoder:\")\n",
    "        # self.print_matrix(phrase_vectors_x)\n",
    "        xi = cp.array([[vocabulary_encoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "        word_indexes=cp.array([[vocabulary_encoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "        inputs_e =xi + pos_encoding\n",
    "\n",
    "        return inputs_e,input_e_words,mask,word_indexes\n",
    "    \n",
    "    def generate_target(self,x_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "        target_vector = cp.array([[self.get_one_hot(i,vocabulary) for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    def generate_target_sparse_categorical(self,y_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        len_phrase=max_words_per_phrase#+1\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(y_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:len_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "\n",
    "        target_vector = cp.array([[vocabulary[i][1] for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target_sparse(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target_sparse_categorical(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    @log_time\n",
    "    def create_decoder_input(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "        len_phrase=max_words_per_phrase#+1\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        \n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        #print(len(decoder_input[0]))\n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:len_phrase] for i in decoder_input]\n",
    "        #print(phrase_vectors_y)\n",
    "        indices = cp.array([[vocabulary_decoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        mask = (indices != vocabulary_decoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        word_indexes=  cp.array([[vocabulary_decoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(len_phrase, embedding_size)\n",
    "   \n",
    "        yi = yi + pos_encoding\n",
    "      \n",
    "        return yi,phrase_vectors_y,mask,word_indexes\n",
    "    @log_time\n",
    "    def create_decoder_input_teacher_forcing(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        # for sentence in phrase_vectors_y:\n",
    "        #     print(sentence)\n",
    "        #print_matrix(phrase_vectors_y)\n",
    "        indices = cp.array([[vocabulary_decoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        mask = (indices != vocabulary_decoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "       \n",
    "\n",
    "        # print(\"decoder_input:\")\n",
    "        # self.print_matrix(decoder_input)\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        # print(pos_encoding.shape,yi.shape)\n",
    "        yi = yi + pos_encoding\n",
    "        #print_matrix(yi)\n",
    "        decoder_inputs = cp.array(cp.swapaxes(self.create_timestaped_input(yi, max_words_per_phrase), 0, 1))\n",
    "        \n",
    "        # decoder_inputs[zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "        for i in range(decoder_inputs.shape[0]):\n",
    "            for j in range(decoder_inputs[i].shape[0]):\n",
    "                zero_rows = cp.all(decoder_inputs[i][j] == 0, axis=1)\n",
    "\n",
    "                decoder_inputs[i][j][zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "\n",
    "        decoder_inputs = cp.array(decoder_inputs)\n",
    "        #print(decoder_inputs[2])\n",
    "        #print(decoder_inputs)\n",
    "        return decoder_inputs,phrase_vectors_y,mask\n",
    "    # @log_time\n",
    "    def update_wembedding_encoder(self,learning_rate, x_batch, dLoss_dWemb_encoder, vocabulary, max_words_per_phrase):\n",
    "        \n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n",
    "\n",
    "        phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n",
    "        phrase_vectors_x = [i[:max_words_per_phrase] for i in phrase_vectors_x]\n",
    "\n",
    "        for phrase in range(dLoss_dWemb_encoder.shape[0]):\n",
    "            for position, word in enumerate(phrase_vectors_x[phrase]):\n",
    "                # Retrieve current embedding\n",
    "                current_embedding, index = vocabulary[word]\n",
    "\n",
    "                # Calculate the updated embedding using the gradient\n",
    "                updated_embedding = current_embedding - learning_rate * dLoss_dWemb_encoder[phrase][position]\n",
    "\n",
    "                # Update the vocabulary with the new embedding\n",
    "                vocabulary[word] = (updated_embedding, index)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "\n",
    "    # @log_time\n",
    "    def update_wembedding(self,updated_vectors,input_words,vocabulary):\n",
    "        special_tokens=[\"[PAD]\",\"[START]\",\"[END]\",\"\\n\"]\n",
    "        #print(\"updated_vectors\",updated_vectors.shape)\n",
    "        for phrase_index in range(len(updated_vectors)):\n",
    "            for word_index in range(len(updated_vectors[phrase_index])):\n",
    "                word=input_words[phrase_index][word_index] \n",
    "                if word not in special_tokens: \n",
    "                    #print(word)\n",
    "                    vocabulary[word]=(updated_vectors[phrase_index][word_index],vocabulary[word][1])\n",
    "        return vocabulary\n",
    "\n",
    "  \n",
    "    # @log_time\n",
    "    def get_one_hot(self,word, vocabulary_decoder):\n",
    "        # print(word)\n",
    "        vocab_size = len(vocabulary_decoder)\n",
    "        one_hot_vector = cp.zeros(vocab_size)\n",
    "        one_hot_vector[vocabulary_decoder[word][1]] = 1\n",
    "        # print(vocabulary_decoder[word][1])\n",
    "        # print(np.where(one_hot_vector== 1))\n",
    "        # print(cp.sum(one_hot_vector))\n",
    "        return one_hot_vector\n",
    " \n",
    "    \n",
    "    def log_sparse_entropy(self,ans,target,y_batch,step):\n",
    "        #print(\"target\",target)\n",
    "        #print(\"ans\",ans)\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans)\n",
    "        print(f\"----DECODER--step {step}---\")\n",
    "        self.print_matrix(y_batch)\n",
    "        print(\"target\",target)\n",
    "        indexes=[]\n",
    "        yy=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in y_batch] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values)\n",
    "            indexes.append(max_index)\n",
    "             \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "            print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {max_index}\")\n",
    "        print(\"indexes\",indexes)\n",
    "        print(\"accuracy batch:\",round(counter_found/total_lenght,2))\n",
    "        \n",
    "    def accruacy_sparse_entropy(self,ans,target):\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans) \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values) \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "             \n",
    "        accuracy_batch_on_step=round(counter_found/total_lenght,2)\n",
    "        return accuracy_batch_on_step\n",
    "    \n",
    "\n",
    "    def print_target_vs_prediction_sparce_loss(self,ans,target): \n",
    "        indexes=[] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = np.argmax(values).item()\n",
    "            indexes.append(max_index) \n",
    "        print(\"target\",target)\n",
    "        print(\"indexes\",indexes)\n",
    "        \n",
    "  \n",
    "# def clip_gradient(gradient,threshold):\n",
    "#     return cp.clip(gradient, -threshold, threshold)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class layer_dropout: \n",
    "\n",
    "    def __init__(self,dropout_rate=0.1):\n",
    "        self.dropout_rate=dropout_rate \n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self,X):   \n",
    "        self.mask = (cp.random.rand(*X.shape) > self.dropout_rate)#.astype(cp.float64)\n",
    "        result = X * self.mask \n",
    "        #print(self.mask )\n",
    "        return result\n",
    "    #\n",
    "    def grad(self, X):\n",
    "        # Only pass gradients through neurons that were not dropped out\n",
    "        grad_input = X * self.mask\n",
    "        #grad_input = clip_gradient(grad_input, 1)\n",
    "        return grad_input\n",
    "    \n",
    "    def grad_tf(self, X):\n",
    "        # Only pass gradients through neurons that were not dropped out\n",
    "        grad_input = X * self.mask\n",
    "        #grad_input = clip_gradient(grad_input, 1)\n",
    "        return grad_input\n",
    "\n",
    "class layer_normalization:\n",
    "    def __init__(self, threshold, epsilon=0.0001):\n",
    "        self.epsilon = epsilon\n",
    "        self.mu = 0\n",
    "        self.var = 0\n",
    "        self.N = None\n",
    "        self.beta = None\n",
    "        self.alpha = None\n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilonopt = 1e-8\n",
    "        self.t = 0 \n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.N = x.shape[-1]\n",
    "        \n",
    "        # Initialize parameters if not done\n",
    "        if self.alpha is None:\n",
    "            self.alpha = cp.ones(self.N)\n",
    "            self.beta = cp.zeros(self.N)\n",
    "            self.m_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.v_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.m_Walpha = cp.zeros_like(self.alpha)\n",
    "            self.v_Walpha = cp.zeros_like(self.alpha)\n",
    "\n",
    "        # Forward computation\n",
    "        self.mu = cp.mean(x, axis=-1, keepdims=True)\n",
    "        self.var = cp.var(x, axis=-1, keepdims=True)\n",
    "        self.std = cp.sqrt(self.var + self.epsilon)\n",
    "        self.x_norm = (x - self.mu) / self.std\n",
    "        \n",
    "        return self.alpha * self.x_norm + self.beta\n",
    "\n",
    "    def dL_dNorm(self):\n",
    "        self.dL_dnorm_ = self.dLoss_dy * self.alpha\n",
    "        return self.dL_dnorm_\n",
    "\n",
    "    def dL_dsigma(self): \n",
    "        self.dL_dsigma_ = (-0.5)*cp.sum(self.dx_norm*(self.x-self.mu)*((self.var+self.epsilon)**(-1.5)),axis=-1,keepdims=True)\n",
    "        return self.dL_dsigma_\n",
    "    \n",
    "    def dL_dsigma_tf(self):\n",
    "        #print(\"(self.x-self.mu)\",(self.x-self.mu).shape)\n",
    "        #print(\"(self.var+self.epsilon)\",(self.var+self.epsilon).shape)\n",
    "        a=cp.sum((self.x-self.mu),axis=1)\n",
    "        b=cp.sum(((self.var+self.epsilon)**(-1.5)),axis=1)\n",
    "        #print(cp.sum(self.dx_norm*a*b,axis=-1,keepdims=True).shape)\n",
    "        self.dL_dsigma_ = (-0.5)*(self.dx_norm*a*b)\n",
    "        return self.dL_dsigma_\n",
    "    \n",
    "    def dSigma_dmu(self):\n",
    "        return (-2/self.N)*(self.x-self.mu)\n",
    "    \n",
    "    def dSigma_dmu_tf(self):\n",
    "         \n",
    "        return (-2/self.N)*(self.x-self.mu)\n",
    "    \n",
    "    def dL_dmu(self):\n",
    "        a = -1*cp.sum(self.dx_norm*(1/cp.sqrt(self.var+self.epsilon)),axis=-1,keepdims=True)\n",
    "        b = -2*self.dL_dsigma_*cp.sum((1/self.N)*(self.x-self.mu),axis=-1,keepdims=True)\n",
    "        self.dL_dmu_=a+b\n",
    "        return self.dL_dmu_\n",
    "         \n",
    "    def dL_dx(self): \n",
    "        self.dL_dx_=self.dx_norm*self.dNorm_dx()+self.dL_dsigma()*self.dSigma_dx()+self.dL_dmu()*(1/self.N)\n",
    "        return self.dL_dx_\n",
    "    \n",
    "    def dL_dx_tf(self): \n",
    "        print(\"self.dx_norm\",self.dx_norm.shape)\n",
    "        print(\"self.dNorm_dx()\",self.dNorm_dx().shape)\n",
    "        print(\"self.dL_dsigma_tf\",self.dL_dsigma_tf().shape)\n",
    "        print(\"self.dSigma_dx\",self.dSigma_dx().shape)\n",
    "        print(\"self.dL_dmu\",self.dSigma_dmu().shape)\n",
    "        print((self.dx_norm*cp.sum(self.dNorm_dx(),axis=1)).shape)\n",
    "        a=self.dx_norm*cp.sum(self.dNorm_dx(),axis=1)\n",
    "        print((self.dL_dsigma_tf()*cp.sum(self.dSigma_dx(),axis=1)).shape)\n",
    "        b=self.dL_dsigma_tf()*cp.sum(self.dSigma_dx(),axis=1)\n",
    "        print(cp.sum(self.dSigma_dmu()*(1/self.N),axis=1).shape)\n",
    "        c=cp.sum(self.dSigma_dmu()*(1/self.N),axis=1)\n",
    "        self.dL_dx_=a+b+c\n",
    "        return self.dL_dx_\n",
    "    \n",
    "    def dNorm_dx(self):\n",
    "        return 1/cp.sqrt(self.var+self.epsilon)\n",
    "\n",
    "    def dSigma_dx(self):\n",
    "        return (2/self.N)*(self.x-self.mu)\n",
    "         \n",
    "    def backpropagation(self, dLoss_dy):\n",
    "        self.dLoss_dy = dLoss_dy\n",
    "        self.dx_norm = dLoss_dy * self.alpha \n",
    "        return self.dL_dx()\n",
    "    \n",
    "    def backpropagation_tf(self, dLoss_dy):\n",
    "        self.dLoss_dy = dLoss_dy\n",
    "        self.dx_norm = dLoss_dy * self.alpha \n",
    "        return self.dL_dx_tf()\n",
    "   \n",
    "    def dL_dalpha(self):\n",
    "        result = self.dLoss_dy * self.x_norm\n",
    "        result=cp.sum(cp.sum(result,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.alpha.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "\n",
    "    def dL_dbeta(self):\n",
    "        result = cp.sum(cp.sum(self.dLoss_dy,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.beta.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "     \n",
    "\n",
    "    \n",
    "    def params_update(self, learning_rate):\n",
    "\n",
    "         \n",
    "        self.t += 1\n",
    "        \n",
    "        # Update beta\n",
    "        dbeta = self.dL_dbeta()\n",
    "        self.m_Wbeta = self.beta1 * self.m_Wbeta + (1 - self.beta1) * dbeta\n",
    "        self.v_Wbeta = self.beta2 * self.v_Wbeta + (1 - self.beta2) * cp.square(dbeta)\n",
    "        \n",
    "        m_W_hat = self.m_Wbeta / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wbeta / (1 - self.beta2 ** self.t)\n",
    "        self.beta -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "        \n",
    "        # Update alpha\n",
    "        dalpha = self.dL_dalpha()\n",
    "        self.m_Walpha = self.beta1 * self.m_Walpha + (1 - self.beta1) * dalpha\n",
    "        self.v_Walpha = self.beta2 * self.v_Walpha + (1 - self.beta2) * cp.square(dalpha)\n",
    "        \n",
    "        m_W_hat = self.m_Walpha / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Walpha / (1 - self.beta2 ** self.t)\n",
    "        self.alpha -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "\n",
    "       \n",
    "        \n",
    "class linear_layer: \n",
    "    def __init__(self,input_size,output_size,out=False,only_weights=False,threshold=1):\n",
    "\n",
    "        variance = 2 / (input_size + output_size)  # Variance for Glorot normal initializer\n",
    "       \n",
    "        self.W = cp.random.normal(0, cp.sqrt(variance), (input_size, output_size))\n",
    "          \n",
    "        if not only_weights:\n",
    "            self.b = cp.random.normal(0, cp.sqrt(variance), (output_size,))\n",
    "        \n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0  # Time step for Adam updates\n",
    "        \n",
    "        # Initialize first (m) and second (v) moment vectors for weights and biases\n",
    "        self.m_W = cp.zeros_like(self.W)\n",
    "        self.v_W = cp.zeros_like(self.W)\n",
    "        if not only_weights:\n",
    "            self.m_b = cp.zeros_like(self.b)\n",
    "            self.v_b = cp.zeros_like(self.b)\n",
    "      \n",
    "    def forward(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) + self.b \n",
    "        return Xout\n",
    "    \n",
    "    def forward_weights_only(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) \n",
    "        return Xout\n",
    "     \n",
    "    def grad(self,dL_dy):\n",
    "        self.dL_dy = dL_dy\n",
    "        # print(\"self.dL_dy\",self.dL_dy)\n",
    "        return self.dL_dy@self.W.T\n",
    "    \n",
    "    def dLoss_dW(self):\n",
    "        #return cp.mean(self.dL_dy.T@self.x,axis=0).T\n",
    "        return cp.sum(cp.transpose(self.dL_dy,(0,2,1))@self.x,axis=0).T\n",
    "    \n",
    "    def dLoss_dW_tf(self):\n",
    "        return (self.dL_dy.T@self.x).T\n",
    "         \n",
    "    \n",
    "    def dLoss_db(self):\n",
    "        return cp.sum(cp.sum(self.dL_dy,axis=0))\n",
    "    \n",
    "    def Adam_optimize(self,dW,db,learning_rate):\n",
    "        \n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_b = self.beta1 * self.m_b + (1 - self.beta1) * db\n",
    "        self.v_b = self.beta2 * self.v_b + (1 - self.beta2) * cp.square(db)\n",
    "        # Correct bias in first and second moment for biases\n",
    "        m_b_hat = self.m_b / (1 - self.beta1 ** self.t)\n",
    "        v_b_hat = self.v_b / (1 - self.beta2 ** self.t)\n",
    "        # Update biases using Adam\n",
    "         \n",
    "        #print(up.shape,self.b.shape,db.shape)\n",
    "        self.b -= learning_rate * m_b_hat / (cp.sqrt(v_b_hat) + self.epsilon)\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "        db = self.dLoss_db()  \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        self.Adam_optimize(dW,db,learning_rate)\n",
    "\n",
    "    def update_weights_tf(self,learning_rate):\n",
    "        dW = self.dLoss_dW_tf()\n",
    "        db = self.dLoss_db()  \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        self.Adam_optimize(dW,db,learning_rate)\n",
    "\n",
    "    def update_weights_only(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights only\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "class AdamOptimize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_block:\n",
    "    def __init__(self,embedding_size,hidden_size,clipping_threshold):\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.linear_layer_1=linear_layer(self.embedding_size,self.hidden_size,threshold=clipping_threshold)\n",
    "        self.linear_layer_2=linear_layer(self.hidden_size,self.embedding_size,threshold=clipping_threshold)\n",
    "        self.dropout=layer_dropout()\n",
    "        self.ReLu=ReLu_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_1=self.linear_layer_1.forward(x)\n",
    "        x_1_r=self.ReLu.forward_leaky(x_1)\n",
    "        #x_1_rd=self.dropout.forward(x_1_r)\n",
    "        x_2=self.linear_layer_2.forward(x_1_r)\n",
    "        return x_2\n",
    "    \n",
    "    def grad(self,dL_dy):\n",
    "        dL_dx_1_rd=self.linear_layer_2.grad(dL_dy)\n",
    "        #dL_dx_1_r=self.dropout.grad(dL_dx_1_rd)\n",
    "        dL_dx_1=self.ReLu.backward_leaky(dL_dx_1_rd)\n",
    "        dL_dx=self.linear_layer_1.grad(dL_dx_1)\n",
    "        return dL_dx\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.linear_layer_1.update_weights(learning_rate)\n",
    "        self.linear_layer_2.update_weights(learning_rate)\n",
    "        \n",
    " \n",
    "class ReLu_layer:\n",
    "    def __init__(self,alpha=0.001):\n",
    "        self.alpha=alpha \n",
    "    def forward_leaky(self,X):\n",
    "        self.X=X\n",
    "        return cp.where(X > 0, X, self.alpha * X)\n",
    "\n",
    "    def forward(self,X): \n",
    "        self.X=X\n",
    "        return cp.maximum(0,self.X)\n",
    "    \n",
    "    def backward(self, dLoss): \n",
    "        # Gradient of ReLU is 1 for x > 0, else 0\n",
    "        dx = dLoss * (self.X > 0)  # Only propagate gradients for inputs > 0\n",
    "        return dx\n",
    "    \n",
    "    def backward_leaky(self, dLoss): \n",
    "        dx = dLoss * cp.where(self.X > 0, 1, self.alpha)  # Gradient: 1 for x > 0, else alpha\n",
    "        return dx\n",
    "\n",
    "class residual_layer:\n",
    "    def __init__(self,threshold):\n",
    "        self.dropout=layer_dropout()\n",
    "        self.normalization=layer_normalization(threshold=threshold)\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "\n",
    "    def forward(self,x,sublayer_output): \n",
    "        residual=self.dropout.forward(sublayer_output)+x\n",
    "        result=self.normalization.forward(residual)\n",
    "        return result\n",
    "    \n",
    "    def grad(self, dL_dy):\n",
    "        dl_dNorm = self.normalization.backpropagation(dL_dy) \n",
    "        scaling_factor = 1.0 #/ np.sqrt(2.0)\n",
    "        sublayer_grad = self.dropout.grad(dl_dNorm) * scaling_factor\n",
    "        residual_grad = dl_dNorm * scaling_factor\n",
    "        \n",
    "        return sublayer_grad, residual_grad\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.normalization.params_update(learning_rate)\n",
    "\n",
    "\n",
    "      \n",
    "class multihead_attention: \n",
    "    def __init__(self,embedding_size,num_heads,batch_size,threshold):\n",
    "        self.num_heads=num_heads\n",
    "        self.dk=embedding_size//num_heads\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.q=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.k=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.v=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.projection_layer=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold) \n",
    "        self.helper=Helper()\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0 \n",
    "        self.m_Wq = cp.zeros_like(self.q.W)\n",
    "        self.v_Wq = cp.zeros_like(self.q.W)\n",
    "\n",
    "        self.m_Wk = cp.zeros_like(self.k.W)\n",
    "        self.v_Wk = cp.zeros_like(self.k.W)\n",
    "\n",
    "        self.m_Wv = cp.zeros_like(self.v.W)\n",
    "        self.v_Wv = cp.zeros_like(self.v.W)\n",
    "         \n",
    "    def reshape_heads(self,Q,K,V):\n",
    "        self.Q = cp.swapaxes(cp.array(np.array_split(Q, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Qval.shape: \",Q_E.shape)\n",
    "        self.K = cp.swapaxes(cp.array(np.array_split(K, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Kval.shape: \",K_E.shape)\n",
    "        self.V = cp.swapaxes(cp.array(np.array_split(V, self.num_heads, axis=2)), 0, 1)\n",
    "        #return self.Q,self.K,self.V\n",
    "\n",
    "    def QKV(self,input_q,input_k,input_v): \n",
    "        Q=self.q.forward_weights_only(input_q)\n",
    "        K=self.k.forward_weights_only(input_k)\n",
    "        V=self.v.forward_weights_only(input_v) \n",
    "        self.reshape_heads(Q,K,V)\n",
    "        \n",
    "\n",
    "    def attention_weights(self,mask): \n",
    "         \n",
    "        QKscaled =cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])  \n",
    "        #print(QKscaled)\n",
    "        if mask is not None:\n",
    "            \n",
    "            # Ensure mask has shape [batch_size, 1, 1, seq_len] for broadcasting\n",
    "            mask = mask[:, cp.newaxis, :]  # Shape: (batch_size, 1, 1, seq_len)\n",
    "            #print(\"mask padding in attention_weights\",mask)\n",
    "            #print(\"mask.shape-------->\",mask.shape)\n",
    "            # Add a large negative value to masked positions\n",
    "            QKscaled = QKscaled + (mask - 1) * 1e9\n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "        #print(\"attention weights\")\n",
    "        #print(self.Attention_weights)\n",
    "         \n",
    "\n",
    "    def forward_attention(self,input_q,input_k,input_v,mask_padding): \n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v\n",
    "        #print(\"input_q.shape\",input_q.shape)\n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights(mask_padding)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def forward_masked_attention(self,input_q,input_k,input_v,mask_size,mask_padding):\n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v \n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights_masked(mask_size,mask_padding)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def attention_weights_masked(self,mask_size,mask_padding):\n",
    "        #mask_size =  words_per_phrase \n",
    "\n",
    "        QKscaled = cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])\n",
    "        mask = cp.tril(cp.ones((mask_size, mask_size)))  # (9, 9) lower triangular matrix\n",
    "        mask[mask == 0]=-cp.inf  # Set future tokens to -inf\n",
    "        mask[mask == 1]=0  # Set allowed tokens to 0\n",
    "        self.mask = mask.reshape(1, 1, mask_size, mask_size)\n",
    "        if mask_padding is not None:\n",
    "            \n",
    "            # Ensure mask has shape [batch_size, 1, 1, seq_len] for broadcasting\n",
    "            maskpad = mask_padding[:, cp.newaxis, :]  # Shape: (batch_size, 1, 1, seq_len)\n",
    "            #print(\"mask padding in masked attention\",mask_padding)\n",
    "            #print(\"mask.shape-------->\",maskpad.shape)\n",
    "            # Add a large negative value to masked positions\n",
    "            QKscaled = QKscaled + (maskpad - 1) * 1e9\n",
    "        QKscaled = QKscaled + self.mask\n",
    "       \n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "        \n",
    "    \n",
    "    def diffQi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_dX=cp.transpose(dAttention, (0, 2, 1)) @ (self.helper.redimension(dAttention_weights @ (self.K * self.V) / cp.sqrt(self.K.shape[-1]))*self.input_q)\n",
    "        self.dLoss_Qi= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffKi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        X = cp.swapaxes(cp.array(cp.array_split(self.input_k, self.num_heads, axis=2)), 0, 1) \n",
    "         \n",
    "        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ self.helper.redimension(\n",
    "            (dAttention_weights * (self.Q @ cp.transpose(self.V, (0, 1, 3, 2))) @ X) / cp.sqrt(self.K.shape[-1])) \n",
    "        self.dLoss_Ki= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffVi(self,dAttention):\n",
    "        self.dLoss_Vi = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ (\n",
    "                self.Attention_weights @ cp.expand_dims(self.input_v, axis=1)), axis=1), axis=0)\n",
    "       \n",
    "\n",
    "\n",
    "    def diffKInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "         \n",
    "        \n",
    "        A = self.helper.redimension(self.V)@self.k.W\n",
    "         \n",
    "        B = self.helper.redimension(dAttention_weights@self.K)\n",
    "         \n",
    "        C=cp.transpose(dAttention,(0,2,1))@B\n",
    "       \n",
    "        dLoss_KI=cp.transpose((C@cp.transpose(A,(0,2,1))),(0,2,1))\n",
    "        #print(\"dLoss_KI.shape\",dLoss_KI.shape)\n",
    "        \n",
    "        return dLoss_KI\n",
    "    \n",
    "    def diffVInput(self,dAttention):\n",
    "        dLoss_V_E = cp.transpose(\n",
    "        cp.sum(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ self.Attention_weights, axis=1), (0, 2, 1))\n",
    "        dLossVI = dLoss_V_E @ self.v.W\n",
    "        #print(\"dLossVI.shape\",dLossVI.shape)\n",
    "        return dLossVI\n",
    "    \n",
    "    def diffQInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        \n",
    "         \n",
    "        A1=self.helper.redimension(dAttention_weights @ (self.K*self.V / cp.sqrt(self.K.shape[-1])))@self.q.W\n",
    "   \n",
    "        dLoss_QI=dAttention*A1\n",
    "        #print(\"dLoss_QI.shape\",dLoss_QI.shape)\n",
    "        return dLoss_QI\n",
    "    \n",
    "    def grad(self,dL_dy): \n",
    "        self.dLoss_dAcr=self.projection_layer.grad(dL_dy)\n",
    "        self.diffQi(self.dLoss_dAcr)\n",
    "        self.diffVi(self.dLoss_dAcr)\n",
    "        self.diffKi(self.dLoss_dAcr)\n",
    "\n",
    "        dLoss_KI=self.diffKInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_QI=self.diffQInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_VI=self.diffVInput(self.dLoss_dAcr)\n",
    "       \n",
    "        return dLoss_QI,dLoss_KI,dLoss_VI\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_Wq = self.beta1 * self.m_Wq + (1 - self.beta1) * self.dLoss_Qi\n",
    "        self.v_Wq = self.beta2 * self.v_Wq + (1 - self.beta2) * cp.square(self.dLoss_Qi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wq / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wq / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.q.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_Wk = self.beta1 * self.m_Wk + (1 - self.beta1) * self.dLoss_Ki\n",
    "        self.v_Wk = self.beta2 * self.v_Wk + (1 - self.beta2) * cp.square(self.dLoss_Ki)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wk / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wk / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.k.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "        self.m_Wv = self.beta1 * self.m_Wv + (1 - self.beta1) * self.dLoss_Vi\n",
    "        self.v_Wv = self.beta2 * self.v_Wv + (1 - self.beta2) * cp.square(self.dLoss_Vi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wv / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wv / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.v.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "\n",
    "        self.projection_layer.update_weights_only(learning_rate)\n",
    "        # self.q.W= self.q.W-self.dLoss_Qi*learning_rate\n",
    "        # self.k.W= self.k.W-self.dLoss_Ki*learning_rate\n",
    "        # self.v.W= self.v.W-self.dLoss_Vi*learning_rate\n",
    "        # print(\"self.q.W\",self.q.W)\n",
    "        # print(\"self.k.W\",self.k.W)\n",
    "        # print(\"self.v.W\",self.v.W)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_punctuation(input_str):\n",
    "    return re.sub(r'[^\\w\\s]', '', input_str)\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.batch_size=batch_size\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.num_heads=num_heads\n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        self.multihead_attention_encoder=multihead_attention(num_heads=2,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.residual_layer_1=residual_layer(clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "         \n",
    "        self.helper=Helper()\n",
    "     \n",
    "\n",
    "    def forward(self,inputs_e,mask_e):\n",
    "        self.inputs_e=inputs_e \n",
    "\n",
    "        PrjAe=self.multihead_attention_encoder.forward_attention(inputs_e,inputs_e,inputs_e,mask_e)\n",
    "        #print(\"PrjAe\",PrjAe.shape)\n",
    "        Ect1=self.residual_layer_1.forward(PrjAe,inputs_e) \n",
    "\n",
    "        FLe2=self.fully_connected_block.forward(Ect1) \n",
    "\n",
    "        Ecout=self.residual_layer_2.forward(FLe2,Ect1)\n",
    "\n",
    "        return Ecout\n",
    "    \n",
    "    def backpropagation(self,dL_Ecout): \n",
    "        \n",
    "        dL_dFLe2,dL_dEct1_residual=self.residual_layer_2.grad(dL_Ecout)\n",
    "        \n",
    "        #print(\"dL_dFLe2\",dL_dFLe2)\n",
    "        #print(\"dL_dEct1_residual\",dL_dFLe2)\n",
    "        \n",
    "\n",
    "        dL_dEct1=self.fully_connected_block.grad(dL_dFLe2)+dL_dEct1_residual\n",
    "        #print(\"dL_dEct1\",dL_dEct1)\n",
    "        \n",
    "        dL_dPrjAe,dL_inputs_e_residual=self.residual_layer_1.grad(dL_dEct1)\n",
    "        #print(\"dL_dPrjAe\",dL_dPrjAe)\n",
    "        #print(\"dL_inputs_e_residual\",dL_inputs_e_residual)\n",
    "        dL_inputs_e_q,dL_inputs_e_k,dL_inputs_e_v=self.multihead_attention_encoder.grad(dL_dPrjAe)\n",
    "        \n",
    "        dL_inputs_e=dL_inputs_e_residual+dL_inputs_e_q+dL_inputs_e_k+dL_inputs_e_v\n",
    "\n",
    "        #dL_inputs_e=clip_gradient(dL_inputs_e,self.clipping_threshold)\n",
    "        #print(\"dL_inputs_e\",dL_inputs_e_residual)\n",
    "        #dLoss_dWemb_encoder = dL_inputs_e * self.inputs_e\n",
    "        return dL_inputs_e#,dLoss_dWemb_encoder\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_encoder.update_weights(learning_rate) \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "  \n",
    "      \n",
    "     \n",
    "class Decoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.batch_size=batch_size\n",
    "        self.num_heads=num_heads \n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size  \n",
    "        self.multihead_cross_attention=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.multihead_attention_decoder=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "        self.helper=Helper() \n",
    "        self.residual_layer_1=residual_layer(threshold=clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(threshold=clipping_threshold) \n",
    "        self.residual_layer_3=residual_layer(threshold=clipping_threshold) \n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        \n",
    "\n",
    "    def forward(self,inputs_decoder,Ecout,mask_d,mask_e):\n",
    "        self.inputs_decoder=inputs_decoder \n",
    "        \n",
    "        PrjA_mask=self.multihead_attention_decoder.forward_masked_attention(inputs_decoder,inputs_decoder,inputs_decoder,mask_size=inputs_decoder.shape[1],mask_padding=mask_d)\n",
    " \n",
    "        Dt1=self.residual_layer_1.forward(self.inputs_decoder,PrjA_mask)\n",
    "        #print(\"cross attention multihead calc attention weights\")\n",
    "        PrjAcr=self.multihead_cross_attention.forward_attention(Dt1,Ecout,Ecout,mask_padding=mask_e)\n",
    "   \n",
    "        Dt2=self.residual_layer_2.forward(PrjAcr,Dt1)\n",
    " \n",
    "        FLd2=self.fully_connected_block.forward(Dt2)\n",
    "      \n",
    "        Dout=self.residual_layer_3.forward(FLd2,Dt2)  \n",
    "\n",
    "        return Dout\n",
    "    \n",
    "    # def output(self,Dout):\n",
    "    #     SigmaZout=self.helper.softmax(self.final_projection_layer.forward(Dout))\n",
    "    #     return SigmaZout\n",
    "\n",
    "\n",
    "    def backpropagation(self,dL_dDout): \n",
    "\n",
    "        dL_FLd2,dL_Dt2_residual=self.residual_layer_3.grad(dL_dDout)\n",
    "\n",
    "        dL_Dt2=self.fully_connected_block.grad(dL_FLd2)+dL_Dt2_residual\n",
    "\n",
    "        dL_PrjAcr,dL_Dt1_residual=self.residual_layer_2.grad(dL_Dt2)\n",
    "\n",
    "        dL_Dt1_q,dL_DEcout_k,dL_DEcout_v=self.multihead_cross_attention.grad(dL_PrjAcr)\n",
    "\n",
    "        dL_Dt1=dL_Dt1_residual+dL_Dt1_q\n",
    "\n",
    "        dL_PrjA_mask,dL_inputs_decoder_residual=self.residual_layer_1.grad(dL_Dt1)\n",
    "\n",
    "        dL_inputs_decoder_q,dL_inputs_decoder_k,dL_inputs_decoder_v=self.multihead_attention_decoder.grad(dL_PrjA_mask)\n",
    "\n",
    "        dL_inputs_decoder=dL_inputs_decoder_residual+dL_inputs_decoder_q+dL_inputs_decoder_k+dL_inputs_decoder_v\n",
    "        \n",
    "        dL_Ecout=dL_DEcout_k+dL_DEcout_v\n",
    "        #dL_inputs_decoder=clip_gradient(dL_inputs_decoder,self.clipping_threshold)\n",
    "        #dLoss_dWemb_decoder= dL_inputs_decoder * self.inputs_decoder\n",
    "        \n",
    "        return dL_Ecout,dL_inputs_decoder#,dLoss_dWemb_decoder\n",
    " \n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        self.residual_layer_3.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.multihead_cross_attention.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_decoder.update_weights(learning_rate)\n",
    "        #dLoss_dWemb_decoder=clip_gradient(dLoss_dWemb_decoder,self.clipping_threshold)\n",
    "         \n",
    "    \n",
    "    \n",
    "\n",
    "class output_stack:\n",
    "    def __init__(self,embedding_size,vocabulary_size,threshold,temperature=1):\n",
    "        self.final_projection_layer=linear_layer(embedding_size,vocabulary_size,threshold=threshold,out=True)\n",
    "        self.clipping_threshold=threshold\n",
    "        self.temperature=temperature\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp((x - max_logits) / self.temperature)  # Apply temperature\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        SoftmaxOutput=self.softmax(self.final_projection_layer.forward(x)) \n",
    "        return SoftmaxOutput\n",
    "\n",
    "    \n",
    "    # def cross_entropy_loss(self,SigmaZout, target):\n",
    "    #     epsilon = 1e-12  # Small constant to avoid log(0)\n",
    "    #     SigmaZout = cp.clip(SigmaZout, epsilon, 1 - epsilon)  # Clipping predictions\n",
    "    #     return -cp.sum(target * cp.log(SigmaZout), axis=1).mean() \n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        epsilon = 1e-12\n",
    "        return -np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=-1))\n",
    "    \n",
    "    def grad_cross_entropy(self,softmax_output,target):\n",
    "        dL_dZ =softmax_output-target\n",
    "        dL_dDout=self.final_projection_layer.grad(dL_dZ)  \n",
    "        #dL_dDout=clip_gradient(dL_dDout,self.clipping_threshold)\n",
    "        return dL_dDout\n",
    "    \n",
    "    def sparse_categorical_crossentropy(self, probabilities, labels,padding_mask): \n",
    "        #print(\"probabilities.shape\", probabilities.shape)\n",
    "        #print(\"labels.shape\", labels.shape)\n",
    "        \n",
    "        # Unpack batch and sequence dimensions\n",
    "        batch_size, seq_length = labels.shape\n",
    "        \n",
    "        # Gather correct class probabilities for each position in the batch and sequence\n",
    "        correct_class_probs = probabilities[np.arange(batch_size)[:, None], np.arange(seq_length), labels] \n",
    "        \n",
    "        # Calculate the log loss and average it\n",
    "        loss = -np.log(correct_class_probs + 1e-8)\n",
    "        \n",
    "        masked_loss = loss * padding_mask\n",
    "        #print(\"loss shape\",loss.shape,\"mask shape\",padding_mask.shape)\n",
    "\n",
    "        return np.mean(loss)\n",
    "    \n",
    "    def grad(self,dl_dy):\n",
    "        return self.final_projection_layer.grad(dl_dy)\n",
    "\n",
    "\n",
    "    def grad_sparse_cross_entropy(self, softmax_output, target,mask):\n",
    "        dL_dZ = softmax_output.copy()  # Create a copy of the softmax output\n",
    "        \n",
    "        # Adjust indexing to handle both batch and sequence dimensions\n",
    "        batch_size, seq_length = target.shape\n",
    "\n",
    "        dL_dZ[np.arange(batch_size)[:, None], np.arange(seq_length), target] -= 1\n",
    "\n",
    "        expanded_mask = mask.reshape(batch_size, seq_length,1)\n",
    "         \n",
    "        #dL_dZ *= expanded_mask\n",
    "        \n",
    "        #print(\"expanded_mask\",expanded_mask.shape)\n",
    "        # Compute gradient through final projection layer\n",
    "        dL_dDout = self.final_projection_layer.grad(dL_dZ)  \n",
    "        # dL_dDout = clip_gradient(dL_dDout, self.clipping_threshold)\n",
    "        return dL_dDout\n",
    " \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.final_projection_layer.update_weights(learning_rate) \n",
    "\n",
    "    def update_weights_tf(self,learning_rate):\n",
    "        self.final_projection_layer.update_weights_tf(learning_rate)  \n",
    "\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "    def __init__(self,num_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,words_per_phrase_decoder,clipping_threshold,vocabulary,index_based_vocabulary):\n",
    "        self.vocabulary=vocabulary\n",
    "        self.index_based_vocabulary=index_based_vocabulary\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.EncoderStack = [Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.DecoderStack = [Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_decoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.outout_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "        self.helper=Helper()\n",
    "    def forward(self,inputs_e,inputs_decoder,X_batch,y_batch,mask_e,mask_d):\n",
    "\n",
    "        self.X_batch=X_batch\n",
    "        self.y_batch=y_batch\n",
    "        #print(\"encoder stack\")\n",
    "        Ecout=self.forward_encoder(inputs_e,mask_e)\n",
    "        #print(\"Ecout.shape\",Ecout.shape)\n",
    "        #(\"decoder stack\")\n",
    "        Dout=self.forward_decoder(Ecout,inputs_decoder,mask_d,mask_e)\n",
    "        #SigmaZout=self.outout_stack.forward(Dout) \n",
    "        return Dout\n",
    "    \n",
    "    def backpropagation(self,dL_dDout,decoder_words,encoder_words):\n",
    "        dL_Ecout,dL_dInput_decoder=self.backpropagation_decoder(dL_dDout,decoder_words)\n",
    "        dL_dInput_encoder=self.backpropagation_encoder(dL_Ecout,encoder_words)\n",
    "        return dL_dInput_encoder,dL_dInput_decoder\n",
    "      \n",
    " \n",
    "    def forward_encoder(self,inputs_e,mask_e):\n",
    "        for encoder_i in self.EncoderStack:\n",
    "            inputs_e=encoder_i.forward(inputs_e,mask_e)\n",
    "        return inputs_e\n",
    "    \n",
    "    def forward_decoder(self,Ecout,inputs_decoder,mask_d,mask_e):\n",
    "        for decoder_i in self.DecoderStack:\n",
    "            inputs_decoder=decoder_i.forward(inputs_decoder,Ecout,mask_d,mask_e)\n",
    "        return inputs_decoder\n",
    "    \n",
    "    def backpropagation_decoder(self,dL_dInput_decoder,decoder_words):\n",
    "        tot_dL_dEcout=0 \n",
    "        for decoder_i in reversed(self.DecoderStack):\n",
    "            dL_Ecout_i,dL_dInput_decoder=decoder_i.backpropagation(dL_dInput_decoder)\n",
    "            tot_dL_dEcout+=dL_Ecout_i\n",
    "            #dLoss_dWemb_decoder_tot+=dLoss_dWemb_decoder\n",
    "            decoder_i.update_weights(decoder_i.learning_rate)\n",
    "        return tot_dL_dEcout,dL_dInput_decoder\n",
    "    \n",
    "    def backpropagation_encoder(self,dL_dInput_encoder,encoder_words):  \n",
    "        for encoder_i in reversed(self.EncoderStack):\n",
    "            dL_dInput_encoder=encoder_i.backpropagation(dL_dInput_encoder)  \n",
    "            encoder_i.update_weights(encoder_i.learning_rate)\n",
    "        return dL_dInput_encoder\n",
    " \n",
    "    def update_embeddings(self,inputs_decoder,inputs_e,dL_dInput_decoder,dL_dInput_encoder,decoder_words,encoder_words,learning_rate,vocabulary):\n",
    "        input_d=inputs_decoder-learning_rate*dL_dInput_decoder\n",
    "        vocabulary=self.helper.update_wembedding(input_d,decoder_words,vocabulary)\n",
    "        input_e=inputs_e-learning_rate*dL_dInput_encoder\n",
    "        vocabulary=self.helper.update_wembedding(input_e,encoder_words,vocabulary)\n",
    "        return vocabulary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dae219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978e23dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4452 Amanda baked cookies and will bring Jerry some tomorrow\n",
      "Vocabulary loaded from file.\n",
      "vocabulary size 11342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "helper=Helper()\n",
    "def load_x_y_train_plain():\n",
    "    with open('corpus/train.json', 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            dataset = json.load(f)  # Load the JSON data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # #Loop through the list and process each dialogue and summary\n",
    "    for data in dataset:\n",
    "        dialogue = data['dialogue']  # Split dialogue into a list of lines\n",
    "        summary = data['summary']\n",
    "\n",
    "        X_train.append(remove_punctuation(dialogue))\n",
    "        y_train.append(remove_punctuation(summary))\n",
    "    return X_train, y_train\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# with open('data/vocabolary_full.pkl', 'rb') as f:\n",
    "#     vocabulary=pickle.load(f)\n",
    "def filter_train_data(X_train, y_train, to_eliminate):\n",
    "    filtered_X_train = []\n",
    "    filtered_y_train = []\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if not any(to_eliminate_str in x for to_eliminate_str in to_eliminate):\n",
    "             \n",
    "            filtered_X_train.append(remove_punctuation(x))\n",
    "            filtered_y_train.append(remove_punctuation(y))\n",
    "\n",
    "    return filtered_X_train, filtered_y_train\n",
    "\n",
    "\n",
    "def create_complete_vocabulary(X_train, y_train,max_v,name):\n",
    "    nlp_model = spacy.load('en_core_web_lg')\n",
    "    nlp_model.disable_pipes([\"parser\", \"ner\"])\n",
    "    complete_text_target = ' '.join(y_train)\n",
    "    complete_text_origin = ' '.join(X_train)\n",
    "    complete_text = complete_text_target + \" [START] [PAD] [END] \" + complete_text_origin\n",
    "\n",
    "    vocabulary = helper.create_vocabulary(complete_text, name, nlp_model)\n",
    "    print(\"vocabulary size\", len(vocabulary))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "X_train, y_train = load_x_y_train_plain()\n",
    "# to_eliminate = [\n",
    "#     \"[I hope I'm not coming off as rude - If I am, I'm sorry. I just thought it would be beneficial for the both of us...]\",\n",
    "#     \"[pulls back the curtain and checks out the window]\",\n",
    "#     \"[hopefully, masses of]\"]\n",
    "# X_train, y_train = filter_train_data(X_train, y_train, to_eliminate)\n",
    "\n",
    "\n",
    "sample = [i for i in range(0,len(y_train))]\n",
    "\n",
    "\n",
    "X_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n",
    "y_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n",
    "\n",
    "\n",
    "min_v = 10\n",
    "max_v = 50\n",
    "\n",
    "\n",
    "y_train = [y_train[i] for i in sample if len(X_train[i]) <= max_v and len(X_train[i]) >= min_v]\n",
    "X_train = [X_train[i] for i in sample if len(X_train[i]) <= max_v and len(X_train[i]) >= min_v]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate lengths of the tokenized phrases\n",
    "\n",
    "\n",
    "def plot_lenghts(X_train,y_train):\n",
    "    X_lengths = [len(x) for x in X_train]\n",
    "    y_lengths = [len(y) for y in y_train]\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for X_train lengths\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(X_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of X_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for y_train lengths\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(y_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of y_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#X_train=[i[::-1] for i in y_train]\n",
    "plot_lenghts(X_train,y_train)\n",
    " \n",
    "\n",
    "X_train=[\" \".join(x) for x in X_train]\n",
    "y_train=[\" \".join(y) for y in y_train]\n",
    "\n",
    "print(len(y_train),y_train[0])\n",
    "name=f\"vocabolary_fultest{max_v}{min_v}\"\n",
    "vocabulary=create_complete_vocabulary(X_train, y_train,max_v,name)\n",
    "index_based_vocabulary=dict()\n",
    "for word,(vect,pos) in vocabulary.items():\n",
    "    index_based_vocabulary[pos]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9a5cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Amanda I baked cookies Do you want some \\n Jerry Sure \\n Amanda Ill bring you tomorrow',\n",
       "  'Olivia Who are you voting for in this election \\n Oliver Liberals as always \\n Olivia Me too \\n Oliver Great',\n",
       "  'Edward Rachel I think Im in ove with Bella \\n rachel Dont say anything else \\n Edward What do you mean \\n rachel Open your fuing door Im outside'],\n",
       " ['Amanda baked cookies and will bring Jerry some tomorrow',\n",
       "  'Olivia and Olivier are voting for liberals in this election',\n",
       "  'Edward thinks he is in love with Bella Rachel wants Edward to open his door Rachel is outside'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:3],y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ca1596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.36, 0.642, 3.66, 1.28e-05, -4.96, -3.76, -0.72, -3.87, -6.41, -2.2, -1.41, 2.04, -6.14, 1.5, 0.0749, -2.84, -0.69, 1.02, -2.39, -2.48, 4.8, 0.409, -0.595, -9.68, 1.01, -2.62, 1.62, -1.28, -3.36, 2.54, -8.26, -2.06, -3.59, 2.56, 3.42, 4.83, -4.73, 1.45, 1.95, -3.57, 0.711, -4.07, -2.38, 2.93, -1.04, 0.807, -10.4, 1.01, -2.36, 4.67, -5.65, -8.97, -0.0444, 0.406, 5.98, -2.7, 3.15, 1.74, 0.803, 2.41, 2.22, 4.96, -2.34, -5.5, 0.107, -1.84, -3.34, 5.73, -2.7, 1.66, -1.93, 1.43, 5.99, -12.5, 0.562, -5.37, 1.94, -2.24, 2.37, -7.11, 1.86, -6.78, 1.91, -4.02, -2.38, 2.46, 11.7, 4.9, 2.19, -3.72, 2.3, -0.689, 2.56, -3.24, -6.29, 2.85, 0.306, -6.82, 2.37, 3.29, -3.64, 2.86, 1.97, -4.42, 2.47, 4.65, 5.46, 0.32, -6.8, 3.07, -11.7, -1.96, 11.2, 2.73, 0.346, 3.32, 7.52, -3.86, 5.57, -8.39, -5.25, -1.62, 4.82, 6.21, 2.04, 2.07, -5.04, -0.343, -2.45, 3.21, 0.221, 1.75, 1.28, -1.19, 4.11, -1.43, -1.99, -5.08, 1.5, 4.04, -3.38, -0.534, 5.4, -2.7, 6.03, -2.73, 1.85, 0.919, 5.87, 0.668, -1.23, -0.749, -7.17, 0.538, -4.97, 0.632, 2.87, -0.91, -2.7, 1.39, -2.28, -5.82, -1.8, -0.302, 5.87, 8.8, 2.4, -3.6, 1.84, -3.4, 1.46, -2.02, 3.56, 2.46, 7.01, -2.09, -5.22, 3.7, -3.9, 6.43, -6.2, 9.72, -3.94, -2.37, 1.68, 10.2, 10.2, -2.45, -2.52, -3.85, -6.24, 6.32, -5.07, 4.63, 8.12, 4.69, -2.92, -0.363, 3.76, 2.22, -5.73, -1.74, 1.86, 7.94, -6.45, -0.00233, -0.489, -1.51, 4.77, -7.31, 6.95, -1.15, 4.96, -4.44, 4.58, -8.26, 8.38, -3.83, -1.29, 1, -5.21, -1.64, 4.34, -8.35, 3.86, 6.03, -2.61, -4.7, 0.668, -4.21, -5.43, -0.211, -1.02, -2.38, 0.443, -6.76, 2.47, -0.115, 7.13, 3.75, -1.58, 3.47, 0.841, 1.56, 6.24, -7.6, 6.4, 0.404, 1.96, -1.47, -4.63, 2.75, -4.27, 0.3, 1.69, -3.67, 4.13, 0.703, -7.32, 4.91, -2.84, -5.93, 0.779, -6.11, -1.31, 0.867, -7.44, -1.43, 6.17, -0.297, -4.79, 3.03, 0.381, 2.97, -3.06, -0.489, 4.97, -0.0124, -0.0216, 2.04, -5.23, 5.43, -1.65, -3.13, 1.3, 6.39, -0.475, 4.25, 4.43, 3.68, -2.75, 8.54, 2.06, -1.21, -3.98, -2.38, -0.377, -0.8, -3.01, -1.59], dtype=float32),\n",
       " 10907)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9350b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4452, 11342)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a882c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.158, random_state=42)\n",
    "len(y_test),len(X_test)\n",
    "embedding_size=300\n",
    "fl1_size=2048\n",
    "batch_size=64\n",
    "num_heads=5\n",
    "dropout_rate=0.2 \n",
    "num_batches_per_epoch = len(X_train) // batch_size\n",
    "num_epochs=550\n",
    "tot_loss_epoch=0\n",
    "learning_rate=0.0001\n",
    "clipping_threshold=1e10\n",
    "tot_loss_epoch=0\n",
    "temperature=1\n",
    " \n",
    "decoder_seq_len=max_v\n",
    "encoder_seq_len=max_v\n",
    "\n",
    "n_layers=1\n",
    "Output_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "encoder=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "decoder=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "\n",
    "# encoder_second=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "# decoder_second=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "\n",
    "# encoder_third=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "# decoder_third=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "MyTransformer=Transformer(n_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,decoder_seq_len,clipping_threshold,vocabulary,index_based_vocabulary)\n",
    "output_linear_layer=linear_layer(embedding_size,len(vocabulary),out=True) \n",
    "accuracies=[0,0]\n",
    "mean_acc=0 \n",
    "validation_accuracies=[0]\n",
    "def print_word_from_vocabulary(word_index,vocabulary): \n",
    "    for word,(vector,position), in vocabulary.items():\n",
    "        if position==word_index:\n",
    "            return word\n",
    "@log_time       \n",
    "def training_accuracy_cross_entropy(SigmaZout,target_decoder):\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==np.argmax(target_decoder[n][l]): \n",
    "                    counter_beccate+=1\n",
    "                    print(np.argmax(target_decoder[n][l]),np.argmax(SigmaZout[n][l]))\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "    return np.mean(np.array(taccuracies))\n",
    "\n",
    "\n",
    "def sparse_cross_entropy_validation(X_validation,y_validation,batch_size,transformer,Output_stack,vocabulary,encoder_seq_len,decoder_seq_len,embedding_size):\n",
    "    num_batches_per_epoch = len(X_validation) // batch_size\n",
    "    counter=0\n",
    "    val_acc=[]\n",
    "    for i in range(0,num_batches_per_epoch):\n",
    "        #try: \n",
    "         \n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]  \n",
    "        inputs_e_val,_,mask_e,_=helper.create_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n",
    "        mask_e=cp.transpose(mask_e,(0,2,1)) \n",
    "        inputs_decoder_val,_,mask_d,_=helper.create_decoder_input(y_batch,embedding_size,decoder_seq_len,vocabulary) \n",
    "        mask_d=cp.transpose(mask_d,(0,2,1)) \n",
    "        target_decoder_val,_,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len)\n",
    "        mask_t=cp.transpose(mask_t,(0,2,1)) \n",
    "        \n",
    "        Dout=transformer.forward(inputs_e_val,inputs_decoder_val,X_validation,y_validation,mask_e,mask_d) \n",
    "\n",
    "        SigmaZout=Output_stack.forward(Dout) \n",
    "        acc=training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder_val)\n",
    "        val_acc.append(acc)\n",
    "    return np.mean(np.array(val_acc))\n",
    "\n",
    "def training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder):\n",
    "    #print(SigmaZout.shape)\n",
    "    #print(target_decoder.shape)\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==target_decoder[n][l]: \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(SigmaZout[n][l]),target_decoder[n][l],print_word_from_vocabulary(np.argmax(SigmaZout[n][l]),vocabulary))\n",
    "            #print(\"-------------------------\")\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "\n",
    "    \n",
    "    return np.mean(np.array(taccuracies))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8240e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d29d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0 mean accuracy 0.0 mean accuracy validation 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550: 100%|| 58/58 [02:02<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.787074901430996 mean accuracy 0.6803286637931035 mean accuracy validation 0.3693607954545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/550:  97%|| 56/58 [02:26<00:05,  2.59s/it]"
     ]
    }
   ],
   "source": [
    " \n",
    "for epoch in range(10):\n",
    "     \n",
    "        \n",
    "\n",
    "    print(\"Loss\",tot_loss_epoch/num_batches_per_epoch,\"mean accuracy\",np.mean(np.array(accuracies)),\"mean accuracy validation\",np.mean(np.array(validation_accuracies)))#np.mean(np.array(accuracies))\n",
    "    tot_loss_epoch=0\n",
    "    total_accuracy_epoch=0\n",
    "    mean_acc=0\n",
    "    accuracies=[]\n",
    "     \n",
    "    for i in tqdm(range(0,num_batches_per_epoch),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        #try: \n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]  \n",
    "        \n",
    "        inputs_e,input_e_words,mask_e,word_indexes_encoder=helper.create_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n",
    "        mask_e=cp.transpose(mask_e,(0,2,1))\n",
    "        # print(\"inputs_e.shape\",inputs_e.shape)\n",
    "        # helper.print_matrix(\"input_e_words\",input_e_words)\n",
    "        # helper.print_matrix(\"word_indexes_encoder\",word_indexes_encoder)\n",
    "        # helper.print_matrix(\"mask_e\",mask_e)\n",
    "        inputs_decoder,inputs_decoder_words,mask_d,word_indexes_decoder=helper.create_decoder_input(y_batch,embedding_size,decoder_seq_len,vocabulary) \n",
    "        mask_d=cp.transpose(mask_d,(0,2,1))\n",
    "        # print(inputs_decoder.shape) \n",
    "        # helper.print_matrix(\"inputs_decoder_words\",inputs_decoder_words)\n",
    "        # helper.print_matrix(\"mask_d\",mask_d)\n",
    "        # print(\"word_indexes_decoder\",word_indexes_decoder)\n",
    "\n",
    "\n",
    "        target_decoder,target_decoder_words,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len) \n",
    "        \n",
    "        \n",
    "        mask_t=cp.transpose(mask_t,(0,2,1))\n",
    "        \n",
    "        # helper.print_matrix(\"target_decoder_words\",target_decoder_words)\n",
    "        # helper.print_matrix(\"mask_t\",mask_t)\n",
    "        # print(\"mask_e.shape\",mask_e.shape)\n",
    "        # print(\"mask_d.shape\",mask_d.shape)\n",
    "        # print(\"mask_t.shape\",mask_t.shape)\n",
    "        \n",
    "   \n",
    "        \n",
    "        Dout=MyTransformer.forward(inputs_e,inputs_decoder,X_batch,y_batch,mask_e,mask_d) \n",
    "\n",
    "        SigmaZout=Output_stack.forward(Dout)\n",
    "        #print(SigmaZout.shape)\n",
    "        batch_accuracy=training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder)\n",
    "        accuracies.append(batch_accuracy) \n",
    "        \n",
    "        \n",
    " \n",
    "        Loss = Output_stack.sparse_categorical_crossentropy(SigmaZout,target_decoder,mask_t) \n",
    "        #print(\"Loss\",Loss,\"Batch accuracy\",batch_accuracy)\n",
    "        tot_loss_epoch+=Loss\n",
    " \n",
    "        dL_dDout = Output_stack.grad_sparse_cross_entropy(SigmaZout,target_decoder,mask_t) \n",
    "        #print(dL_dDout.shape)\n",
    "        dL_dInput_encoder,dL_dInput_decoder=MyTransformer.backpropagation(dL_dDout,inputs_decoder_words,input_e_words)#dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot=\n",
    "        \n",
    "#  \n",
    "\n",
    "        Output_stack.update_weights(learning_rate)\n",
    "        \n",
    "        vocabulary=MyTransformer.update_embeddings(inputs_decoder,inputs_e,dL_dInput_decoder,dL_dInput_encoder,inputs_decoder_words,input_e_words,learning_rate,vocabulary)\n",
    " \n",
    "        \n",
    "        # vocabulary=helper.update_wembedding_decoder(0.00001,y_batch, dLoss_dWemb_decoder_tot,vocabulary, decoder_seq_len)\n",
    "        # vocabulary=helper.update_wembedding_encoder(0.00001,X_batch, dLoss_dWemb_encoder_tot,vocabulary,encoder_seq_len)\n",
    "    val_acc=sparse_cross_entropy_validation(X_test,y_test,batch_size,MyTransformer,Output_stack,vocabulary,encoder_seq_len,decoder_seq_len,embedding_size)\n",
    "    validation_accuracies.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1908873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052db673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.00843914658577071 mean accuracy 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550:   0%|          | 0/1113 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_train[start:end]\n\u001b[0;32m     24\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[start:end]  \n\u001b[1;32m---> 26\u001b[0m inputs_e,input_e_words,mask_e\u001b[38;5;241m=\u001b[39mhelper\u001b[38;5;241m.\u001b[39mcreate_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n\u001b[0;32m     27\u001b[0m inputs_decoder,inputs_decoder_words,mask_d\u001b[38;5;241m=\u001b[39mhelper\u001b[38;5;241m.\u001b[39mcreate_decoder_input_teacher_forcing(y_batch,embedding_size,decoder_seq_len,vocabulary) \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#target_decoder,target_decoder_words,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len) \u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "@log_time       \n",
    "def training_accuracy_cross_entropy_teacher_forcing(SigmaZout,target_decoder):\n",
    "    taccuracies=[]\n",
    "    counter_beccate=0\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            if np.argmax(SigmaZout[n])==np.argmax(target_decoder[n]): \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(target_decoder[n][l]),np.argmax(SigmaZout[n][l])) \n",
    "    batch_accuracy=counter_beccate/SigmaZout.shape[0]\n",
    "    taccuracies.append(batch_accuracy)\n",
    "    return np.mean(np.array(taccuracies))\n",
    "\n",
    "for epoch in range(num_batches_per_epoch):\n",
    "    print(\"Loss\",tot_loss_epoch/num_batches_per_epoch,\"mean accuracy\",np.mean(np.array(accuracies)))#np.mean(np.array(accuracies))\n",
    "    tot_loss_epoch=0\n",
    "    total_accuracy_epoch=0\n",
    "    mean_acc=0\n",
    "    accuracies=[]\n",
    "    for i in tqdm(range(0,num_batches_per_epoch),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        #try: \n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]  \n",
    "        \n",
    "        inputs_e,input_e_words,mask_e=helper.create_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n",
    "        inputs_decoder,inputs_decoder_words,mask_d=helper.create_decoder_input_teacher_forcing(y_batch,embedding_size,decoder_seq_len,vocabulary) \n",
    "        #target_decoder,target_decoder_words,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len) \n",
    "        mask_e=cp.transpose(mask_e,(0,2,1))\n",
    "        mask_d=cp.transpose(mask_d,(0,2,1))\n",
    "        #mask_t=cp.transpose(mask_t,(0,2,1))\n",
    "        # print(\"inputs_e.shape\",inputs_e.shape)\n",
    "        # helper.print_matrix(\"input_e_words\",input_e_words)\n",
    "        # helper.print_matrix(\"mask_e\",mask_e)\n",
    "        #helper.print_matrix(\"inputs_decoder_words\",inputs_decoder)\n",
    "        # helper.print_matrix(\"mask_d\",mask_d)\n",
    "        # helper.print_matrix(\"target_decoder_words\",target_decoder_words)\n",
    "        # helper.print_matrix(\"mask_t\",mask_t)\n",
    "        # print(\"mask_e.shape\",mask_e.shape)\n",
    "        # print(\"mask_d.shape\",mask_d.shape)\n",
    "        # print(\"mask_t.shape\",mask_t.shape)\n",
    "        \n",
    "        \n",
    "        Ecout=encoder.forward(inputs_e,mask_e)\n",
    " \n",
    "        target_d=helper.pad_sequences(y_batch,lenght=decoder_seq_len,target_type=\"target\")\n",
    "            \n",
    "        target_d=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in target_d] \n",
    "        #print_matrix(target_d) \n",
    "        dL_Ecout_tot=0\n",
    "        tot_loss=0\n",
    "        for step in range(0,inputs_decoder.shape[0]):\n",
    "                inputs_d=inputs_decoder[step]\n",
    "                #mask_d = cp.array([1 if x <= step else 0 for x in range(decoder_seq_len)]).T\n",
    "                mask_d=cp.array([cp.array([1 if x <= step else 0 for x in range(decoder_seq_len)]).T for _ in range(batch_size)])\n",
    "                mask_d=np.expand_dims(mask_d,axis=2)\n",
    "                #print(mask_d.shape)\n",
    "                target=cp.array([helper.get_one_hot(x[step], vocabulary) for x in target_d])\n",
    "                #print(inputs_d.shape)\n",
    "                Dout=decoder.forward(inputs_d,Ecout,mask_d,mask_e) \n",
    "                #print(Dout.shape)\n",
    "                Dout=Dout[:, step, :]\n",
    "                #Dout=Dout.reshape(Dout.shape[0],Dout.shape[1]*Dout.shape[2])\n",
    "                SigmaZout=Output_stack.forward(Dout)\n",
    "                #print(SigmaZout.shape,target.shape)\n",
    "                batch_accuracy=training_accuracy_cross_entropy_teacher_forcing(SigmaZout,target)\n",
    "                accuracies.append(batch_accuracy) \n",
    "                \n",
    "        \n",
    "                Loss = Output_stack.cross_entropy_loss(SigmaZout,target) #mask_t\n",
    "                #print(\"Loss\",Loss)#\"Batch accuracy\",batch_accuracy\n",
    "                tot_loss+=Loss\n",
    "        \n",
    "                dL_dDout = Output_stack.grad_cross_entropy(SigmaZout,target) #mask_t\n",
    "                #print(dL_dDout.shape)\n",
    "                dL_dDout=cp.tile(dL_dDout[:, cp.newaxis, :], (1, decoder_seq_len, 1))\n",
    "                \n",
    "                #dL_dDout=dL_dDout.reshape(batch_size,decoder_seq_len,embedding_size)\n",
    "                \n",
    "                dL_Ecout,dL_inputs_decoder,dLoss_dWemb_decoder=decoder.backpropagation(dL_dDout)\n",
    "                dL_Ecout_tot+=dL_Ecout\n",
    "                _=decoder.update_weights(learning_rate,vocabulary)\n",
    "                Output_stack.update_weights_tf(learning_rate)\n",
    "        tot_loss_epoch+=tot_loss/inputs_decoder.shape[0]\n",
    "        #dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot=MyTransformer.backpropagation(dL_dDout)\n",
    "        dL_inputs_e,dLoss_dWemb_encoder=encoder.backpropagation(dL_Ecout_tot)\n",
    "        _=encoder.update_weights(learning_rate,vocabulary)\n",
    "#  \n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "        #vocabulary=helper.update_wembedding_decoder(0.00001,y_batch, dLoss_dWemb_decoder_tot,vocabulary, decoder_seq_len)\n",
    "        #vocabulary=helper.update_wembedding_encoder(0.00001,X_batch, dLoss_dWemb_encoder_tot,vocabulary,encoder_seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a523cc",
   "metadata": {},
   "source": [
    "To identify where to place    values in   scaled QK scaled  , consider how the mask interacts with the sequence positions. Shape of   scaled QK scaled  : For a batch size of  N,   scaled QK scaled  typically has the shape (  , num_heads , seq_len , seq_len ) (N,num_heads,seq_len,seq_len), where seq_len seq_len is the length of the input sequence. Each element in   scaled [  ,  ,  ,  ] QK scaled  [i,h,j,k] represents the attention score between the  j-th query position and the  k-th key position for the  h-th attention head in the  i-th batch item. Mask Shape Alignment: The mask typically has shape (  , seq_len ) (N,seq_len) and marks each position with a 1 (for valid tokens) or a 0 (for padding tokens). To align with   scaled QK scaled  , you expand the mask to shape (  , 1 , 1 , seq_len ) (N,1,1,seq_len). After expansion, the mask will effectively broadcast over the query positions (dimension 2 of   scaled QK scaled  ) and attention heads (dimension 1). Applying    Masking: When broadcasting the mask, only key positions that correspond to padding tokens (mask=0) in the last dimension will be assigned   . This is why adding ( mask  1 )  1 0 9 (mask1)10 9 works; any position where the mask is 0 will add  1 0 9 10 9 to   scaled QK scaled  , effectively zeroing out the attention after the softmax. So, for every padding token position (where mask[i, k] = 0), every attention score   scaled [  , : , : ,  ] QK scaled  [i,:,:,k] will be set to a large negative value, ensuring no attention is paid to padding tokens across all queries and heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634240f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.37, -1.45, 2.02, -0.26, 0.333, -0.391, 1.99, -0.604, -0.584, 0.184, 0.922, -0.555, -0.528, 0.44, -0.242, 0.749, 1.24, 0.674, -0.0289, 0.0349, -0.418, -0.262, -0.415, -0.931, -1.76, -0.447, 0.703, 2.63, 0.596, -0.222, -1.3, 0.0114, 0.596, -0.87, -0.492, 0.0834, -0.616, 0.361, 1.03, 2.06, -0.77, 0.471, 0.344, 2.18, 0.541, -2.58, 2.16, -1.38, 1.61, 0.0977, -0.866, 0.659, -0.834, 0.855, -2.03, 0.000912, 1.22, -1.42, 0.258, -0.855, -0.123, -1.12, -1.07, -0.63, -0.0727, -0.0296, -2.37, 0.993, -1.82, -0.436, 0.612, 0.438, 0.221, 1.24, -0.135, -0.894, 0.155, 0.167, 0.0837, 1.14, -0.236, -0.657, 0.111, -0.463, -0.538, -0.847, -0.551, -0.581, 0.755, 0.68, -0.635, -0.585, -1.22, -1.84, -0.29, 1.83, -0.583, -1.74, -0.512, -0.712, -0.43, 1.1, 0.947, -0.572, -0.66, -0.528, 3.82, 0.223, -0.0052, -1.21, 2.11, 0.419, 0.108, 0.54, 1.22, 0.569, 0.222, -0.577, 0.886, -1.54, 0.354, 0.892, 0.447, 0.0819, -0.168, 0.188, -0.292, -0.616, -0.298, -2.27, -1.56, -0.397, 0.899, -1.08, -1.36, 1.34, 0.682, 1.86, 0.243, 0.892, 0.0116, -0.7, -2.01, 0.483, -1.42, 1.02, -0.362, -0.494, 1.98, 0.318, -1.13, 0.9, -1.66, 1.98, -0.916, -0.12, -0.524, -1.14, 0.171, 1.52, 0.156, -0.17, -0.465, -0.544, 0.462, -0.494, -0.101, 0.708, 1.29, 1.07, 0.169, 0.449, 1.99, -1.07, 0.226, -0.462, 0.067, 0.969, 0.514, 0.003, 0.863, 0.312, -1.44, -1.84, -0.105, 0.77, 0.268, -0.0641, -0.423, 0.0831, -0.947, 0.662, 0.675, 1.19, 0.701, -0.186, -1.62, 0.386, -0.864, -2.04, 0.024, -0.397, -0.351, 1.71, -1.27, -0.0627, 0.884, -0.532, -0.366, -0.0249, -0.261, 0.255, -0.302, -0.453, -0.349, 2.29, 0.173, -0.515, -0.0477, 0.12, 2.58, -0.355, -0.885, -1.07, -0.298, 2.29, 0.21, -0.701, 1.11, -1.28, -0.308, 0.795, 0.366, -1.18, -0.442, -2.62, 0.827, 1.75, -0.442, 1.21, 0.686, -1.73, -1.23, -0.139, 0.23, 0.535, 0.278, -0.761, 1.04, -1.43, 1.42, 0.524, -0.911, -2.17, -0.563, -0.218, 0.653, -0.709, 0.22, 1.61, 0.34, -0.329, -0.228, 0.874, -0.42, -0.382, -1.12, -0.558, 0.984, -0.398, 1.12, 1.41, -0.066, -0.24, 0.858, 0.193, -1.76, 0.033, 0.297, 1.44, -0.543, 0.555, -1.06, 0.599, -0.146, 0.757, 1.34, -0.49, -0.152, 0.925, 0.592, -0.134, -0.63, 0.075, -0.091, -0.472, -0.374, -0.981, -1.21, 1.37],\n",
       "       [-1.41, -1.4, 1.6, -1.06, -0.499, 0.359, 1.26, 0.411, 1.12, 0.429, 0.683, -0.958, -0.909, -0.258, -0.179, 0.676, 0.223, 0.965, 0.379, 0.254, 0.136, -0.18, -0.283, -2.3, -2.32, 0.915, -0.619, 1.82, 1.57, 1.22, -1.25, -0.154, -0.316, -1.12, 0.744, 0.836, -0.0201, 0.674, 0.478, 0.922, 0.0382, 0.856, 0.754, 1.74, 0.431, -0.346, 1.71, 0.0126, 1.24, -0.0703, -0.476, -0.18, 0.308, 0.127, -1.08, -0.264, 0.922, -0.798, 0.408, -1.45, -1.28, -0.954, -0.216, -1.76, -0.113, 0.832, -2.67, 0.974, -0.937, 0.215, -0.432, -0.239, 0.472, 1.27, -0.375, -1.31, -0.837, -0.0656, 0.273, 0.745, 0.486, -0.743, -2.27, -1.07, -1.34, 0.0399, -0.185, 0.404, 0.618, 1.66, -1.94, 0.683, -0.975, -1.86, 0.0327, 0.21, -0.181, -1.47, -0.985, -0.827, 0.53, 0.955, -0.224, 0.52, 0.144, -0.742, 2.38, 0.359, -1.3, -0.362, 1.76, -1.02, 0.709, 0.31, 1.03, -0.0937, -0.276, -0.125, -0.0355, -0.314, -0.143, 1.39, 0.216, 0.539, 0.467, 0.0643, 0.0719, 0.0057, -1.16, -1.11, -0.428, 0.936, -0.55, -0.519, -0.0482, 0.342, 0.537, 1.12, 0.908, 1.29, -0.468, -1.38, -1.25, 0.0798, 0.367, 0.958, 0.398, -0.765, 2.11, 1.03, 0.224, 0.527, -0.629, 1.7, -0.959, 0.669, -2.1, -2.16, 0.16, 1.22, 0.336, 0.211, -1.94, -0.88, 1, -0.388, 0.443, 1.43, 1.14, 0.273, 1.26, 0.388, 0.695, -0.0923, 0.768, -0.675, -0.443, 0.202, 1.71, 0.416, 0.166, -1.32, -1.25, -2.22, 0.6, -0.778, -0.112, 0.189, -0.355, -0.233, -1.65, 1.17, 0.231, 0.909, 0.899, -0.793, -0.122, 0.878, 1.29, -2.26, -0.207, -0.764, 0.0283, 0.925, -0.984, 0.491, 0.649, -0.879, 0.464, 0.312, -1.28, -0.0056, 0.541, -0.175, 0.302, 2.05, -1.09, 0.206, -0.126, -0.268, 1.85, -0.422, -0.67, -1.23, -0.452, 1.36, 0.744, -1.24, 0.956, -0.348, -0.603, 0.251, 0.558, -1.4, -0.599, -2.41, 1.29, 1.26, 0.211, 1.18, 0.828, -0.94, -0.884, 0.728, 0.664, -0.0845, 0.643, -1.57, -0.177, -0.432, 2.36, 0.593, 0.432, -0.641, 0.759, -0.0208, 0.757, -1.64, 0.448, 1.63, -0.541, 0.0401, -0.0306, 0.82, -0.875, -0.254, -1.93, -0.463, 0.939, -0.557, 1.74, 0.912, 0.324, -0.0317, 1.11, -0.727, -1.73, -2.15, -0.183, 1.28, -0.74, 0.679, -2.11, 1.61, 0.293, 2.68, 0.735, 0.263, -0.4, 1.28, 0.196, 0.383, -1.07, -0.337, -0.69, -2.52, -0.851, -0.175, -1.19, 1.18],\n",
       "       [0.614, -1.64, 1.12, -1.71, -0.0118, 0.485, 2.15, 0.505, -0.948, 0.906, 1.25, -0.0288, -0.123, -0.269, -0.542, 0.235, 0.125, 0.711, -1.36, 0.859, -1.26, -0.523, 0.0717, -0.866, -1.23, 0.78, -0.409, 2.59, 1.8, -0.07, -1.43, 0.914, -0.208, -1.22, 0.843, 1.37, -0.17, 0.969, 0.552, 1.49, -0.412, -0.265, 0.18, 1.71, 0.693, -1.97, 2.14, -0.946, 1.55, 0.202, -0.167, -0.495, -0.501, 0.0241, -1.47, -0.134, 1.37, -0.767, 1.15, -1.67, -0.373, -0.975, -1.08, -0.46, -0.131, -0.221, -2.18, 1.4, -1.44, 0.221, -0.619, -0.673, -0.0493, 0.843, -0.417, -1.11, -0.574, -0.571, -0.0248, 1.08, 0.23, -0.668, -2.57, -0.778, -1.11, -0.969, -0.163, 0.365, 0.746, 0.213, -1.22, 0.307, -1.74, -1.6, -0.575, 0.184, -0.297, -1.58, -0.81, -1.33, 0.464, 1.04, 0.574, 0.0698, -0.296, 0.146, 0.335, -0.409, -0.919, -0.875, 0.642, -1.11, 1.44, 0.719, -0.428, 1.41, -0.68, 0.296, 0.892, -0.43, 0.0463, 0.945, 0.599, -0.0897, -1.34, -0.391, -0.0938, -0.116, -0.538, -1.16, -0.0308, 0.85, 0.321, -1.72, 0.039, 0.621, 0.309, 1.03, 0.789, 0.961, 0.32, -1.36, -1.38, 0.267, -1.02, 0.969, -0.122, -0.141, 1.39, 2.13, -0.238, 1.29, -1.41, 1.64, -1.91, 0.0172, -1.68, -1.75, 0.133, 2.41, 0.0863, -0.042, 0.0544, -0.328, -0.0305, 0.22, 0.136, 1.3, 0.824, -0.0685, 1.58, 0.569, 2.19, -1.11, 0.0968, -0.39, 0.402, 0.847, 1.82, 0.135, 0.734, -1.82, -1.67, -2.26, 0.473, -0.18, 0.179, 0.095, 0.252, -0.934, -0.842, 0.748, 0.101, 1.14, -0.6, 0.187, -0.565, 1.21, 0.308, -1.78, -0.291, 0.0845, -0.408, 1.8, -0.353, -0.9, 1.27, -0.685, -0.261, -0.686, -1.66, -0.198, -0.474, -0.0984, 0.279, 2.27, -0.666, 0.0238, -0.106, -0.000628, 0.257, 0.458, -0.749, -1.04, 2.14, 1.04, 1.41, -0.296, 0.951, -1.05, -0.842, -0.474, 1.49, -1.35, 0.169, -0.448, 0.907, 1.34, -0.0207, 1.2, 0.645, -0.634, -0.987, 0.581, 0.98, 0.314, 0.0194, -1.53, -0.386, 0.333, 2.11, 0.275, -0.0331, -0.585, 0.125, -0.927, 0.723, 0.415, 0.361, 1.09, 1.35, -0.418, -0.468, 0.434, -0.468, 0.496, -0.305, -0.0122, 1.21, -0.822, 1.78, 0.728, 0.6, 0.459, 1.28, -1.21, -0.562, -2.38, -0.598, 0.933, -0.524, 0.535, -2.24, 0.853, 0.652, 1.44, 1.91, 0.0245, 0.524, 0.864, 1.08, -0.715, -0.405, -0.947, 0.115, -1.81, -1.3, -0.796, -1.91, 1.3]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426995db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 13, 300)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(Dout[:, np.newaxis, :], (1, 13, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare\n"
     ]
    }
   ],
   "source": [
    "for i,(j,k) in vocabulary.items():\n",
    "    #print(i,k)\n",
    "    if k==775:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.29, -4.52, 6.58, -2.67, -1.89, 1.38, 4.31, -3.22, -10.3, -1.86, -0.165, -2.48, 9.21, 0.397, 1.59, 7.13, -6.91, 4.72, -1.58, -0.172, 4.32, 3.8, 1.43, -5.23, -7.19, 1.69, 4.76, 6.03, -3.68, -4.43, -0.472, -1.38, 6.1, 2.23, 0.887, -5.05, -1.16, 0.472, 6.07, 6.63, 1.5, -2.8, -7.84, 8.3, 2.25, -13.7, 4.49, 1.6, 3.39, -6.48, -7.28, -0.184, -2.28, -3.54, -4.86, 4.98, 6.52, -3.3, 7.13, -2.69, -0.978, -2.03, -4.34, -0.0675, -4.21, 3.58, -9.06, 0.371, 0.468, 1.56, 0.745, -5.18, -5.34, -5.32, -0.718, 0.632, 1.63, 3.74, -2.94, 5.61, -0.722, -3.61, -3.2, -1.7, -5.03, -1.62, 1.89, -1.64, 6.58, 2.95, -10.6, 1.52, -6.33, -7.92, -5.77, 4.34, -0.0952, -1.63, -0.553, -0.957, 0.99, -2.37, 3.49, -3.04, 1.74, 4.95, 11.8, 0.265, -4.32, 5.9, 3.63, 0.339, 2.86, -1.67, -1.76, 0.766, -3.32, 4.36, -0.622, -1.46, 4.53, 1.96, 0.922, -0.981, 2.86, 2.27, 2.65, 1.67, 0.0472, -3.75, -6.28, -1.6, 2.4, -0.826, 4.83, -6, -0.0516, 1.95, -1.24, 4.48, -3.47, -0.587, -5.91, 3.51, -4.78, -0.428, -4.84, 0.476, 10.3, 1.23, -2.86, -1.37, -0.346, 3.42, -1.12, 4.54, -2.6, 0.17, -2.31, 5.26, 5.8, 8.39, -6.88, -3.1, -0.798, -1.88, -1.21, 7.81, 1.87, 4.69, 0.746, 7.02, 5.14, -2.88, 4.15, -2.83, 5.87, 1.71, 2.81, -3.75, 3.28, -11.9, -2.58, -5.91, 1.13, 2.79, 2.79, -2.02, -0.957, -1.8, 1.35, 4.26, 6.17, 3.6, 2.16, 3.13, -0.854, 10.2, -2.07, -9.68, 2.2, -0.799, 7.39, 8.04, 1.21, 6.69, -0.302, -4.33, 2.12, -0.99, -7.7, 0.765, 1.27, 0.75, -4.04, 8.9, -3.62, 2.47, 3.74, 4.85, 5.78, -1.26, -7.27, -3.62, 5.2, 9.79, 2.46, -6.25, 5.65, 2.95, -0.848, 2.27, 3.52, -3.82, -0.333, -5.25, 2.65, 3.7, -6.49, 0.463, 1.33, -6.31, 1.85, 0.486, 0.216, -1.13, 7.71, -3.44, 4.6, -8.98, 10.4, -3.87, -1.83, -2.21, -0.618, -1.18, -0.666, -3.63, 0.421, 5.58, 5.23, -0.541, 5.17, 4.31, -2.18, -2.06, -3.73, -0.0329, 5.45, -6.7, -0.49, 4.69, 0.407, 2.87, -1.45, -5.18, -3.36, -7.6, 5.32, -0.654, 2.86, 1.41, -1.81, 3.77, -0.498, 2.77, 4.2, 0.539, 3.52, -0.979, -2.79, 1.96, 0.588, -2.52, -1.21, -6.74, -1.87, -4.61, 0.664, 2.34], dtype=float32),\n",
       " 3787)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3,50,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300 #dAttention.shape \n",
    "3, 10, 15, 50 #dAttention_weights\n",
    "3, 10, 50, 30 #self.K\n",
    "3, 10, 50, 30 #self.V\n",
    "300, 300#k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebeffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)\n",
    "300, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02a010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)@self.k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36268ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 30#dAttention_weights@self.K\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da8522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 15, 300#self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67c183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 300, 300#dAttention*self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
