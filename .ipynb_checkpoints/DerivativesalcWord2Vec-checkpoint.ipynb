{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a62b3d20-53d1-4dc4-b016-ee5307a328e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\python312\\\\lib\\\\site-packages')\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import re \n",
    "from functools import partial\n",
    "from numba import njit\n",
    "import time\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit\n",
    "from numba.typed import Dict\n",
    "from numba.types import int64, unicode_type\n",
    "import cupy as cp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "568da604-e309-4207-b31a-98df212dba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"data/bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72551055-5dbb-448c-85f1-392f51f8497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  29457\n",
      "29457\n"
     ]
    }
   ],
   "source": [
    "def create_vocabulary(complete_text):\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', complete_text).split()\n",
    "        vocabulary = list(set(text))\n",
    "        print(\"Vocabulary size: \", len(vocabulary))\n",
    "        return vocabulary\n",
    "complete_text = ' '.join(df[\"text\"].tolist())\n",
    "vocabulary=create_vocabulary(complete_text)\n",
    "vocabulary = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba4ab941-bd43-4766-96f8-44187d619588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@njit\n",
    "def numpy_matrix_test():\n",
    "    A = np.zeros((12, 12))\n",
    "    return A\n",
    "numpy_matrix_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a880ff0-3c52-45e5-b09a-7e9ebe516fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def log_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Execute the wrapped function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90e39123-6ed9-47ce-aa8c-ff1336631ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'inputs_window_words' executed in 0.2666 seconds\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "side_window_size=3\n",
    "def input_one_hot_vectors(words,vocabulary):\n",
    "     \n",
    "    inputs=np.zeros((len(words),len(vocabulary)),int)\n",
    "     \n",
    "    for i in range(len(words)): \n",
    "        inputs[i][vocabulary[words[i]]]=1\n",
    "        \n",
    "    return inputs \n",
    "\n",
    " \n",
    "\n",
    "@log_time \n",
    "def inputs_window_words(sequence,vocabulary,side_window_size):\n",
    "    training_samples=[]\n",
    "    for i in range(side_window_size,len(sequence)-side_window_size):\n",
    "        words_before=sequence[i-side_window_size:i]\n",
    "        words_after=sequence[i+1:i+1+side_window_size]\n",
    "        #print(words_before)\n",
    "        #print(words_after)\n",
    "        words_input=words_before+words_after\n",
    "        X_i=input_one_hot_vectors(words_input,vocabulary)\n",
    "        y_i=input_one_hot_vectors([sequence[i]],vocabulary)\n",
    "        #print(X_i,y_i)\n",
    "        training_sample=[X_i,y_i]\n",
    "        training_samples.append(training_sample)\n",
    "    return training_samples\n",
    "\n",
    "\n",
    "\n",
    "vocab_dict = {word: idx for idx, word in enumerate(vocabulary)}    \n",
    "for i in range(1):\n",
    "    \n",
    "    training_samples=inputs_window_words(re.sub(r'[^\\w\\s]',' ',df[\"text\"].iloc[i]).split(),vocab_dict,side_window_size)\n",
    "    \n",
    "    print(len(training_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957218e8-0f23-4a21-9ab8-5e091bcb19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa25f578-980e-41ed-a570-52fb0e09182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 29457)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xi=cp.array(training_samples[0][0])\n",
    "Xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da4e1f79-0e0b-48a4-8a33-e4e3d76bc9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 29457)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yi=cp.array(training_samples[0][1])\n",
    "yi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "331b73eb-a1ad-4ae2-9373-bf35ed1d5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=300\n",
    "semi_context_window=3\n",
    "\n",
    "W1= cp.random.rand(len(vocabulary),embedding_size)   \n",
    "B1 = cp.random.rand(embedding_size)\n",
    " \n",
    "#W2 = cp.random.rand(embedding_size, len(vocabulary))\n",
    "#B2 = cp.random.rand(len(vocabulary))\n",
    "W2C = cp.random.rand(semi_context_window * 2 * embedding_size, len(vocabulary))\n",
    "B2C = cp.random.rand(len(vocabulary))\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c91f6df-207f-4671-906f-459de6ba483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_time\n",
    "def softmax(x, axis=-1):\n",
    "        x = cp.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = cp.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / cp.sum(e_x, axis=axis, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3954f0cf-2f13-4634-8253-271bf81c2fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'softmax' executed in 0.0010 seconds\n",
      "(6, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1800)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_Z1= softmax(cp.matmul(cp.array(Xi), W1) +  B1)\n",
    "print(sigma_Z1.shape)\n",
    "sigma_Z1 = sigma_Z1.reshape(1, sigma_Z1.shape[0] * embedding_size)\n",
    "sigma_Z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd0f57fc-597e-48d5-bcfc-2b6121a00c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'softmax' executed in 0.0000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 29457)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_Z2 = softmax(cp.matmul(sigma_Z1, W2C) + B2C)\n",
    "sigma_Z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "415da4d6-0406-4e39-beef-3fc8e53e7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'softmax' executed in 0.0000 seconds\n",
      "Function 'softmax' executed in 0.0010 seconds\n",
      "Function 'forward' executed in 0.0030 seconds\n"
     ]
    }
   ],
   "source": [
    "@log_time\n",
    "def forward(Input):\n",
    "    global W1,B1,W2C,B2C\n",
    "     \n",
    "    \n",
    "    sigma_Z1 = softmax(cp.matmul(cp.array(Input), W1) +  B1)\n",
    "\n",
    "\n",
    "    if flattening_strategy == \"concat\":\n",
    "        sigma_Z1 = sigma_Z1.reshape(1, sigma_Z1.shape[0] * embedding_size)\n",
    "        sigma_Z2 = softmax( cp.matmul(sigma_Z1, W2C) + B2C)\n",
    "\n",
    "\n",
    "    if flattening_strategy == \"average\":\n",
    "        sigma_Z1 = cp.mean(sigma_Z1, axis=0).reshape(1, sigma_Z1.shape[1])\n",
    "        sigma_Z2 = softmax(cp.matmul(sigma_Z1, W2) + B2)\n",
    "\n",
    "    return [sigma_Z1, sigma_Z2]\n",
    "\n",
    "flattening_strategy= \"concat\"\n",
    "sigma_Z1, sigma_Z2=forward(Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f10fcc17-b7ce-499f-abc2-48cda55ab7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'cross_entropy_loss' executed in 0.0010 seconds\n",
      "loss: 10.301150539430743\n"
     ]
    }
   ],
   "source": [
    "@log_time\n",
    "def cross_entropy_loss(predictions, target):\n",
    "    # Cross-entropy loss for a batch of predictions and targets\n",
    "    batch_loss = -cp.sum(target * cp.log(predictions + 1e-9), axis=1)\n",
    "    return cp.mean(batch_loss)\n",
    "\n",
    "Loss=cross_entropy_loss(sigma_Z2, yi)\n",
    " \n",
    "print(\"loss:\", Loss)\n",
    "\n",
    "dLoss_dZ2=sigma_Z2-yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "693fd649-163f-4b08-b315-b44ba453b92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 29457), (1800, 29457), (1, 1800), (6, 29457))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dZ2.shape,W2C.shape,sigma_Z1.shape,Xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ad09fae-52ee-4f2d-a32b-b4ea8c0661b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29457, 300), (29457, 300))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding Weights C\n",
    "dL_dSigmaZ1=cp.matmul(dLoss_dZ2,W2C.T)\n",
    "dL_dZ1=dL_dSigmaZ1*sigma_Z1*(1-sigma_Z1)\n",
    "dL_dZ1=dL_dZ1.reshape(2*semi_context_window,embedding_size)\n",
    "dL_dW1=cp.matmul(dL_dZ1.T,Xi).T \n",
    "dL_dW1.shape,W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "868349de-c504-41c4-a300-2c4f818d46ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (300,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding Bias C\n",
    "dL_dB1=cp.sum(dL_dZ1,axis=0).T\n",
    "dL_dB1.shape,B1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6c58021b-2df1-4a08-9b25-e3f53d664e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1800, 29457), (1800, 29457))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding W2C\n",
    "dL_dW2=dLoss_dZ2.T@sigma_Z1 \n",
    "dL_dW2=dL_dW2.T\n",
    "dL_dW2.shape,W2C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "402f5322-e12b-4689-a65f-078ad278ed29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29457, 1), (29457,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding B2C\n",
    "dL_dB2=dLoss_dZ2.T \n",
    "dL_dB2.shape,B2.reshape(B2.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "75cf1a39-4fde-4f60-beb0-a2c2fe3c6353",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6, 300) (1, 1800)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dL_dSigmaZ1\u001b[38;5;241m=\u001b[39mdLoss_dZ2\u001b[38;5;129m@W2\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      3\u001b[0m dL_dSigmaZ1\u001b[38;5;241m=\u001b[39mdL_dSigmaZ1\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m6\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m dL_dZ1\u001b[38;5;241m=\u001b[39m\u001b[43mdL_dSigmaZ1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msigma_Z1\u001b[49m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msigma_Z1)\n\u001b[0;32m      5\u001b[0m dL_dW1\u001b[38;5;241m=\u001b[39mdL_dZ1\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@Xi\u001b[39m\n\u001b[0;32m      6\u001b[0m dL_dW1\u001b[38;5;241m=\u001b[39mdL_dW1\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:1287\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__mul__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\_kernel.pyx:1315\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\internal.pyx:381\u001b[0m, in \u001b[0;36mcupy._core.internal._broadcast_core\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6, 300) (1, 1800)"
     ]
    }
   ],
   "source": [
    "#Gradient Embedding Weights\n",
    "dL_dSigmaZ1=dLoss_dZ2@W2.T\n",
    "dL_dSigmaZ1=dL_dSigmaZ1.repeat(6,axis=0)\n",
    "dL_dZ1=dL_dSigmaZ1*sigma_Z1*(1-sigma_Z1)\n",
    "dL_dW1=dL_dZ1.T@Xi\n",
    "dL_dW1=dL_dW1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acfdf36f-8460-4899-bec0-4453857ced48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (300,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding Bias\n",
    "dL_dSigmaZ1=dLoss_dZ2@W2.T\n",
    "dL_dSigmaZ1=dL_dSigmaZ1.repeat(6,axis=0)\n",
    "dL_dZ1=dL_dSigmaZ1*sigma_Z1*(1-sigma_Z1)\n",
    "dL_dB1=cp.sum(dL_dZ1,axis=0).T\n",
    "dL_dB1.shape,B1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66f86fb5-4eec-45b1-a4a1-6af5ea95fcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 29457), (300, 29457))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding W2\n",
    "dL_dW2=dLoss_dZ2.T@sigma_Z1 \n",
    "dL_dW2=dL_dW2.T\n",
    "dL_dW2.shape,W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "04e5ed94-14ce-4246-8768-f0ec06dfa1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29457, 1), (29457,))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Embedding B2\n",
    "dL_dB2=dLoss_dZ2 \n",
    "dL_dB2=dL_dB2.T\n",
    "dL_dB2.shape,B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "59030c48-e6c8-4de0-8cc7-3f70281b2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1311914e-05])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dB2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "56da858e-134b-4b66-b8f9-21942eddb67a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigma_zout_one' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 48\u001b[0m\n\u001b[0;32m     41\u001b[0m         words_len_embedding_bias \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m dLoss_db1\n\u001b[0;32m     47\u001b[0m learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m   \n\u001b[1;32m---> 48\u001b[0m a\u001b[38;5;241m=\u001b[39mfast_backpropagation_gpu(dLoss_dZ2,\u001b[43msigma_zout_one\u001b[49m,sigma_zout_output,Xi,\n\u001b[0;32m     49\u001b[0m                words_len_embedding_layer,\n\u001b[0;32m     50\u001b[0m                 words_len_embedding_bias,\n\u001b[0;32m     51\u001b[0m                 outlayer_maps_vocab_concat,\n\u001b[0;32m     52\u001b[0m                 out_bias_maps_vocab_concat,\n\u001b[0;32m     53\u001b[0m                 embedding_size,\n\u001b[0;32m     54\u001b[0m                 semi_context_window,\n\u001b[0;32m     55\u001b[0m                 learning_rate)    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigma_zout_one' is not defined"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "\n",
    "@log_time\n",
    "def fast_backpropagation_gpu(dLoss_dZ2, sigma_Z_1, sigma_Z_2, Xi,\n",
    "                             words_len_embedding_layer,\n",
    "                             words_len_embedding_bias,\n",
    "                             outlayer_maps_vocab_concat,\n",
    "                             out_bias_maps_vocab_concat,\n",
    "                             embedding_size,\n",
    "                             semi_context_window,\n",
    "                             learning_rate):\n",
    "    \n",
    "    # Convert everything to CuPy arrays to leverage GPU acceleration\n",
    "    \n",
    "\n",
    "    if flattening_strategy == \"concat\":\n",
    "        # Matrix multiplication on GPU\n",
    "        dLoss_dW2 = cp.matmul(sigma_Z_1.T, dLoss_dZ2)  # (1800, 29457)\n",
    "\n",
    "        # Gradient of loss with respect to b2\n",
    "        dLoss_db2 = cp.sum(dLoss_dZ2, axis=0)  # (29457,)\n",
    "\n",
    "        # Gradient of loss with respect to Z1\n",
    "        dLoss_dZ1 = cp.matmul(dLoss_dZ2, outlayer_maps_vocab_concat.T)  # (1, 1800)\n",
    "\n",
    "        # Softmax gradient with element-wise operations on GPU\n",
    "        dZ1_dPreSoftmax = sigma_Z_1 * (1 - sigma_Z_1)\n",
    "        dLoss_dPreSoftmax = dLoss_dZ1 * dZ1_dPreSoftmax\n",
    "\n",
    "        # Gradient of loss with respect to W1\n",
    "        dLoss_dW1 = cp.matmul(Xi.T, dLoss_dPreSoftmax.reshape(Xi.shape[0], -1))  # (29457, 1800)\n",
    "\n",
    "        # Gradient of loss with respect to b1\n",
    "        dLoss_db1 = cp.sum(dLoss_dPreSoftmax, axis=(0, 1))  # (300,)\n",
    "\n",
    "        # Update weights and biases (in-place operations on GPU)\n",
    "        outlayer_maps_vocab_concat -= learning_rate * dLoss_dW2\n",
    "        out_bias_maps_vocab_concat -= learning_rate * dLoss_db2\n",
    "        words_len_embedding_layer -= learning_rate * dLoss_dW1\n",
    "        words_len_embedding_bias -= learning_rate * dLoss_db1\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "learning_rate=0.01   \n",
    "a=fast_backpropagation_gpu(dLoss_dZ2,sigma_zout_one,sigma_zout_output,Xi,\n",
    "               words_len_embedding_layer,\n",
    "                words_len_embedding_bias,\n",
    "                outlayer_maps_vocab_concat,\n",
    "                out_bias_maps_vocab_concat,\n",
    "                embedding_size,\n",
    "                semi_context_window,\n",
    "                learning_rate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0687bb-b2aa-4d01-9a97-17004bb9ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cp.cuda.runtime.getVersion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496f388-a696-4c94-81b9-1c03129f37c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c0343-6fdc-4c89-9b75-ceddd4df00e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada8503-3aa1-43c6-8a7e-468b898abc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5b7e2-b0db-4f02-a1cd-578337e9a28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0187890-20f2-46ba-a3a2-250e6e7803dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfc2b4-8d27-4c85-ae4b-4098e57d21c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3751aa-38cf-44f3-8730-cc09500309b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665d9aa8-7430-4d50-b5ad-5f5aa0aa1fc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs_window_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m----> 2\u001b[0m     training_samples\u001b[38;5;241m=\u001b[39m\u001b[43minputs_window_words\u001b[49m(re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i])\u001b[38;5;241m.\u001b[39msplit(),vocabulary,side_window_size)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(training_samples))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs_window_words' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    training_samples=inputs_window_words(re.sub(r'[^\\w\\s]',' ',df[\"text\"].iloc[i]).split(),vocabulary,side_window_size)\n",
    "    print(len(training_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca966219-8214-4440-b38b-13f99665cadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524d6d9-651a-4982-957d-a9b041159445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    start = time.time()\n",
    "    training_samples=inputs_window_words(re.sub(r'[^\\w\\s]',' ',df[\"text\"].iloc[i]).split(),vocabulary,side_window_size)\n",
    "    end = time.time()\n",
    "    print(len(training_samples),\" delta t\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e94638-3929-4343-beee-78cf2a026c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0.0\n",
      "744  delta t 3.73740816116333\n",
      "294  delta t 1.3751134872436523\n",
      "242  delta t 1.2456028461456299\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[0;32m     36\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 37\u001b[0m     training_samples\u001b[38;5;241m=\u001b[39m\u001b[43minputs_window_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[^\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43mside_window_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(training_samples),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m delta t\u001b[39m\u001b[38;5;124m\"\u001b[39m,end \u001b[38;5;241m-\u001b[39m start)\n",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m, in \u001b[0;36minputs_window_words\u001b[1;34m(sequence, vocabulary, side_window_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m words_input\u001b[38;5;241m=\u001b[39mwords_before\u001b[38;5;241m+\u001b[39mwords_after\n\u001b[0;32m     27\u001b[0m X_i\u001b[38;5;241m=\u001b[39minput_one_hot_vectors(words_input,vocabulary)\n\u001b[1;32m---> 28\u001b[0m y_i\u001b[38;5;241m=\u001b[39m\u001b[43minput_one_hot_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(X_i,y_i)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m training_sample\u001b[38;5;241m=\u001b[39m[X_i,y_i]\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36minput_one_hot_vectors\u001b[1;34m(words, vocabulary)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_one_hot_vectors\u001b[39m(words,vocabulary):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#print(len(words))\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#print(inputs.shape)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words)): \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "def input_one_hot_vectors(words,vocabulary):\n",
    "    #print(len(words))\n",
    "    inputs=np.zeros((len(words),len(vocabulary)),int)\n",
    "    #print(inputs.shape)\n",
    "    for i in range(len(words)): \n",
    "        inputs[i][vocabulary.index(words[i])]=1\n",
    "    return inputs\n",
    "side_window_size=3\n",
    "\n",
    " \n",
    "def inputs_window_words(sequence,vocabulary,side_window_size):\n",
    "   \n",
    "    training_samples=[]\n",
    "    for i in range(side_window_size,len(sequence)-side_window_size):\n",
    "        words_before=sequence[i-side_window_size:i]\n",
    "        words_after=sequence[i+1:i+1+side_window_size]\n",
    "        #print(words_before)\n",
    "        #print(words_after)\n",
    "        words_input=words_before+words_after\n",
    "        X_i=input_one_hot_vectors(words_input,vocabulary)\n",
    "        y_i=input_one_hot_vectors([sequence[i]],vocabulary)\n",
    "        #print(X_i,y_i)\n",
    "        training_sample=[X_i,y_i]\n",
    "        training_samples.append(training_sample)\n",
    "    return training_samples\n",
    "    \n",
    " \n",
    "for i in range(len(df)):\n",
    "    start = time.time()\n",
    "    training_samples=inputs_window_words(re.sub(r'[^\\w\\s]',' ',df[\"text\"].iloc[i]).split(),vocabulary,side_window_size)\n",
    "    end = time.time()\n",
    "    print(len(training_samples),\" delta t\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ae3b8-cfb4-4c51-9caa-cff741938f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87958af8-a2c1-4960-a92d-5f65a7491732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "@njit\n",
    "def foo(x):\n",
    "   lst = []\n",
    "   for i in range(x):\n",
    "       lst.append(np.zeros(5))\n",
    "   return lst\n",
    "\n",
    "foo(4)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65d66ec4-3714-4ce7-99dd-71e9c01e97a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4,3),int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142abce-d32e-46ef-b1a7-ee66dfc7f780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
