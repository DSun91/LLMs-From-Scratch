{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00344db5-aab6-4409-84d9-ef8cdf2e2db9",
   "metadata": {},
   "source": [
    " # NLP Model Implementation Using the QVC Attention Mechanism\n",
    "\n",
    "This guide focuses on developing a Natural Language Processing (NLP) model using the QVC (Query, Value, Context) attention mechanism from scratch using Python and Numpy. The attention mechanism is a critical component in modern NLP models, enhancing their ability to focus on different parts of the input sequence to make more accurate predictions.\n",
    "\n",
    "## Key Components:\n",
    "\n",
    "- **QVC Attention Mechanism**: Understanding and implementing the Query, Value, and Context (QVC) attention mechanism from scratch.\n",
    "- **Model Architecture**: Building the architecture of the NLP model utilizing QVC attention.\n",
    "- **Training and Evaluation**: Training the model with appropriate datasets and evaluating its performance.\n",
    "\n",
    "This project aims to provide a comprehensive guide to implementing and experimenting with attention mechanisms in NLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146946e-0ba5-4973-84d5-b9e5b5086ab8",
   "metadata": {},
   "source": [
    "# Preparing Input Data for NLP Model\n",
    "\n",
    "In this section, we are preparing the input data for our NLP model by defining arrays representing word embeddings and combining them into a structured format.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa334299-b0e7-483b-ae85-95b418fd030e",
   "metadata": {},
   "source": [
    "Let's consider as starting point for example 3 phrases made of 4 words each where each word have embedding size 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9826cbc-8702-4db0-8063-c3425427ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\python312\\\\lib\\\\site-packages')\n",
    "import numpy as np\n",
    " \n",
    "\n",
    "import sys \n",
    "import numpy as np\n",
    " \n",
    "\n",
    "# Phrase 1\n",
    "word1 = np.array([0.1, 0.2, 0.3, 0.4, 0.5,0.3])\n",
    "word2 = np.array([0.5, 0.4, 0.7,0.3, 0.2,0.3])\n",
    "word3 = np.array([0.2,0.7, 0.3, 0.5, 0.4,0.4])\n",
    "word4 = np.array([0.4, 0.1,0.7, 0.2, 0.5,0.7])\n",
    "\n",
    "# Phrase 2\n",
    "word5 = np.array([0.1, 0.9, 0.3, 0.4, 0.5,0.2])\n",
    "word6 = np.array([0.4, 0.4, 0.7,0.3, 0.4,0.6])\n",
    "word7 = np.array([0.2,0.7, 0.4, 0.5, 0.4,0.2])\n",
    "word8 = np.array([0.4, 0.5,0.7, 0.7, 0.5,0.1])\n",
    "\n",
    "# Phrase 3\n",
    "word9 = np.array([0.1, 0.2, 0.3, 0.8, 0.5,0.2])\n",
    "word10 = np.array([0.4, 0.5, 0.7,0.3, 0.8,0.4])\n",
    "word11 = np.array([0.9,0.7, 0.3, 0.5, 0.4,0.6])\n",
    "word12 = np.array([0.4, 0.5,0.1, 0.7, 0.4,0.4])\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa490b91-9b93-48fe-a5f4-c68e4323be09",
   "metadata": {},
   "source": [
    "We combine all these word embeddings into a single matrix. This matrix, `inputs`, has the shape `(3, 4, 6)`, where:\n",
    "- `3` represents the number of phrases (batch size),\n",
    "- `4` is the number of words in each phrase (sequence length),\n",
    "- `6` is the dimensionality of each word embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010108fc-3efd-4649-84d4-1e405ea6af37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.1, 0.2, 0.3, 0.4, 0.5, 0.3],\n",
       "         [0.5, 0.4, 0.7, 0.3, 0.2, 0.3],\n",
       "         [0.2, 0.7, 0.3, 0.5, 0.4, 0.4],\n",
       "         [0.4, 0.1, 0.7, 0.2, 0.5, 0.7]],\n",
       " \n",
       "        [[0.1, 0.9, 0.3, 0.4, 0.5, 0.2],\n",
       "         [0.4, 0.4, 0.7, 0.3, 0.4, 0.6],\n",
       "         [0.2, 0.7, 0.4, 0.5, 0.4, 0.2],\n",
       "         [0.4, 0.5, 0.7, 0.7, 0.5, 0.1]],\n",
       " \n",
       "        [[0.1, 0.2, 0.3, 0.8, 0.5, 0.2],\n",
       "         [0.4, 0.5, 0.7, 0.3, 0.8, 0.4],\n",
       "         [0.9, 0.7, 0.3, 0.5, 0.4, 0.6],\n",
       "         [0.4, 0.5, 0.1, 0.7, 0.4, 0.4]]]),\n",
       " (3, 4, 6))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.stack([[word1, word2, word3, word4],[word5, word6, word7, word8],[word9, word10, word11, word12]])\n",
    "#inputs = np.stack([word1, word2, word3, word4])\n",
    "inputs, inputs.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01448d4b-217c-4fd2-99ce-e432932482f4",
   "metadata": {},
   "source": [
    "Implementing the classifier model class we can start by adding these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32f97bf-07f9-4931-834f-98b0a2c86862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self,word_len,batch_size):\n",
    "        self.word_len=word_len\n",
    "        self.batch_size = batch_size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c80dc-cdad-492c-b715-0dbdb1e01c13",
   "metadata": {},
   "source": [
    "# Attention Head\n",
    "\n",
    "An attention head in the attention mechanism is a crucial component of the model that computes the weighted sum of the values based on the similarity between the queries and keys.\n",
    "The primary goal of the attention mechanism is to derive better and richer representations of word embeddings. By focusing on different parts of the input sequence, the attention mechanism helps the model capture intricate relationships and dependencies between words. This enhanced representation improves the model’s ability to understand context and perform various NLP tasks more effectively.\n",
    "\n",
    "The output of an attention head can be represented mathematically as follows:\n",
    "\n",
    "1. **Calculate the Scores**: The attention scores are computed as the dot product of the query matrix \\\\( Q \\\\) with the transpose of the key matrix \\\\( K \\\\). To ensure that the gradients are well-behaved and to prevent excessively large values in the softmax step, the dot product is scaled by \\\\( \\sqrt{d_k} \\\\):\n",
    "  $$\n",
    "  \\text{Scores} = \\frac{QK^T}{\\sqrt{d_k}}\n",
    "  $$\n",
    "   where \\\\( d_k \\\\) refers to the dimensionality of the key vectors. Specifically, \\\\( d_k \\\\) is equal to the number of neurons in the key matrix \\\\( K \\\\). This dimension is crucial for scaling the attention scores, which helps in stabilizing the gradients during training.\n",
    "\n",
    "2. **Apply Softmax**: Apply the softmax function to the scores to get the attention weights:\n",
    "   $$\n",
    "   \\text{Attention Weights} = \\text{softmax}(\\text{Scores})\n",
    "   $$\n",
    "\n",
    "3. **Compute the Weighted Sum**: Multiply the attention weights by the value matrix \\\\( V \\\\) to get the weighted sum:\n",
    "   $$\n",
    "   \\text{Output} = \\text{Attention Weights} \\times V\n",
    "   $$\n",
    "\n",
    "Here’s a more detailed breakdown:\n",
    "\n",
    "- **Query Matrix \\( Q \\)**: Represents the queries for which we are computing attention.\n",
    "- **Key Matrix \\( K \\)**: Represents the keys that are used to compute the similarity with the queries.\n",
    "- **Value Matrix \\( V \\)**: Contains the values that will be weighted by the attention weights to produce the final output.\n",
    "\n",
    "While the query and key matrices have dimensions \\\\(\\text{embedding} \\times d_k\\\\), the value matrix \\\\( V \\\\) has a second dimension \\\\( d_v \\\\) that specifies how the words will be represented after attention. This dimension \\\\( d_v \\\\) influences the output representation of the words, allowing the model to create a more meaningful and rich representation based on the attention mechanism.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f61a6-2c2d-45a1-83c0-621fc877d3e8",
   "metadata": {},
   "source": [
    "![Alt text](imgs/NotebookAttention1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5cc195bf-ea34-41a7-8682-3f902a54a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_len=6\n",
    "dk=5\n",
    "dv=5\n",
    "num_prases=3\n",
    "num_head=2\n",
    "words_per_phrase=4\n",
    "Q = np.random.rand(num_head,word2vec_len, dk)/ np.sqrt(word2vec_len)\n",
    "K = np.random.rand(num_head,word2vec_len, dk)/ np.sqrt(word2vec_len)\n",
    "V = np.random.rand(num_head,word2vec_len, dv)/ np.sqrt(word2vec_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db965b7b-e103-4867-890d-c4cba8aebb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23415098, 0.31460001, 0.35830761, 0.31637215, 0.12121329],\n",
       "        [0.01511963, 0.37463799, 0.06929941, 0.32233647, 0.02954524],\n",
       "        [0.12855307, 0.15196105, 0.12807635, 0.31897333, 0.25119741],\n",
       "        [0.36072389, 0.23409489, 0.30312702, 0.40559826, 0.37673865],\n",
       "        [0.38357843, 0.3962838 , 0.11107209, 0.31946467, 0.13115045],\n",
       "        [0.29073199, 0.12788633, 0.01961107, 0.28919533, 0.33903282]],\n",
       "\n",
       "       [[0.05638389, 0.27553134, 0.17058821, 0.22087972, 0.08687059],\n",
       "        [0.17696066, 0.08558182, 0.08926616, 0.318107  , 0.07508469],\n",
       "        [0.06288942, 0.3326586 , 0.28557413, 0.05651184, 0.18373996],\n",
       "        [0.33842056, 0.31093827, 0.12490728, 0.17868365, 0.03850839],\n",
       "        [0.02927902, 0.08024997, 0.15719157, 0.30466315, 0.22904225],\n",
       "        [0.08409397, 0.2868046 , 0.01159387, 0.39491377, 0.04146868]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381c338-89ff-4ffc-b614-26d6b9d91824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918bd284-1b11-46af-9381-c5f93d7f81b1",
   "metadata": {},
   "source": [
    "Adding Q,K,V to the classifier we have:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbf587ef-f7dc-4c44-960c-ba87237d8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self,word2vec_len,seqLenght,batch_size,dk,dv,num_heads):\n",
    "        self.word2vec_len=word2vec_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk=dk\n",
    "        self.dv = dv\n",
    "        self.num_heads=num_heads\n",
    "        self.Q = np.random.rand(self.num_heads,self.word2vec_len, self.dk) / np.sqrt(self.word_len)\n",
    "        self.K = np.random.rand(self.num_heads,self.word2vec_len, self.dk) / np.sqrt(self.word_len)\n",
    "        self.V = np.random.rand(self.num_heads,self.word2vec_len, self.dv) / np.sqrt(self.word_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393f1d5-2200-4f81-bf46-fc39f2841dee",
   "metadata": {},
   "source": [
    "## Forward Pass in Attention Mechanism\n",
    "\n",
    "The `forward` method in the attention mechanism is responsible for computing the query, key, and value vectors from the input embeddings. Let’s break down the code provided:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e056ba64-4e24-445d-a023-ef9400239ed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.48830332, 0.48212167, 0.27078372, 0.60052674, 0.41137013],\n",
       "         [0.48526294, 0.60137906, 0.41556286, 0.782733  , 0.48922446],\n",
       "         [0.54606598, 0.69747041, 0.36243079, 0.83086508, 0.49672618],\n",
       "         [0.65260589, 0.60415784, 0.36979563, 0.82535255, 0.60552396]],\n",
       "\n",
       "        [[0.23513327, 0.39500875, 0.25262115, 0.44494209, 0.22119107],\n",
       "         [0.27560896, 0.60023227, 0.39329111, 0.5102528 , 0.27188871],\n",
       "         [0.36857554, 0.51710208, 0.312244  , 0.65297699, 0.25251396],\n",
       "         [0.22546162, 0.65470759, 0.38875674, 0.62422881, 0.32212555]]],\n",
       "\n",
       "\n",
       "       [[[0.46981386, 0.73157963, 0.3173322 , 0.79724273, 0.39814851],\n",
       "         [0.62578313, 0.68754171, 0.40782984, 0.90174731, 0.60504307],\n",
       "         [0.50077488, 0.68708924, 0.37131621, 0.80492335, 0.45403936],\n",
       "         [0.6645765 , 0.79432869, 0.53731226, 0.98356906, 0.60229168]],\n",
       "\n",
       "        [[0.35059634, 0.42623556, 0.31394807, 0.62812561, 0.26960348],\n",
       "         [0.30105457, 0.67477051, 0.41114877, 0.66757159, 0.32145071],\n",
       "         [0.35804569, 0.49300702, 0.33848264, 0.57964542, 0.26259422],\n",
       "         [0.41499978, 0.6723267 , 0.47996052, 0.60386518, 0.34653242]]],\n",
       "\n",
       "\n",
       "       [[[0.60351967, 0.56297099, 0.39007342, 0.73384651, 0.52816231],\n",
       "         [0.72258007, 0.85794177, 0.4552664 , 1.00392776, 0.59265121],\n",
       "         [0.76811806, 0.94326768, 0.61716832, 1.11016465, 0.64938205],\n",
       "         [0.63630641, 0.70188958, 0.45524256, 0.8469972 , 0.54016804]],\n",
       "\n",
       "        [[0.3620921 , 0.4907036 , 0.30142467, 0.47692417, 0.23244756],\n",
       "         [0.31364345, 0.65806776, 0.48063324, 0.7422648 , 0.41228234],\n",
       "         [0.42486306, 0.76733494, 0.43397453, 0.88657554, 0.3216171 ],\n",
       "         [0.39956642, 0.55074792, 0.29637505, 0.65796589, 0.22582482]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval = np.matmul(inputs[:, np.newaxis, :, :], Q[np.newaxis, :, :, :])\n",
    "Qval \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d3002d6-50aa-4319-9ff8-51b6fe4e0e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.27288818, 0.32668234, 0.43987998, 0.40353516, 0.25465167],\n",
       "         [0.29633193, 0.4995027 , 0.49230935, 0.55875161, 0.44099382],\n",
       "         [0.38283161, 0.56661481, 0.58486216, 0.55342048, 0.42001212],\n",
       "         [0.29939186, 0.50319141, 0.62098571, 0.64262208, 0.43436568]],\n",
       "\n",
       "        [[0.3862477 , 0.17223405, 0.26657642, 0.39743623, 0.53002439],\n",
       "         [0.41219553, 0.30326357, 0.27305641, 0.501071  , 0.57885631],\n",
       "         [0.48953984, 0.29091747, 0.3220343 , 0.52635797, 0.69940846],\n",
       "         [0.57238054, 0.29197191, 0.34300763, 0.54370742, 0.6909699 ]]],\n",
       "\n",
       "\n",
       "       [[[0.43267077, 0.52486023, 0.51811998, 0.54217197, 0.34591215],\n",
       "         [0.34311181, 0.59005077, 0.63791538, 0.6626669 , 0.47799567],\n",
       "         [0.38403687, 0.51235658, 0.52014679, 0.5236505 , 0.37647328],\n",
       "         [0.43419594, 0.53527668, 0.60293644, 0.62587106, 0.45808768]],\n",
       "\n",
       "        [[0.49145571, 0.28950913, 0.27269537, 0.57563749, 0.69267587],\n",
       "         [0.568812  , 0.33017565, 0.34353434, 0.58914561, 0.73190677],\n",
       "         [0.44599343, 0.27801208, 0.29234521, 0.53763834, 0.6611583 ],\n",
       "         [0.48751035, 0.31599475, 0.3758643 , 0.64109801, 0.76362716]]],\n",
       "\n",
       "\n",
       "       [[[0.30791811, 0.37998032, 0.5184287 , 0.40817692, 0.31294478],\n",
       "         [0.49978466, 0.5528039 , 0.67299657, 0.76804957, 0.45506622],\n",
       "         [0.52586696, 0.74663891, 0.78551942, 0.84404312, 0.75022877],\n",
       "         [0.39285119, 0.54249629, 0.62072194, 0.55258228, 0.49888754]],\n",
       "\n",
       "        [[0.3730142 , 0.17329406, 0.34709562, 0.42594192, 0.6120533 ],\n",
       "         [0.66862911, 0.36288521, 0.37969147, 0.73670499, 0.85987588],\n",
       "         [0.5967956 , 0.47124578, 0.45546643, 0.620086  , 0.86172783],\n",
       "         [0.43666462, 0.28906308, 0.38371188, 0.45213165, 0.68875695]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kval=np.matmul(inputs[:, np.newaxis, :, :], K[np.newaxis,:, :, :])\n",
    "Kval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53b206d8-fd56-4a0e-994b-9c04c755a067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.41004327, 0.40524876, 0.41438249, 0.34808021, 0.36120131],\n",
       "         [0.55274083, 0.57247167, 0.55477581, 0.54474699, 0.50954881],\n",
       "         [0.59762075, 0.50218418, 0.596659  , 0.42705441, 0.60621111],\n",
       "         [0.6071217 , 0.70847462, 0.52889518, 0.58312974, 0.55634891]],\n",
       "\n",
       "        [[0.4987024 , 0.31736093, 0.27549481, 0.47444951, 0.40180584],\n",
       "         [0.63968421, 0.40094908, 0.28201351, 0.62051973, 0.48163086],\n",
       "         [0.74186296, 0.40944264, 0.39588903, 0.69829561, 0.51663476],\n",
       "         [0.59190739, 0.4417119 , 0.38101764, 0.73913009, 0.52228043]]],\n",
       "\n",
       "\n",
       "       [[[0.48577513, 0.39983759, 0.62757871, 0.35004028, 0.60157257],\n",
       "         [0.64887549, 0.68911428, 0.6010074 , 0.58905234, 0.63087547],\n",
       "         [0.5284141 , 0.45282125, 0.60067326, 0.42264319, 0.54667054],\n",
       "         [0.64152173, 0.60764812, 0.72731254, 0.62115457, 0.54211017]],\n",
       "\n",
       "        [[0.76681742, 0.37044753, 0.35352385, 0.69288226, 0.48552112],\n",
       "         [0.70884368, 0.45702809, 0.39811337, 0.78084988, 0.56041132],\n",
       "         [0.74155751, 0.39017882, 0.33285062, 0.63610303, 0.5058025 ],\n",
       "         [0.86797558, 0.50978513, 0.33555053, 0.67998832, 0.64527097]]],\n",
       "\n",
       "\n",
       "       [[[0.53130703, 0.45385304, 0.48959526, 0.43700412, 0.35999188],\n",
       "         [0.62308487, 0.68590465, 0.77060112, 0.60207976, 0.6650814 ],\n",
       "         [0.92932998, 0.79606842, 0.88303529, 0.68572593, 0.81601259],\n",
       "         [0.70249025, 0.54546233, 0.62897578, 0.47626176, 0.55945761]],\n",
       "\n",
       "        [[0.63600525, 0.39398674, 0.30956379, 0.45955083, 0.51804839],\n",
       "         [0.83964834, 0.52732134, 0.40894605, 0.88037676, 0.62683919],\n",
       "         [0.925806  , 0.64615509, 0.51851517, 0.98236427, 0.65105811],\n",
       "         [0.73622306, 0.47822295, 0.41343259, 0.66158173, 0.53776077]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vval=np.matmul(inputs[:, np.newaxis, :, :], V[np.newaxis,:, :, :])\n",
    "Vval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe060e4-c99f-4dab-acc6-ab43500fd004",
   "metadata": {},
   "source": [
    "Having the values of the \\\\(Q\\\\), \\\\(K\\\\), \\\\(V\\\\) matrices and the \\\\(dk\\\\) values we can calculate the scores:\n",
    "$$\n",
    "  \\text{QKscaled} = \\frac{QK^T}{\\sqrt{d_k}}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3af7a0da-fbeb-4ae6-a83f-242f65e5410a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.33852053, 0.46321815, 0.50249394, 0.50156934],\n",
       "         [0.42580205, 0.58221536, 0.62978047, 0.63569398],\n",
       "         [0.44634944, 0.61354735, 0.66396425, 0.66599326],\n",
       "         [0.45856311, 0.62852278, 0.67955752, 0.68085512]],\n",
       "\n",
       "        [[0.23267148, 0.28473101, 0.31317315, 0.32705751],\n",
       "         [0.29586601, 0.3649627 , 0.40022475, 0.41734025],\n",
       "         [0.31663447, 0.38789553, 0.42562649, 0.44656728],\n",
       "         [0.32302502, 0.40109832, 0.43822303, 0.4541586 ]]],\n",
       "\n",
       "\n",
       "       [[[0.59105314, 0.67704495, 0.57586963, 0.65663389],\n",
       "         [0.68920982, 0.79037181, 0.67292439, 0.7724154 ],\n",
       "         [0.60961806, 0.69968022, 0.59475913, 0.68015169],\n",
       "         [0.77119756, 0.88510258, 0.75287327, 0.86276313]],\n",
       "\n",
       "        [[0.41574511, 0.45409622, 0.39471005, 0.46160316],\n",
       "         [0.4751045 , 0.520489  , 0.45325186, 0.5312784 ],\n",
       "         [0.41436781, 0.45455239, 0.39397624, 0.46049394],\n",
       "         [0.49959296, 0.55111009, 0.47677   , 0.55764259]]],\n",
       "\n",
       "\n",
       "       [[[0.47708864, 0.7510236 , 0.92115178, 0.65008506],\n",
       "         [0.61705051, 0.97607164, 1.19413033, 0.8417944 ],\n",
       "         [0.70269004, 1.10410827, 1.34934086, 0.95434985],\n",
       "         [0.54265469, 0.85361815, 1.04488068, 0.73827988]],\n",
       "\n",
       "        [[0.29969437, 0.48560744, 0.48328867, 0.35390235],\n",
       "         [0.43216882, 0.68528702, 0.6850186 , 0.50587393],\n",
       "         [0.45462021, 0.74103389, 0.73330511, 0.53496447],\n",
       "         [0.34248863, 0.56280005, 0.55256861, 0.40268259]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QKscaled=np.matmul(Qval,np.transpose(Kval, (0, 1, 3,2)))/np.sqrt(dk)\n",
    "QKscaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874ca4b-689b-42e5-b5fb-e19733e3a3b1",
   "metadata": {},
   "source": [
    "and finally the \\\\(attention\\\\) \\\\(weights\\\\) as:\n",
    "$$\n",
    "  \\text{Attention weights} =\\sigma( \\frac{QK^T}{\\sqrt{d_k}})\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57134a6b-fb58-4943-9a33-89df9fc70197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22281228, 0.25240305, 0.26251364, 0.26227103],\n",
       "         [0.21602351, 0.25259832, 0.26490351, 0.26647466],\n",
       "         [0.21409933, 0.25306287, 0.26614862, 0.26668918],\n",
       "         [0.21360632, 0.25317839, 0.26643467, 0.26678062]],\n",
       "\n",
       "        [[0.23605767, 0.24867222, 0.25584653, 0.25942358],\n",
       "         [0.23198096, 0.24857683, 0.25749853, 0.26194368],\n",
       "         [0.23106605, 0.24813294, 0.25767411, 0.2631269 ],\n",
       "         [0.23023345, 0.24892884, 0.25834394, 0.26249377]]],\n",
       "\n",
       "\n",
       "       [[[0.24139968, 0.26307675, 0.23776207, 0.2577615 ],\n",
       "         [0.2394024 , 0.26488819, 0.23553521, 0.2601742 ],\n",
       "         [0.2408145 , 0.26350941, 0.23726271, 0.25841338],\n",
       "         [0.23818729, 0.26692355, 0.23386242, 0.26102674]],\n",
       "\n",
       "        [[0.24598997, 0.25560719, 0.2408696 , 0.25753324],\n",
       "         [0.24494218, 0.25631488, 0.23964761, 0.25909533],\n",
       "         [0.24581957, 0.25589889, 0.24085769, 0.25742385],\n",
       "         [0.24449457, 0.25742032, 0.23897768, 0.25910743]]],\n",
       "\n",
       "\n",
       "       [[[0.19751058, 0.25975194, 0.3079247 , 0.23481279],\n",
       "         [0.18299067, 0.26202929, 0.32587536, 0.22910469],\n",
       "         [0.17577051, 0.26259094, 0.33556982, 0.22606872],\n",
       "         [0.19108746, 0.26078458, 0.31575204, 0.23237592]],\n",
       "\n",
       "        [[0.22413735, 0.26993255, 0.26930736, 0.23662273],\n",
       "         [0.21495139, 0.27686502, 0.27679072, 0.23139287],\n",
       "         [0.2111177 , 0.28113346, 0.27896901, 0.22877982],\n",
       "         [0.22015356, 0.27441367, 0.27162034, 0.23381244]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    # Subtract the max value for numerical stability\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "Attention_weights=softmax(QKscaled)\n",
    "Attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b132f5-af6a-44a1-af9e-49de32810dd2",
   "metadata": {},
   "source": [
    "and finally the \\\\(Attention\\\\) value as:\n",
    "$$\n",
    "  \\text{Attention} =\\sigma( \\frac{QK^T}{\\sqrt{d_k}})V\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f9a3f8b-7be8-4f5b-996c-0ad41fef0bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.54699018, 0.55243056, 0.52770162, 0.48009799, 0.51414465],\n",
       "         [0.54829477, 0.55396953, 0.52864602, 0.4813132 , 0.51557949],\n",
       "         [0.5486369 , 0.55423295, 0.52896276, 0.48155331, 0.51599533],\n",
       "         [0.54872506, 0.55430773, 0.52904159, 0.48162012, 0.5161004 ]],\n",
       "\n",
       "        [[0.62015202, 0.39396534, 0.33529338, 0.63670775, 0.48228864],\n",
       "         [0.62077516, 0.39442286, 0.33575758, 0.63773063, 0.48277433],\n",
       "         [0.62086555, 0.39454906, 0.33590068, 0.63801827, 0.4829016 ],\n",
       "         [0.62108163, 0.39459854, 0.33591971, 0.63811689, 0.48296577]]],\n",
       "\n",
       "\n",
       "       [[[0.57896645, 0.54210262, 0.63989887, 0.50006384, 0.58090074],\n",
       "         [0.57954272, 0.54301002, 0.64015128, 0.50098924, 0.58093262],\n",
       "         [0.57911725, 0.54233679, 0.63996582, 0.50030773, 0.58090208],\n",
       "         [0.57993614, 0.54368734, 0.64022723, 0.5015854 , 0.58103341]],\n",
       "\n",
       "        [[0.77196616, 0.43321487, 0.35531297, 0.69837041, 0.55068965],\n",
       "         [0.77211402, 0.43346969, 0.35534171, 0.6984819 , 0.55096741],\n",
       "         [0.77193848, 0.43322465, 0.35532819, 0.69839815, 0.55069378],\n",
       "         [0.77206808, 0.43355387, 0.35540464, 0.69861703, 0.55103855]]],\n",
       "\n",
       "\n",
       "       [[[0.71790361, 0.6410165 , 0.71646531, 0.56568862, 0.62649662],\n",
       "         [0.72428026, 0.64716504, 0.72337216, 0.57030519, 0.63423872],\n",
       "         [0.72767072, 0.65033484, 0.72692103, 0.57268995, 0.63822538],\n",
       "         [0.72069669, 0.64371152, 0.71949542, 0.56771025, 0.62989502]],\n",
       "\n",
       "        [[0.79273444, 0.51782109, 0.41724016, 0.76174806, 0.58789946],\n",
       "         [0.79579074, 0.52019195, 0.41894957, 0.76752123, 0.58954592],\n",
       "         [0.79702938, 0.52109026, 0.41955752, 0.76992842, 0.59024851],\n",
       "         [0.79403564, 0.5187651 , 0.41787691, 0.76427532, 0.58863922]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention=np.matmul(Attention_weights, Vval)\n",
    "Attention \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308da6ec-5fef-4fec-aabd-c632f8d16a15",
   "metadata": {},
   "source": [
    "Consider now the change in the dimensionality of each word:\n",
    "\n",
    "- **Initial Embedding Size**: The word embeddings begin with a dimensionality of 6.\n",
    "- **Attention Output Size**: After applying the attention mechanism, the output of the attention layer typically has a reduced dimensionality, in our case it end up with a size of 3.\n",
    "\n",
    "This reduction occurs because:\n",
    "  - The attention mechanism often projects the embeddings into a lower-dimensional space to capture the most relevant information while reducing computational complexity.\n",
    "  - The output dimension of the attention mechanism is determined by the number of neurons in the linear layer of V matrix of the attention mechanism.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92ed80-c07e-4513-9263-ac9742f88310",
   "metadata": {},
   "source": [
    "# Computing Phrase Representation from Attention Scores\n",
    "\n",
    "In the attention mechanism, once the attention scores are computed and applied, we often need to summarize or aggregate these scores to obtain a representation of the entire phrase. Here’s how we compute the `phrase_representation`:\n",
    "\n",
    "### Context\n",
    "\n",
    "Given an `Attention` matrix that represents the attention weights applied to each word in a phrase, the goal is to aggregate these weights to obtain a single representation for the phrase.\n",
    "\n",
    "### Computing Phrase Representation\n",
    "\n",
    "1. **Attention Matrix**:\n",
    "   - **Shape**: \\\\((\\text{batch\\_size}, \\text{sequence\\_length}, \\text{embedding\\_dim})\\\\) \n",
    "   - **Purpose**: Contains the attention weights for each word in each phrase. Each entry in this matrix represents the weighted influence of words in the phrase.\n",
    "\n",
    "2. **Phrase Representation Calculation**:\n",
    "   - To obtain a single representation for each phrase, we compute the average of the attention weights along the sequence length dimension.\n",
    "\n",
    "   ```python\n",
    "   phrase_representation = np.mean(Attention, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00244b-1414-4f05-aaee-9d5f84715048",
   "metadata": {},
   "source": [
    "![Alt text](imgs/NotebookAttention2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da1fc1bc-fc23-4e16-933c-3d9af598890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase Representation:\n",
      "[[[0.54816173 0.55373519 0.528588   0.48114616 0.51545497]\n",
      "  [0.62071859 0.39438395 0.33571784 0.63764339 0.48273258]]\n",
      "\n",
      " [[0.57939064 0.54278419 0.6400608  0.50073655 0.58094221]\n",
      "  [0.77202168 0.43336577 0.35534688 0.69846687 0.55084735]]\n",
      "\n",
      " [[0.72263782 0.64555697 0.72156348 0.5690985  0.63221393]\n",
      "  [0.79489755 0.5194671  0.41840604 0.76586826 0.58908328]]] (3, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "phrase_representation = np.mean(Attention, axis=2)\n",
    "print(\"Phrase Representation:\")\n",
    "print(phrase_representation,phrase_representation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc6393e2-a20c-46d0-bf34-2842097108ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_representation=phrase_representation.reshape(num_prases,dv*num_head)\n",
    "phrase_representation.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1569a24a-62df-4d23-b359-8dee5cbaa9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_representation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0cd05-aa0f-445b-9dd2-e29c173864c3",
   "metadata": {},
   "source": [
    "At this point, we have computed the following:\n",
    "\n",
    "- **Attention Mechanism**:\n",
    "  - `Qval`: The result of multiplying the input with the query weight matrix \\( Q \\).\n",
    "  - `Kval`: The result of multiplying the input with the key weight matrix \\( K \\).\n",
    "  - `Vval`: The result of multiplying the input with the value weight matrix \\( V \\).\n",
    "  - `QKscaled`: The scaled dot product of `Qval` and `Kval`, normalized by the square root of the dimensionality of the key vectors \\( d_k \\).\n",
    "  - `attention_weights`: The result of applying the softmax function to `QKscaled` to get attention weights.\n",
    "  - `attention`: The result of multiplying `attention_weights` with `Vval`.\n",
    "We can now add these parts to the classifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d3846a3-848f-476a-bda5-448164a63f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self,word2vec_len,batch_size,dk,dv):\n",
    "        self.word2vec_len=word2vec_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk=dk\n",
    "        self.dv = dv\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.rand(self.word2vec_len, self.dk) / np.sqrt(self.word_len)\n",
    "        self.K = np.random.rand(self.word2vec_len, self.dk) / np.sqrt(self.word_len)\n",
    "        self.V = np.random.rand(self.word2vec_len, self.dv) / np.sqrt(self.word_len)\n",
    "\n",
    "    \n",
    "    def AttentionHead(self, Inputs):\n",
    "        self.Qval = np.dot(Inputs, self.Q)\n",
    "        self.Kval = np.dot(Inputs, self.K)\n",
    "        self.Vval = np.dot(Inputs, self.V) \n",
    "        QKscaled = np.matmul(self.Qval, np.transpose(self.Kval, (0, 2, 1))) / np.sqrt(self.K.shape[1]) \n",
    "        self.Attention_weights = self.softmax(QKscaled) \n",
    "        return np.matmul(self.Attention_weights, self.Vval)\n",
    "    \n",
    "    def forward(self, Inputs):\n",
    "        Attention = self.AttentionHead(Inputs)\n",
    "        self.phrase_representation = np.mean(Attention, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb7df4-17d1-4cad-ae0d-e337352a00c9",
   "metadata": {},
   "source": [
    "With these computations complete, we are now ready to feed the `phrase_rep` into the linear layer for further or classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dfe9b-1d3a-4ee5-9fc0-f517be2ee94d",
   "metadata": {},
   "source": [
    "![Alt text](imgs/Notebooktxtclass.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f760b274-9ded-4466-8b1e-2a8404f2fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  # Example number of classes (binary classification)\n",
    "linearlayer= np.random.rand(dv*num_head, num_classes)   \n",
    "linear_bias = np.random.rand(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d69e7f-f3cd-446d-b64b-61e2ae6ec7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e84053a-063e-4a51-925c-dc2e6a91caf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.379405  , 0.620595  ],\n",
       "       [0.36440656, 0.63559344],\n",
       "       [0.36023999, 0.63976001]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma_Zout=softmax(np.matmul(phrase_representation, linearlayer) + linear_bias)\n",
    "Sigma_Zout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c9059-abe9-47a8-b709-27cfb505317f",
   "metadata": {},
   "source": [
    "We add the linearlayer and Sigma_Zout calculation to the classifier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3727326d-f64c-44d9-b23e-49df570ea4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, batch_size, dk, dv, num_classes):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  \n",
    "        self.K = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  \n",
    "        self.V = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  \n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dk, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes) \n",
    "        \n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "        Attention = self.AttentionHead(Inputs)\n",
    "        self.phrase_representation = np.mean(Attention, axis=1)\n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "\n",
    "        return Sigma_Zout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df671f0-1e4e-47b4-9af2-9ca0bbc910ee",
   "metadata": {},
   "source": [
    "### Cross-Entropy Loss Calculation\n",
    "\n",
    "At this stage, we have calculated the cross-entropy loss between our predictions and the true target values.\n",
    "\n",
    " \n",
    "\n",
    "1. **True Target**:\n",
    "   - The `target` variable represents the true class labels for each example in the batch. It is a list of one-hot encoded vectors. For instance:\n",
    "     - `np.array([0, 1])` represents the true class for the first example.\n",
    "     - `np.array([1, 0])` represents the true class for the second example.\n",
    "     - `np.array([1, 0])` represents the true class for the third example.\n",
    "\n",
    "2. **Cross-Entropy Loss Calculation**:\n",
    "   - The cross-entropy loss is computed using the formula:\n",
    "     \\\\[\n",
    "     \\text{batch\\_loss} = -\\sum (\\text{target} \\cdot \\log(\\text{predictions} + 1e-8))\n",
    "     \\\\]\n",
    "   - This loss function measures the difference between the predicted probabilities and the true class labels. The `1e-8` term is added to avoid taking the logarithm of zero, which could result in undefined values.\n",
    "\n",
    "3. **Result**:\n",
    "   - The computed loss, `loss`, is an average of the individual losses across the batch. It quantifies how well the predicted probabilities match the true labels. A lower loss indicates better performance.\n",
    "\n",
    "In summary, this step provides a measure of how well our model's predictions align with the actual class labels in our batch. The output of this calculation will be used to guide the training process through backpropagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c487b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss:  0.835848818177003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    " \n",
    "target = [np.array([0, 1]),np.array([1, 0]),np.array([1, 0])]\n",
    "\n",
    "\n",
    "def cross_entropy_loss(predictions, target): \n",
    "    batch_loss = -np.sum(target * np.log(predictions + 1e-8), axis=1)\n",
    "    return np.mean(batch_loss) \n",
    " \n",
    "\n",
    "loss = cross_entropy_loss(Sigma_Zout, target)\n",
    "print(\"Cross-Entropy Loss: \",loss)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431718c-20aa-432b-9947-3a8e289e337d",
   "metadata": {},
   "source": [
    "We can now add both softmax and cross entropy loss functions to the classifier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31a1505c-b77c-4921-bdcc-27ed7f1e3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "     \n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        return np.mean(batch_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5138a1a-2c16-4d06-82f3-8a889dc0106c",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    " \n",
    "### Overview\n",
    "\n",
    "Backpropagation is a fundamental algorithm used for training artificial neural networks. It is a supervised learning technique that adjusts the weights of the network to minimize the error between the predicted output and the actual target values. The goal of backpropagation is to optimize the network's performance by systematically reducing the loss function through gradient descent.\n",
    "\n",
    "In our example, using the chain rule we need to calculate therefore the following quantities:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial Z^{out}} = \\frac{\\partial \\text{Loss}}{\\partial \\sigma(Z^{out})} \\frac{\\partial \\sigma(Z^{out})}{\\partial Z^{out}}\n",
    "\\\\]\n",
    "\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial Q} = \\frac{\\partial \\text{Loss}}{\\partial Z^{out}}  \\frac{\\partial Z^{out}}{\\partial A} \\frac{\\partial A}{\\partial Q}\n",
    "\\\\]\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial K} = \\frac{\\partial \\text{Loss}}{\\partial Z^{out}}  \\frac{\\partial Z^{out}}{\\partial A} \\frac{\\partial A}{\\partial K}\n",
    "\\\\]\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial V} = \\frac{\\partial \\text{Loss}}{\\partial Z^{out}}  \\frac{\\partial Z^{out}}{\\partial A} \\frac{\\partial A}{\\partial V}\n",
    "\\\\]\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial W} = \\frac{\\partial \\text{Loss}}{\\partial Z^{out}}  \\frac{\\partial Z^{out}}{\\partial W}\n",
    "\\\\]\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial Bias} =\\frac{\\partial \\text{Loss}}{\\partial Z^{out}}  \\frac{\\partial Z^{out}}{\\partial Bias}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47a656-1879-422e-be31-c66af2997650",
   "metadata": {},
   "source": [
    "### Gradient of loss with respect to output probabilities:\n",
    "\n",
    "\n",
    "The gradient of the loss with respect to the logits \\\\( Z^{out} \\\\) can be expressed as:\n",
    "\\\\[\n",
    "L=-\\sum y_ilog(\\sigma(Z^{out}))\n",
    "\\\\]\n",
    "\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial Z^{out}} = -\\sum y_i \\frac{1}{\\sigma(Z^{out})}  \\frac{\\partial \\sigma(Z^{out})}{\\partial Z^{out}}= -\\sum y_i \\frac{1}{\\sigma(Z^{out})}\\sigma(Z^{out})[1-\\sigma(Z^{out})]\n",
    "\\\\]\n",
    "\n",
    "as \\\\(y_i\\\\) is a one hot encoded vector: \n",
    "\n",
    "\\\\[ \\sum y_i = 1 \\\\]\n",
    "\n",
    "so:\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Loss}}{\\partial Z^{out}} = \\frac{\\partial \\text{Loss}}{\\partial \\sigma(Z^{out})} \\frac{\\partial \\sigma(Z^{out})}{\\partial Z^{out}}=\\sigma_i(Z^{out})-y_i\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a46ee5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.379405  , -0.379405  ],\n",
       "       [-0.63559344,  0.63559344],\n",
       "       [-0.63976001,  0.63976001]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient of loss with respect to output probabilities\n",
    "dLoss_dSigma_Zout =Sigma_Zout - np.stack(target)\n",
    "dLoss_dSigma_Zout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d5926-b7ef-4b54-9d69-c259363d4723",
   "metadata": {},
   "source": [
    "### Gradient of the loss with respect to linear layer and bias:\n",
    "\n",
    "The gradient of the loss with respect to the linear layer weights and bias can be expressed as:\n",
    "\\\\[\n",
    "\\frac{\\partial Loss}{\\partial W}=\\begin{cases} \\frac{\\partial Loss}{\\partial Z^{out}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out})}\\frac{\\partial \\sigma(Z^{out})}{\\partial  Z^{out}}= \\sigma(Z^{out})-y_{true} \\\\  \\frac{\\partial Loss}{\\partial w_{11}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial w_{11}}= [\\sigma(Z^{out}_1)-y_{1}]\\cdot Y_1\\\\  \\frac{\\partial Loss}{\\partial w_{21}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial w_{21}}= [\\sigma(Z^{out}_1)-y_{1}]\\cdot Y_2\\\\  \\frac{\\partial Loss}{\\partial w_{31}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial w_{31}}= [\\sigma(Z^{out}_1)-y_{1}]\\cdot Y_3\\\\  \\frac{\\partial Loss}{\\partial w_{12}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial w_{12}}= [\\sigma(Z^{out}_2)-y_{2}]\\cdot Y_1\\\\  \\frac{\\partial Loss}{\\partial w_{22}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial w_{22}}= [\\sigma(Z^{out}_2)-y_{2}]\\cdot Y_2\\\\  \\frac{\\partial Loss}{\\partial w_{32}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial w_{32}}= [\\sigma(Z^{out}_2)-y_{2}]\\cdot Y_3\\\\  \\frac{\\partial Loss}{\\partial B_{1}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_2}{\\partial B_{1}}= [\\sigma(Z^{out}_1)-y_{1}]\\cdot 1\\\\   \\frac{\\partial Loss}{\\partial B_{2}}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial B_{2}}= [\\sigma(Z^{out}_2)-y_{2}]\\cdot 1\\\\ \\end{cases}\n",
    "\\\\]\n",
    "\n",
    "These values will be used to update the weights of the linear layer trought the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f3098d2-304b-4007-84fd-a07e3652b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.62259637,  0.62259637],\n",
       "        [-0.54790171,  0.54790171],\n",
       "        [-0.66789698,  0.66789698],\n",
       "        [-0.49980208,  0.49980208],\n",
       "        [-0.57814206,  0.57814206],\n",
       "        [-0.76373185,  0.76373185],\n",
       "        [-0.45814748,  0.45814748],\n",
       "        [-0.36616257,  0.36616257],\n",
       "        [-0.69198776,  0.69198776],\n",
       "        [-0.54383573,  0.54383573]]),\n",
       " array([-0.89594846,  0.89594846]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient for linear layer and bias\n",
    "d_linear = np.dot(dLoss_dSigma_Zout.T, phrase_representation).T\n",
    "d_bias =  np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "d_linear,d_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2666bc3-a1e0-461a-903c-b8bdc3886468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier: \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(dLoss_dSigma_Zout.T, self.phrase_representation).T\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8550983-d28e-4555-b782-11872d8723f4",
   "metadata": {},
   "source": [
    "### Gradient of the loss with respect to phrase representation:\n",
    " \n",
    "\n",
    "The gradient of the loss with respect to phrase representation can be expressed as:\n",
    "\\\\[\n",
    "\\frac{\\partial Loss}{\\partial Y}=\\begin{cases} \\frac{\\partial Loss}{\\partial Y^{z_1}_1}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial Y_1}=[\\sigma(Z_1^{out})-y_1]\\cdot w_{11}\\\\  \\frac{\\partial Loss}{\\partial Y^{z_2}_1}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial Y_1}=[\\sigma(Z_2^{out})-y_2]\\cdot w_{12}\\\\    \\frac{\\partial Loss}{\\partial Y^{z_1}_2}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial Y_2}=[\\sigma(Z_1^{out})-y_1]\\cdot w_{21}\\\\  \\frac{\\partial Loss}{\\partial Y^{z_2}_2}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial Y_2}=[\\sigma(Z_2^{out})-y_2]\\cdot w_{22}\\\\     \\frac{\\partial Loss}{\\partial Y^{z_1}_3}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_1)}\\frac{\\partial \\sigma(Z^{out}_1)}{\\partial Z^{out}_1}\\frac{\\partial Z^{out}_1}{\\partial Y_3}=[\\sigma(Z_1^{out})-y_1]\\cdot w_{31}\\\\  \\frac{\\partial Loss}{\\partial Y^{z_2}_3}=\\frac{\\partial Loss}{\\partial \\sigma(Z^{out}_2)}\\frac{\\partial \\sigma(Z^{out}_2)}{\\partial Z^{out}_2}\\frac{\\partial Z^{out}_2}{\\partial Y_2}=[\\sigma(Z_2^{out})-y_3]\\cdot w_{32}\\end{cases}=\\begin{cases}\\frac{\\partial Loss}{\\partial Y_1}=\\frac{\\partial Loss}{\\partial Y^{z_1}_1}+\\frac{\\partial Loss}{\\partial Y^{z_2}_1}\\\\  \\frac{\\partial Loss}{\\partial Y_2}=\\frac{\\partial Loss}{\\partial Y^{z_1}_2}+\\frac{\\partial Loss}{\\partial Y^{z_2}_2}\\\\  \\frac{\\partial Loss}{\\partial Y_3}=\\frac{\\partial Loss}{\\partial Y^{z_1}_3}+\\frac{\\partial Loss}{\\partial Y^{z_2}_3}\\end{cases}\n",
    "\\\\]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57f28c04-c59d-40ef-bd6c-03591fb0fedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06747083, -0.02231603, -0.11821003,  0.20084437,  0.00370432,\n",
       "        -0.03683823, -0.0054395 ,  0.11903841,  0.0083512 , -0.15502397],\n",
       "       [ 0.11302966,  0.03738464,  0.19802987, -0.33646201, -0.00620562,\n",
       "         0.06171279,  0.00911245, -0.1994176 , -0.01399024,  0.25970196],\n",
       "       [ 0.11377061,  0.03762971,  0.19932804, -0.33866765, -0.0062463 ,\n",
       "         0.06211734,  0.00917218, -0.20072487, -0.01408195,  0.26140441]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient for phrase representation\n",
    "d_phrase_rep = np.dot(dLoss_dSigma_Zout, linearlayer.T)\n",
    "d_phrase_rep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df43ef8-93b5-433c-85b1-d93a7a752d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8fa25f63-a6c4-4072-b424-26185f8584c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_phrase_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ede1786d-8c88-429e-8007-34c4d3029288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier: \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        \n",
    "         # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653d85a-7ba3-4c00-8621-31eb998fca4a",
   "metadata": {},
   "source": [
    "### Gradient of the Loss with Respect to Attention Output\n",
    "\n",
    "Given the attention output matrix:\n",
    "\n",
    "\\\\[\n",
    "\\text{Attention} = \n",
    "\\begin{bmatrix}\n",
    "Y_a^1 & Y_a^2 & Y_a^3 \\\\\n",
    "Y_b^1 & Y_b^2 & Y_b^3 \\\\\n",
    "Y_c^1 & Y_c^2 & Y_c^3 \\\\\n",
    "Y_d^1 & Y_d^2 & Y_d^3 \\\\\n",
    "\\end{bmatrix}\n",
    "\\\\]\n",
    "\n",
    "Each row \\\\(Y_a, Y_b, Y_c, Y_d\\\\) represents the attention for each input token.\n",
    "\n",
    "#### Phrase Representation\n",
    "\n",
    "We compute the phrase representation by averaging over the rows for each component:\n",
    "\n",
    "\\\\[\n",
    "\\text{Phrase Representation} = Y =\n",
    "\\begin{bmatrix}\n",
    "\\frac{Y^1_a + Y^1_b + Y^1_c + Y^1_d}{4} \\\\\n",
    "\\frac{Y^2_a + Y^2_b + Y^2_c + Y^2_d}{4} \\\\\n",
    "\\frac{Y^3_a + Y^3_b + Y^3_c + Y^3_d}{4} \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "{Y_1}\\\\\n",
    "{Y_2}\\\\\n",
    "{Y_3}\\\\\n",
    "\\end{bmatrix}\n",
    "\\\\]\n",
    "\n",
    "#### Loss Function and Gradient\n",
    "\n",
    "The loss is computed based on the phrase representation. To compute the gradient of the loss with respect to each attention component \\\\(Y_x^i\\\\), we apply the chain rule:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\\partial Loss}{\\partial Y_x^i} = \\frac{\\partial Loss}{\\partial \\text{Y}_i} \\cdot \\frac{\\partial \\text{Y}_i}{\\partial Y_x^i}\n",
    "\\\\]\n",
    "\n",
    "So we end up with the following set of equations:\n",
    "\\\\[\n",
    "\\begin{align*}\n",
    "\\frac{\\partial Loss}{\\partial Y_x^1} = \\begin{cases}\n",
    "\\frac{\\partial Loss}{\\partial Y^1_a} = \\frac{\\partial Loss}{\\partial \\text{Y}_1} \\cdot \\frac{\\partial \\text{Y}_1}{\\partial Y_1^a}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^1_b} = \\frac{\\partial Loss}{\\partial \\text{Y}_1} \\cdot \\frac{\\partial \\text{Y}_1}{\\partial Y_1^b}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^1_c} = \\frac{\\partial Loss}{\\partial \\text{Y}_1} \\cdot \\frac{\\partial \\text{Y}_1}{\\partial Y_1^c}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^1_d} = \\frac{\\partial Loss}{\\partial \\text{Y}_1} \\cdot \\frac{\\partial \\text{Y}_1}{\\partial Y_1^d}\\\\\n",
    "\\end{cases}  & \n",
    "\\frac{\\partial Loss}{\\partial Y_x^2} = \\begin{cases}\n",
    "\\frac{\\partial Loss}{\\partial Y^2_a} = \\frac{\\partial Loss}{\\partial \\text{Y}_2} \\cdot \\frac{\\partial \\text{Y}_2}{\\partial Y_2^a}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^2_b} = \\frac{\\partial Loss}{\\partial \\text{Y}_2} \\cdot \\frac{\\partial \\text{Y}_2}{\\partial Y_2^b}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^2_c} = \\frac{\\partial Loss}{\\partial \\text{Y}_2} \\cdot \\frac{\\partial \\text{Y}_2}{\\partial Y_2^c}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^2_d} = \\frac{\\partial Loss}{\\partial \\text{Y}_2} \\cdot \\frac{\\partial \\text{Y}_2}{\\partial Y_2^d}\\\\\n",
    "\\end{cases}  & \n",
    "\\frac{\\partial Loss}{\\partial Y_x^3} = \\begin{cases}\n",
    "\\frac{\\partial Loss}{\\partial Y^3_a} = \\frac{\\partial Loss}{\\partial \\text{Y}_3} \\cdot \\frac{\\partial \\text{Y}_3}{\\partial Y_3^a}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^3_b} = \\frac{\\partial Loss}{\\partial \\text{Y}_3} \\cdot \\frac{\\partial \\text{Y}_3}{\\partial Y_3^b}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^3_c} = \\frac{\\partial Loss}{\\partial \\text{Y}_3} \\cdot \\frac{\\partial \\text{Y}_3}{\\partial Y_3^c}\\\\\n",
    "\\frac{\\partial Loss}{\\partial Y^3_d} = \\frac{\\partial Loss}{\\partial \\text{Y}_3} \\cdot \\frac{\\partial \\text{Y}_3}{\\partial Y_3^d}\\\\\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\\\\]\n",
    "\n",
    "\n",
    "\n",
    "Since the phrase representation we used is the mean of the attention outputs, we can simplify the derivative with respect to each attention component as:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\\partial \\text{Y}_i}{\\partial Y_x^i} = \\frac{1}{4}\n",
    "\\\\]\n",
    "\n",
    "Therefore, the gradient of the loss with respect to each attention component is:\n",
    "\n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial A} = \\begin{cases}\n",
    "\\frac{\\partial Loss}{\\partial Y_a^i} = \\frac{1}{4} \\frac{\\partial Loss}{\\partial \\text{Y}_i}; \\\\\n",
    "\\frac{\\partial Loss}{\\partial Y_b^i} = \\frac{1}{4} \\frac{\\partial Loss}{\\partial \\text{Y}_i}; \\\\\n",
    "\\frac{\\partial Loss}{\\partial Y_c^i} = \\frac{1}{4} \\frac{\\partial Loss}{\\partial \\text{Y}_i}; \\\\\n",
    "\\frac{\\partial Loss}{\\partial Y_d^i} = \\frac{1}{4} \\frac{\\partial Loss}{\\partial \\text{Y}_i};  \n",
    "\\end{cases} \n",
    "\\\\]\n",
    "This shows how the gradient propagates through the mean operation during backpropagation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2734b391-4b7c-49a9-9151-3828b844b17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.01686771, -0.00557901, -0.02955251,  0.05021109,\n",
       "          0.00092608, -0.00920956, -0.00135987,  0.0297596 ,\n",
       "          0.0020878 , -0.03875599],\n",
       "        [-0.01686771, -0.00557901, -0.02955251,  0.05021109,\n",
       "          0.00092608, -0.00920956, -0.00135987,  0.0297596 ,\n",
       "          0.0020878 , -0.03875599],\n",
       "        [-0.01686771, -0.00557901, -0.02955251,  0.05021109,\n",
       "          0.00092608, -0.00920956, -0.00135987,  0.0297596 ,\n",
       "          0.0020878 , -0.03875599],\n",
       "        [-0.01686771, -0.00557901, -0.02955251,  0.05021109,\n",
       "          0.00092608, -0.00920956, -0.00135987,  0.0297596 ,\n",
       "          0.0020878 , -0.03875599]],\n",
       "\n",
       "       [[ 0.02825741,  0.00934616,  0.04950747, -0.0841155 ,\n",
       "         -0.0015514 ,  0.0154282 ,  0.00227811, -0.0498544 ,\n",
       "         -0.00349756,  0.06492549],\n",
       "        [ 0.02825741,  0.00934616,  0.04950747, -0.0841155 ,\n",
       "         -0.0015514 ,  0.0154282 ,  0.00227811, -0.0498544 ,\n",
       "         -0.00349756,  0.06492549],\n",
       "        [ 0.02825741,  0.00934616,  0.04950747, -0.0841155 ,\n",
       "         -0.0015514 ,  0.0154282 ,  0.00227811, -0.0498544 ,\n",
       "         -0.00349756,  0.06492549],\n",
       "        [ 0.02825741,  0.00934616,  0.04950747, -0.0841155 ,\n",
       "         -0.0015514 ,  0.0154282 ,  0.00227811, -0.0498544 ,\n",
       "         -0.00349756,  0.06492549]],\n",
       "\n",
       "       [[ 0.02844265,  0.00940743,  0.04983201, -0.08466691,\n",
       "         -0.00156157,  0.01552933,  0.00229305, -0.05018122,\n",
       "         -0.00352049,  0.0653511 ],\n",
       "        [ 0.02844265,  0.00940743,  0.04983201, -0.08466691,\n",
       "         -0.00156157,  0.01552933,  0.00229305, -0.05018122,\n",
       "         -0.00352049,  0.0653511 ],\n",
       "        [ 0.02844265,  0.00940743,  0.04983201, -0.08466691,\n",
       "         -0.00156157,  0.01552933,  0.00229305, -0.05018122,\n",
       "         -0.00352049,  0.0653511 ],\n",
       "        [ 0.02844265,  0.00940743,  0.04983201, -0.08466691,\n",
       "         -0.00156157,  0.01552933,  0.00229305, -0.05018122,\n",
       "         -0.00352049,  0.0653511 ]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient for attention\n",
    "dL_dA = np.array([np.outer(np.ones(inputs.shape[1]), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])  / inputs.shape[1]\n",
    "dL_dA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc8cbe16-671a-4538-bd86-568334032b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 2, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk,dv,num_head,num_prases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ff059ae-8ff8-49b5-9a48-2d368655b754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "74f8b14e-bfbb-4952-92e5-6e3e8151efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dA =dL_dA.reshape(num_prases, num_head, words_per_phrase, dv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbea7979-f839-4249-8d10-29a3b2970fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 4, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eaeb3407-984b-48f3-a746-49b233f04db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier: \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        \n",
    "         # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array([np.outer(np.ones(self.words_per_phrase), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b60002-82cd-4ec8-bdf9-23e91566d6d6",
   "metadata": {},
   "source": [
    "### Gradient of the loss with respect to values matrix V:\n",
    " \n",
    "\n",
    "The gradient of the loss with respect to values matrix can be expressed as:\n",
    "\\\\[\n",
    "\\text{A} =\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})V_{val} = \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})\\cdot Inputs \\cdot V\n",
    "\\\\]\n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{V}} =\\frac{\\partial Loss}{\\partial A} \\cdot \\frac{\\partial A}{\\partial V}=\\frac{\\partial Loss}{\\partial A} \\cdot \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})\\cdot Inputs\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2aef4f23-ca5c-4ece-8d9a-961165860b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.22281228, 0.25240305, 0.26251364, 0.26227103],\n",
       "         [0.21602351, 0.25259832, 0.26490351, 0.26647466],\n",
       "         [0.21409933, 0.25306287, 0.26614862, 0.26668918],\n",
       "         [0.21360632, 0.25317839, 0.26643467, 0.26678062]],\n",
       "\n",
       "        [[0.23605767, 0.24867222, 0.25584653, 0.25942358],\n",
       "         [0.23198096, 0.24857683, 0.25749853, 0.26194368],\n",
       "         [0.23106605, 0.24813294, 0.25767411, 0.2631269 ],\n",
       "         [0.23023345, 0.24892884, 0.25834394, 0.26249377]]],\n",
       "\n",
       "\n",
       "       [[[0.24139968, 0.26307675, 0.23776207, 0.2577615 ],\n",
       "         [0.2394024 , 0.26488819, 0.23553521, 0.2601742 ],\n",
       "         [0.2408145 , 0.26350941, 0.23726271, 0.25841338],\n",
       "         [0.23818729, 0.26692355, 0.23386242, 0.26102674]],\n",
       "\n",
       "        [[0.24598997, 0.25560719, 0.2408696 , 0.25753324],\n",
       "         [0.24494218, 0.25631488, 0.23964761, 0.25909533],\n",
       "         [0.24581957, 0.25589889, 0.24085769, 0.25742385],\n",
       "         [0.24449457, 0.25742032, 0.23897768, 0.25910743]]],\n",
       "\n",
       "\n",
       "       [[[0.19751058, 0.25975194, 0.3079247 , 0.23481279],\n",
       "         [0.18299067, 0.26202929, 0.32587536, 0.22910469],\n",
       "         [0.17577051, 0.26259094, 0.33556982, 0.22606872],\n",
       "         [0.19108746, 0.26078458, 0.31575204, 0.23237592]],\n",
       "\n",
       "        [[0.22413735, 0.26993255, 0.26930736, 0.23662273],\n",
       "         [0.21495139, 0.27686502, 0.27679072, 0.23139287],\n",
       "         [0.2111177 , 0.28113346, 0.27896901, 0.22877982],\n",
       "         [0.22015356, 0.27441367, 0.27162034, 0.23381244]]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e925ac2d-a640-4512-81ce-41e6a3f98092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.01686771, -0.00920956, -0.01686771, -0.00920956],\n",
       "         [-0.00557901, -0.00135987, -0.00557901, -0.00135987],\n",
       "         [-0.02955251,  0.0297596 , -0.02955251,  0.0297596 ],\n",
       "         [ 0.05021109,  0.0020878 ,  0.05021109,  0.0020878 ],\n",
       "         [ 0.00092608, -0.03875599,  0.00092608, -0.03875599]],\n",
       "\n",
       "        [[-0.01686771, -0.00920956, -0.01686771, -0.00920956],\n",
       "         [-0.00557901, -0.00135987, -0.00557901, -0.00135987],\n",
       "         [-0.02955251,  0.0297596 , -0.02955251,  0.0297596 ],\n",
       "         [ 0.05021109,  0.0020878 ,  0.05021109,  0.0020878 ],\n",
       "         [ 0.00092608, -0.03875599,  0.00092608, -0.03875599]]],\n",
       "\n",
       "\n",
       "       [[[ 0.02825741,  0.0154282 ,  0.02825741,  0.0154282 ],\n",
       "         [ 0.00934616,  0.00227811,  0.00934616,  0.00227811],\n",
       "         [ 0.04950747, -0.0498544 ,  0.04950747, -0.0498544 ],\n",
       "         [-0.0841155 , -0.00349756, -0.0841155 , -0.00349756],\n",
       "         [-0.0015514 ,  0.06492549, -0.0015514 ,  0.06492549]],\n",
       "\n",
       "        [[ 0.02825741,  0.0154282 ,  0.02825741,  0.0154282 ],\n",
       "         [ 0.00934616,  0.00227811,  0.00934616,  0.00227811],\n",
       "         [ 0.04950747, -0.0498544 ,  0.04950747, -0.0498544 ],\n",
       "         [-0.0841155 , -0.00349756, -0.0841155 , -0.00349756],\n",
       "         [-0.0015514 ,  0.06492549, -0.0015514 ,  0.06492549]]],\n",
       "\n",
       "\n",
       "       [[[ 0.02844265,  0.01552933,  0.02844265,  0.01552933],\n",
       "         [ 0.00940743,  0.00229305,  0.00940743,  0.00229305],\n",
       "         [ 0.04983201, -0.05018122,  0.04983201, -0.05018122],\n",
       "         [-0.08466691, -0.00352049, -0.08466691, -0.00352049],\n",
       "         [-0.00156157,  0.0653511 , -0.00156157,  0.0653511 ]],\n",
       "\n",
       "        [[ 0.02844265,  0.01552933,  0.02844265,  0.01552933],\n",
       "         [ 0.00940743,  0.00229305,  0.00940743,  0.00229305],\n",
       "         [ 0.04983201, -0.05018122,  0.04983201, -0.05018122],\n",
       "         [-0.08466691, -0.00352049, -0.08466691, -0.00352049],\n",
       "         [-0.00156157,  0.0653511 , -0.00156157,  0.0653511 ]]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(dL_dA,(0,1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4729440e-770a-4d0f-8f6e-c9a310eda190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 5, 4)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_Vval=np.transpose(dL_dA,(0,1,3,2))@Attention_weights \n",
    "d_Vval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40894489-8059-4d72-ac0b-0028a5af8145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704feda4-573c-4f0d-a788-db5ce650a672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17f28c59-ebe7-49e4-a254-84b788090699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 5, 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(d_Vval,inputs.reshape(num_prases, 1, words_per_phrase, inputs.shape[2])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4577a940-455b-42df-9128-4a178a230075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.mean(np.matmul(d_Vval,inputs.reshape(num_prases, 1, words_per_phrase, inputs.shape[2])),axis=0),(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b5cf74a-090d-42ad-ac9c-86772f81ee84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.01762669,  0.00469007, -0.00014544, -0.03534795,\n",
       "           0.02557546],\n",
       "         [ 0.02667187,  0.00709996, -0.00013401, -0.05353434,\n",
       "           0.03862594],\n",
       "         [ 0.01720924,  0.00457767, -0.00017823, -0.03449081,\n",
       "           0.02500075],\n",
       "         [ 0.02389885,  0.00635858, -0.00020738, -0.04792029,\n",
       "           0.03468475],\n",
       "         [ 0.02152672,  0.00572771, -0.00017967, -0.04316781,\n",
       "           0.03123596],\n",
       "         [ 0.01314346,  0.00349742, -0.00010216, -0.02636091,\n",
       "           0.01906513]],\n",
       " \n",
       "        [[ 0.01665734,  0.00443185, -0.00014557, -0.03339956,\n",
       "           0.02417593],\n",
       "         [ 0.02630477,  0.00700087, -0.00016938, -0.05277698,\n",
       "           0.03812615],\n",
       "         [ 0.01732586,  0.00460938, -0.00016059, -0.03473494,\n",
       "           0.02515405],\n",
       "         [ 0.02411811,  0.0064173 , -0.00019885, -0.04836571,\n",
       "           0.03499406],\n",
       "         [ 0.02176188,  0.00579035, -0.00017982, -0.04364038,\n",
       "           0.03157563],\n",
       "         [ 0.01263291,  0.00336146, -0.00010091, -0.02533544,\n",
       "           0.01832688]]]),\n",
       " (2, 6, 5))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient for V\n",
    "d_Vval=np.matmul(np.transpose(dL_dA,(0,1,3,2)), Attention_weights) \n",
    "dLoss_dV = np.transpose(np.mean(np.matmul(d_Vval,inputs.reshape(num_prases, 1, words_per_phrase, inputs.shape[2])),axis=0),(0,2,1)) \n",
    "dLoss_dV,dLoss_dV.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4ce2ade-d0f1-4230-8611-38543adde97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb8a0f-28a1-4190-9bf2-0f41f2ce9139",
   "metadata": {},
   "source": [
    "### Gradient of the loss with respect to values matrix Q:\n",
    " \n",
    " \n",
    "The gradient of the loss with respect to queries matrix can be expressed as:\n",
    "\\\\[\n",
    "\\text{A} =\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})V_{val}  \n",
    "\\\\]\n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{Q}} =\\frac{\\partial Loss}{\\partial A} \\cdot \\frac{\\partial A}{\\partial Q} \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial A}{\\partial Q}  = \\frac{\\partial \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial Q} \\cdot V_{val} \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial Q}   = \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})] \\cdot \n",
    "\\frac{\\partial (\\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial Q}\n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial (\\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial Q} = \\frac{\\partial (\\frac{Inputs \\cdot Q \\cdot K_{val}^T}{\\sqrt{d_k}})}{\\partial Q}=\\frac{Inputs \\cdot K_{val}^T}{\\sqrt{d_k}}\n",
    "\\\\]  \n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{Q}} =\\frac{\\partial Loss}{\\partial A} \\cdot [\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})]] \\cdot \\frac{Inputs \\cdot K_{val}^T}{\\sqrt{d_k}} \\cdot V_{val}\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "076035fe-5128-4f4b-ba42-952eddaf4a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.1, 0.2, 0.3, 0.4, 0.5, 0.3],\n",
       "         [0.5, 0.4, 0.7, 0.3, 0.2, 0.3],\n",
       "         [0.2, 0.7, 0.3, 0.5, 0.4, 0.4],\n",
       "         [0.4, 0.1, 0.7, 0.2, 0.5, 0.7]],\n",
       " \n",
       "        [[0.1, 0.9, 0.3, 0.4, 0.5, 0.2],\n",
       "         [0.4, 0.4, 0.7, 0.3, 0.4, 0.6],\n",
       "         [0.2, 0.7, 0.4, 0.5, 0.4, 0.2],\n",
       "         [0.4, 0.5, 0.7, 0.7, 0.5, 0.1]],\n",
       " \n",
       "        [[0.1, 0.2, 0.3, 0.8, 0.5, 0.2],\n",
       "         [0.4, 0.5, 0.7, 0.3, 0.8, 0.4],\n",
       "         [0.9, 0.7, 0.3, 0.5, 0.4, 0.6],\n",
       "         [0.4, 0.5, 0.1, 0.7, 0.4, 0.4]]]),\n",
       " (3, 4, 6))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs,inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c93b9c06-d450-4cab-88ba-377642f62c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 4)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(inputs,(0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e463ccec-800e-44e0-be23-ec1dcfb1a4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 6, 4)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(inputs,(0,2,1)).reshape(num_prases,1,inputs.shape[2],words_per_phrase).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e623f5e-f4fc-48e4-87d9-e1ba4dd28f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 4, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57636286-9ef0-41a1-bf5a-a472736f17ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f9f1e45c-c162-4269-a900-74888aeef18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 4, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0852d1bd-d95f-4e28-8082-7f408354376f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dAttention_dSoftmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdAttention_dSoftmax\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dAttention_dSoftmax' is not defined"
     ]
    }
   ],
   "source": [
    "dAttention_dSoftmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977eb51-7758-462c-8e4c-31e33e3b4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(dL_dA,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19c850-a7fd-4397-8150-4b0272af2186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe169fae-c86f-4e0e-8718-6faef0b4e32e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dQKscaled_dQ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mdQKscaled_dQ\u001b[49m,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dQKscaled_dQ' is not defined"
     ]
    }
   ],
   "source": [
    "np.transpose(dQKscaled_dQ,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74ee5970-619d-458a-8384-e60d45911814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dAttention_dSoftmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(dL_dA,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@dAttention_dSoftmax\u001b[39m\n\u001b[0;32m      2\u001b[0m A\u001b[38;5;241m.\u001b[39mshape                   \n",
      "\u001b[1;31mNameError\u001b[0m: name 'dAttention_dSoftmax' is not defined"
     ]
    }
   ],
   "source": [
    "A=np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax\n",
    "A.shape                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d23797c1-89c7-466d-89ae-51132a788f15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dQKscaled_dQ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdQKscaled_dQ\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dQKscaled_dQ' is not defined"
     ]
    }
   ],
   "source": [
    "dQKscaled_dQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6030b70-988a-43de-a6a4-5092c736f038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m B\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mA\u001b[49m,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@dQKscaled_dQ\u001b[39m\n\u001b[0;32m      2\u001b[0m B\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "B=np.transpose(A,(0,1,3,2))@dQKscaled_dQ\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d91b9915-c25f-4e6d-9afb-d13baa5a15bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mB\u001b[49m,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@Vval\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "np.transpose(B,(0,1,3,2))@Vval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c19169b-63ac-4dbd-a137-b5652ba4ab56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f87a8204-4caa-42dd-b16a-8963959ce57d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dQKscaled_dQ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdQKscaled_dQ\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dQKscaled_dQ' is not defined"
     ]
    }
   ],
   "source": [
    "dQKscaled_dQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a5965bcf-13e8-4337-add0-a3b89df2742b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dAttention_dSoftmax\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(Attention_weights,(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mAttention_weights))\n\u001b[0;32m      4\u001b[0m A\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(dL_dA,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@dAttention_dSoftmax\u001b[39m\n\u001b[1;32m----> 5\u001b[0m B\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@dQKscaled_dQ\u001b[39;49m\n\u001b[0;32m      6\u001b[0m C\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(B,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@Vval\u001b[39m \n\u001b[0;32m      7\u001b[0m dLoss_dQ\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mmean(C,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)"
     ]
    }
   ],
   "source": [
    "#Gradient of Q\n",
    "dQKscaled_dQ=np.matmul(np.transpose(inputs,(0,2,1)).reshape(num_prases,1,inputs.shape[2],words_per_phrase),Kval)/np.sqrt(dk)\n",
    "dAttention_dSoftmax=np.matmul(Attention_weights,(1-Attention_weights))\n",
    "A=np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax\n",
    "B=np.transpose(A,(0,1,3,2))@dQKscaled_dQ\n",
    "C=np.transpose(B,(0,1,3,2))@Vval \n",
    "dLoss_dQ=np.transpose(np.mean(C,axis=0),(0,2,1))\n",
    "dLoss_dQ\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6154c95b-a361-465f-952a-0c2ad481204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 5)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0113ab83-caf6-4ae2-baa8-401b51721438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 5)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee3113bd-d3ac-48ab-9eba-93de732e2fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dQKscaled_dQ\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(inputs,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(num_prases,\u001b[38;5;241m1\u001b[39m,inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],words_per_phrase),Kval)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(dk)\n\u001b[0;32m      3\u001b[0m dAttention_dSoftmax\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(Attention_weights,(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mAttention_weights))\n\u001b[1;32m----> 4\u001b[0m dLoss_dQ\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL_dA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129m@dAttention_dSoftmax\u001b[39m,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose( dQKscaled_dQ,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;129m@Vval\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m dLoss_dQ\n",
      "File \u001b[1;32m~\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:655\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m    Returns an array with axes transposed.\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "#Gradient of Q\n",
    "dQKscaled_dQ=np.matmul(np.transpose(inputs,(0,2,1)).reshape(num_prases,1,inputs.shape[2],words_per_phrase),Kval)/np.sqrt(dk)\n",
    "dAttention_dSoftmax=np.matmul(Attention_weights,(1-Attention_weights))\n",
    "dLoss_dQ=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@np.transpose( dQKscaled_dQ,(0,2,1)),(0,2,1))@Vval,axis=0)\n",
    "dLoss_dQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271928d-103a-44e4-800d-ce8cc38c4bec",
   "metadata": {},
   "source": [
    "### Gradient of the loss with respect to values matrix K:\n",
    " \n",
    " \n",
    "The gradient of the loss with respect to queries matrix can be expressed as:\n",
    "\\\\[\n",
    "\\text{A} =\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})V_{val}  \n",
    "\\\\]\n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{K}} =\\frac{\\partial Loss}{\\partial A} \\cdot \\frac{\\partial A}{\\partial K} \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial A}{\\partial K}  = \\frac{\\partial \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial K} \\cdot V_{val} \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial K}   = \\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})] \\cdot \n",
    "\\frac{\\partial (\\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial K}\n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\frac{\\partial (\\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})}{\\partial K} = \\frac{\\partial (\\frac{Q_{val} \\cdot Inputs \\cdot K }{\\sqrt{d_k}})}{\\partial K}=\\frac{Q_{val} \\cdot Inputs}{\\sqrt{d_k}}\n",
    "\\\\]  \n",
    "\\\\[ \n",
    "\\frac{\\partial Loss}{\\partial \\text{K}} =\\frac{\\partial Loss}{\\partial A} \\cdot [\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}}) \\cdot [1-\\sigma( \\frac{Q_{val}K_{val}^T}{\\sqrt{d_k}})]] \\cdot \\frac{Q_{val} \\cdot Inputs}{\\sqrt{d_k}} \\cdot V_{val}\n",
    "\\\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "38d4d6fd-5324-47f7-8247-134054db7ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.13315715, 0.36160432, 0.3870892 , 0.4078847 , 0.28349901],\n",
       "         [0.2791403 , 0.38482965, 0.48216021, 0.49335054, 0.4837765 ],\n",
       "         [0.22351638, 0.46213427, 0.49217453, 0.53306329, 0.48519063],\n",
       "         [0.27752218, 0.42732385, 0.49753365, 0.57876492, 0.39402241]],\n",
       "\n",
       "        [[0.46183388, 0.32327784, 0.29735276, 0.32411487, 0.51005132],\n",
       "         [0.53980734, 0.47515922, 0.40018635, 0.43077769, 0.726098  ],\n",
       "         [0.68728035, 0.48894789, 0.46095752, 0.50693222, 0.73001509],\n",
       "         [0.59188693, 0.51441092, 0.45111115, 0.40773682, 0.74328136]],\n",
       "\n",
       "        [[0.29235756, 0.22250554, 0.47378881, 0.30647452, 0.28416896],\n",
       "         [0.36217101, 0.42308144, 0.47386521, 0.46357898, 0.42190007],\n",
       "         [0.42596616, 0.40717232, 0.63895836, 0.4824136 , 0.42962552],\n",
       "         [0.46073358, 0.36807765, 0.52029214, 0.49858521, 0.42415067]]],\n",
       "\n",
       "\n",
       "       [[[0.20201394, 0.47572828, 0.47672607, 0.54396823, 0.51715281],\n",
       "         [0.29596945, 0.46446822, 0.52575314, 0.60709827, 0.48811349],\n",
       "         [0.20908445, 0.45890679, 0.4915192 , 0.51824566, 0.49408969],\n",
       "         [0.25784595, 0.55525477, 0.6545037 , 0.61224924, 0.57768227]],\n",
       "\n",
       "        [[0.67706686, 0.46392368, 0.43025726, 0.50126501, 0.66803174],\n",
       "         [0.67361865, 0.56522258, 0.48642673, 0.49024795, 0.81755679],\n",
       "         [0.640311  , 0.45854352, 0.40923771, 0.48944206, 0.70076253],\n",
       "         [0.68956196, 0.51966588, 0.44249898, 0.55211307, 0.86937102]],\n",
       "\n",
       "        [[0.38328604, 0.41398526, 0.65709064, 0.47386152, 0.46392757],\n",
       "         [0.47106386, 0.44277368, 0.59172406, 0.55056958, 0.4789179 ],\n",
       "         [0.36353366, 0.39770462, 0.62188093, 0.45072633, 0.43034967],\n",
       "         [0.38753127, 0.44635865, 0.70798085, 0.49235434, 0.48962835]]],\n",
       "\n",
       "\n",
       "       [[[0.1232895 , 0.44449502, 0.48871217, 0.44099315, 0.33051166],\n",
       "         [0.30507354, 0.57996645, 0.66496134, 0.7151694 , 0.58620506],\n",
       "         [0.43276044, 0.5405659 , 0.77966545, 0.65180438, 0.74219799],\n",
       "         [0.23887343, 0.45719294, 0.57863729, 0.48497369, 0.48858038]],\n",
       "\n",
       "        [[0.55018259, 0.35628501, 0.31816763, 0.41426481, 0.6397273 ],\n",
       "         [0.73265547, 0.56865408, 0.52963351, 0.52704303, 0.84854355],\n",
       "         [0.80799335, 0.62176557, 0.72269528, 0.62178738, 1.01078114],\n",
       "         [0.65683523, 0.44267736, 0.49631242, 0.49667734, 0.75676338]],\n",
       "\n",
       "        [[0.29756973, 0.23607201, 0.59933003, 0.3119878 , 0.28968741],\n",
       "         [0.50478325, 0.4769879 , 0.71631089, 0.5771954 , 0.56600585],\n",
       "         [0.66588441, 0.63287246, 0.68064768, 0.65088926, 0.55704719],\n",
       "         [0.4587019 , 0.39251885, 0.61827979, 0.43543525, 0.36995715]]]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c1f4a278-e55d-4dc6-8706-77c0e90b4f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1, 0.2, 0.3, 0.4, 0.5, 0.3],\n",
       "        [0.5, 0.4, 0.7, 0.3, 0.2, 0.3],\n",
       "        [0.2, 0.7, 0.3, 0.5, 0.4, 0.4],\n",
       "        [0.4, 0.1, 0.7, 0.2, 0.5, 0.7]],\n",
       "\n",
       "       [[0.1, 0.9, 0.3, 0.4, 0.5, 0.2],\n",
       "        [0.4, 0.4, 0.7, 0.3, 0.4, 0.6],\n",
       "        [0.2, 0.7, 0.4, 0.5, 0.4, 0.2],\n",
       "        [0.4, 0.5, 0.7, 0.7, 0.5, 0.1]],\n",
       "\n",
       "       [[0.1, 0.2, 0.3, 0.8, 0.5, 0.2],\n",
       "        [0.4, 0.5, 0.7, 0.3, 0.8, 0.4],\n",
       "        [0.9, 0.7, 0.3, 0.5, 0.4, 0.6],\n",
       "        [0.4, 0.5, 0.1, 0.7, 0.4, 0.4]]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a013d29a-cc13-4afa-bd3a-4b17fe939130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3, 4, 5), (3, 4, 6))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qval.shape,inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "18f4d913-d9f6-4b2d-86ee-2c913786f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5, 4)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Qval,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f7768-b335-497d-9a91-d34ad5ac4a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b6a0be64-e78c-4375-bf5a-9f3a69af453f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5, 6)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQKscaled_dK=np.transpose(Qval,(0,1,3,2))@inputs.reshape(num_prases,1,words_per_phrase,inputs.shape[2])/np.sqrt(dk)\n",
    "dQKscaled_dK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e58c0-eb7b-4e39-9ca3-0c4fd80c03cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e74cbcf6-fcac-4b9a-85e7-5e4ec5766b95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 6, 4)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2ca40c4d-24b1-435a-8d4b-d0d300f4b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5, 6)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQKscaled_dK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "76c8e73e-b568-4110-b8e2-1c2a1f08fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 6, 5)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(dQKscaled_dK,(0,1,3,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4c50188d-91c7-4418-8643-edfbb875ceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 5)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=np.transpose(A,(0,1,3,2))@np.transpose(dQKscaled_dK,(0,1,3,2)) \n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "02b0cb3c-7a85-42c9-9d5e-089fda8346b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 6)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f96a2a18-f38a-4775-bb86-5fbe6a8807b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4169357 , 0.30186363, 0.34419425, 0.23502904, 0.32662851,\n",
       "         0.31072044],\n",
       "        [0.30932963, 0.22403817, 0.25588742, 0.1737776 , 0.24155532,\n",
       "         0.23091452],\n",
       "        [0.42908947, 0.31097847, 0.35412103, 0.24407391, 0.33902599,\n",
       "         0.32211283],\n",
       "        [0.5635516 , 0.40851269, 0.46586541, 0.31945499, 0.44382374,\n",
       "         0.42335686],\n",
       "        [0.29097067, 0.21068087, 0.24057167, 0.16335649, 0.22707718,\n",
       "         0.2168209 ]],\n",
       "\n",
       "       [[0.52034467, 0.45738922, 0.46433001, 0.45151806, 0.39513784,\n",
       "         0.49152739],\n",
       "        [0.46468998, 0.40661999, 0.41404908, 0.4030244 , 0.34935266,\n",
       "         0.43735076],\n",
       "        [0.40860874, 0.35869396, 0.36449342, 0.35446122, 0.30947628,\n",
       "         0.38550121],\n",
       "        [0.47508958, 0.41660834, 0.42349181, 0.41232885, 0.35847669,\n",
       "         0.44815612],\n",
       "        [0.52980829, 0.46564822, 0.47253832, 0.4600627 , 0.40151321,\n",
       "         0.50085877]],\n",
       "\n",
       "       [[0.57481968, 0.40871946, 0.37473369, 0.55996618, 0.45650519,\n",
       "         0.70048358],\n",
       "        [0.47636277, 0.3382521 , 0.31036362, 0.46373498, 0.3785589 ,\n",
       "         0.58078912],\n",
       "        [0.39514254, 0.2816675 , 0.25757378, 0.3851429 , 0.31370562,\n",
       "         0.48113654],\n",
       "        [0.46285483, 0.32926165, 0.30145103, 0.4506842 , 0.36781389,\n",
       "         0.56400211],\n",
       "        [0.32754399, 0.23291446, 0.2134678 , 0.3190294 , 0.2601782 ,\n",
       "         0.39914997]]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(C,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7873e792-bda8-4516-b845-7d7b998e8690",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dAttention_dSoftmax\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(Attention_weights,(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mAttention_weights))\n\u001b[0;32m      4\u001b[0m A\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(dL_dA,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@dAttention_dSoftmax\u001b[39m\n\u001b[1;32m----> 5\u001b[0m B\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@np\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdQKscaled_dK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m C\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(B,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m))\u001b[38;5;129m@Vval\u001b[39m\n\u001b[0;32m      7\u001b[0m dLoss_dK\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mmean(C,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 5)"
     ]
    }
   ],
   "source": [
    " \n",
    "#gradient of K\n",
    "dQKscaled_dK=np.transpose(Qval,(0,1,3,2))@inputs.reshape(num_prases,1,words_per_phrase,inputs.shape[2])/np.sqrt(dk)\n",
    "dAttention_dSoftmax=np.matmul(Attention_weights,(1-Attention_weights))\n",
    "A=np.transpose(dL_dA,(0,1,3,2))@dAttention_dSoftmax\n",
    "B=np.transpose(A,(0,1,3,2))@np.transpose(dQKscaled_dK,(0,1,3,2)) \n",
    "C=np.transpose(B,(0,1,3,2))@Vval\n",
    "dLoss_dK=np.transpose(np.mean(C,axis=0),(0,2,1))\n",
    "dLoss_dK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640378f-b399-40f2-9251-4531500c6a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6104f84f-0b8e-4fde-b0f8-1c183e99cd67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 5)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5b4cd2e4-89bc-4b91-9d6f-cbebe65dc0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 5)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74766bc9-de8b-48d3-b7c4-fd377c1508bf",
   "metadata": {},
   "source": [
    "Adding all the gradients in the backpropagation of our classifier we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "a76b2355-c353-4cfc-8167-e842ff53b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier: \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        \n",
    "         # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array([np.outer(np.ones(self.words_per_phrase), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval=np.matmul(np.transpose(d_attention,(0,2,1)), self.Attention_weights) \n",
    "        dLoss_dV = np.mean(np.matmul(d_Vval,inputs),axis=0).T\n",
    "        \n",
    "        #Gradient of softmax\n",
    "        dAttention_dSoftmax=np.matmul(self.Attention_weights,(1-self.Attention_weights))\n",
    "        \n",
    "        #Gradient of Q\n",
    "        dQKscaled_dQ=np.matmul(np.transpose(inputs,(0,2,1)),self.Kval)/np.sqrt(self.dk)\n",
    "        dLoss_dQ=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@np.transpose( dQKscaled_dQ,(0,2,1)),(0,2,1))@self.Vval,axis=0)\n",
    "        \n",
    "        #Gradient of K\n",
    "        dQKscaled_dK=np.transpose(self.Qval,(0,2,1))@inputs/np.sqrt(self.dk) \n",
    "        dLoss_dK=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@dQKscaled_dK,(0,2,1))@Vself.val,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b98c1f-4438-4183-af8a-3855d863b94d",
   "metadata": {},
   "source": [
    "### Parameters update:\n",
    " \n",
    " \n",
    "Fixing a value for the learning rate \\eta we can now proceed to update the model parameters:\n",
    "\\\\[\n",
    "\\text{Q} = \\text{Q} - \\eta \\cdot \\frac{\\partial Loss}{\\partial Q}\\\\   \n",
    "\\\\]\n",
    "\\\\[ \n",
    "\\text{V} = \\text{V} - \\eta \\cdot \\frac{\\partial Loss}{\\partial V}\\\\ \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\text{K} = \\text{K} - \\eta \\cdot \\frac{\\partial Loss}{\\partial K}\\\\  \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\text{W} = \\text{W} - \\eta \\cdot \\frac{\\partial Loss}{\\partial W}\\\\  \n",
    "\\\\] \n",
    "\\\\[ \n",
    "\\text{b} = \\text{b} - \\eta \\cdot \\frac{\\partial Loss}{\\partial b}\\\\  \n",
    "\\\\]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dee326-dcbc-4cf4-9477-0d23a66a45fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1c179624-513e-4b6e-81f2-0e468523eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "learning_rate=0.001\n",
    "Q -= learning_rate * dLoss_dQ\n",
    "K -= learning_rate * dLoss_dK\n",
    "V -= learning_rate * dLoss_dV\n",
    "linearlayer -= learning_rate * d_linear\n",
    "linear_bias -= learning_rate * d_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538f436-433c-419c-a253-c0efe256a5e0",
   "metadata": {},
   "source": [
    "Putting together all the steps we finally have the classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "df45d5ed-1d29-4f99-a24b-529148fe03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, batch_size, dk, dv, num_classes):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "        \n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.K = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.V = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dk, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        return np.mean(batch_loss)\n",
    "\n",
    "    def AttentionHead(self, Inputs):\n",
    "        self.Qval = np.dot(Inputs, self.Q)\n",
    "        self.Kval = np.dot(Inputs, self.K)\n",
    "        self.Vval = np.dot(Inputs, self.V)\n",
    "\n",
    "        QKscaled = np.matmul(self.Qval, np.transpose(self.Kval, (0, 2, 1))) / np.sqrt(self.K.shape[1])\n",
    "        # QKscaled = np.clip(QKscaled, -1e2, 1e2)\n",
    "        self.Attention_weights = self.softmax(QKscaled)\n",
    "\n",
    "        return np.matmul(self.Attention_weights, self.Vval)\n",
    "\n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "\n",
    "        Attention = self.AttentionHead(Inputs)\n",
    "\n",
    "        self.phrase_representation = np.mean(Attention, axis=1)\n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "\n",
    "        return Sigma_Zout\n",
    "        \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        \n",
    "         # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array([np.outer(np.ones(self.words_per_phrase), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval=np.matmul(np.transpose(dL_dA,(0,2,1)), self.Attention_weights) \n",
    "        dLoss_dV = np.mean(np.matmul(d_Vval,inputs),axis=0).T\n",
    "        \n",
    "        #Gradient of softmax\n",
    "        dAttention_dSoftmax=np.matmul(self.Attention_weights,(1-self.Attention_weights))\n",
    "        \n",
    "        #Gradient of Q\n",
    "        dQKscaled_dQ=np.matmul(np.transpose(inputs,(0,2,1)),self.Kval)/np.sqrt(self.dk)\n",
    "        dLoss_dQ=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@np.transpose( dQKscaled_dQ,(0,2,1)),(0,2,1))@self.Vval,axis=0)\n",
    "        \n",
    "        #Gradient of K\n",
    "        dQKscaled_dK=np.transpose(self.Qval,(0,2,1))@inputs/np.sqrt(dk) \n",
    "        dLoss_dK=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@dQKscaled_dK,(0,2,1))@self.Vval,axis=0)\n",
    "        \n",
    "        #Gradient clipping\n",
    "        clip_value = 10.0\n",
    "        dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = np.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "\n",
    "        self.UpdateParams(dLoss_dQ,dLoss_dK,dLoss_dV,dlinear_dW,d_bias)\n",
    "\n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.Q -= self.learning_rate * dLoss_dQ\n",
    "        self.K -= self.learning_rate * dLoss_dK\n",
    "        self.V -= self.learning_rate * dLoss_dV\n",
    "        self.linearlayer -= self.learning_rate * dlinear_dW\n",
    "        self.linear_bias -= self.learning_rate * d_bias\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "\n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                yi = self.forward(X_batch)\n",
    "\n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "\n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "\n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bc7b6-8229-4c26-b4a7-7bbf02cf12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45cab89-4a7a-49b2-8446-fa5d45449e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50a552-3422-4b37-8713-d4ec13830644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73d48560-3e6e-4f76-b6fb-ea168a2988ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2898e162-809a-4934-8945-a7bebc9cf396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba720f59-28b9-4c2f-b129-677a567505fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1446c00-9370-4bf4-ad93-ae0f79e846f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b036f928-2902-4ece-92f6-abf185e4fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1891,), (334,), (1891, 5), (334, 5))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('c:\\\\python312\\\\lib\\\\site-packages')\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    " \n",
    "\n",
    "df=pd.read_csv(\"data/bbc-text.csv\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "with open('data/InputProcessed.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "y = np.array(pd.get_dummies(df[\"category\"], dtype=int))\n",
    "tts=0.85\n",
    "X_train,X_test=X[0:round(tts*len(X))],X[round(tts*len(X)):]\n",
    "y_train,y_test=y[0:round(tts*len(X))],y[round(tts*len(X)):]\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31b2fbaa-eae7-4ef1-b209-cb2d3243470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668,), (557,), (1668, 5), (557, 5))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28528f67-f07e-45d8-97ef-747667fbe72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/125:   0%|                                                                              | 0/26 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 64 is different from 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m X_train_padded \u001b[38;5;241m=\u001b[39m pad_sequences(X_train, max_seq_length)\n\u001b[0;32m    176\u001b[0m model \u001b[38;5;241m=\u001b[39m QKVAttentionClassifier(word_len, word_per_phrase, batch_size, dk, dv, num_classes)\n\u001b[1;32m--> 177\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 141\u001b[0m, in \u001b[0;36mQKVAttentionClassifier.train\u001b[1;34m(self, X_train, y_train, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m    138\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_train[start:end]\n\u001b[0;32m    139\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[start:end]\n\u001b[1;32m--> 141\u001b[0m yi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m Loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_entropy_loss(yi, y_batch)\n\u001b[0;32m    144\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Loss\n",
      "Cell \u001b[1;32mIn[45], line 67\u001b[0m, in \u001b[0;36mQKVAttentionClassifier.forward\u001b[1;34m(self, Inputs)\u001b[0m\n\u001b[0;32m     64\u001b[0m Attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLinearLayer(Attention)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphrase_representation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Attention, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m Zout \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphrase_representation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearlayer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_bias\n\u001b[0;32m     68\u001b[0m Sigma_Zout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(Zout)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Sigma_Zout\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 64 is different from 300)"
     ]
    }
   ],
   "source": [
    "class QKVAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, batch_size, dk, dv, num_classes):\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "\n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.num_heads = 8  # Number of attention heads\n",
    "\n",
    "        self.Q = [np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len) for _ in range(self.num_heads)]\n",
    "        self.K = [np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len) for _ in range(self.num_heads)]\n",
    "        self.V = [np.random.randn(self.word_len, self.dv) / np.sqrt(self.word_len) for _ in range(self.num_heads)]\n",
    "\n",
    "        # Linear layer to project concatenated heads output\n",
    "        self.W_o = np.random.randn(self.num_heads * self.dv, self.word_len) / np.sqrt(self.num_heads * self.dv)\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dk, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        return np.mean(batch_loss)\n",
    "\n",
    "\n",
    "    def AttentionHead(self, Inputs):\n",
    "        head_outputs = []\n",
    "        for i in range(self.num_heads):\n",
    "            Qval = np.dot(Inputs, self.Q[i])\n",
    "            Kval = np.dot(Inputs, self.K[i])\n",
    "            Vval = np.dot(Inputs, self.V[i])\n",
    "    \n",
    "            QKscaled = np.matmul(Qval, np.transpose(Kval, (0, 2, 1))) / np.sqrt(self.dk)\n",
    "            Attention_weights = self.softmax(QKscaled)\n",
    "            head_output = np.matmul(Attention_weights, Vval)\n",
    "            head_outputs.append(head_output)\n",
    "    \n",
    "        # Concatenate along the last axis\n",
    "        multihead_output = np.concatenate(head_outputs, axis=-1)\n",
    "        return multihead_output\n",
    "    \n",
    "    \n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def LinearLayer(self, multihead_output):\n",
    "        output = np.dot(multihead_output, self.W_o)  # Project back to original size\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def forward(self, Inputs):\n",
    "        Attention = self.AttentionHead(Inputs)\n",
    "        Attention = self.LinearLayer(Attention)\n",
    "        self.phrase_representation = np.mean(Attention, axis=1)\n",
    "    \n",
    "        Zout = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "    \n",
    "        return Sigma_Zout\n",
    "    \n",
    "    \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "    \n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "    \n",
    "        # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "    \n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array(\n",
    "            [np.outer(np.ones(self.words_per_phrase), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])\n",
    "    \n",
    "        # Gradient for V\n",
    "        d_Vval = np.matmul(np.transpose(dL_dA, (0, 2, 1)), self.Attention_weights)\n",
    "        dLoss_dV = np.mean(np.matmul(d_Vval, inputs), axis=0).T\n",
    "    \n",
    "        # Gradient of softmax\n",
    "        dAttention_dSoftmax = np.matmul(self.Attention_weights, (1 - self.Attention_weights))\n",
    "    \n",
    "        # Gradient of Q\n",
    "        dQKscaled_dQ = np.matmul(np.transpose(inputs, (0, 2, 1)), self.Kval) / np.sqrt(self.dk)\n",
    "        dLoss_dQ = np.mean(np.transpose(\n",
    "            np.transpose(np.transpose(dL_dA, (0, 2, 1)) @ dAttention_dSoftmax, (0, 2, 1)) @ np.transpose(dQKscaled_dQ,\n",
    "                                                                                                         (0, 2, 1)),\n",
    "            (0, 2, 1)) @ self.Vval, axis=0)\n",
    "    \n",
    "        # Gradient of K\n",
    "        dQKscaled_dK = np.transpose(self.Qval, (0, 2, 1)) @ inputs / np.sqrt(self.dk)\n",
    "        dLoss_dK = np.mean(\n",
    "            np.transpose(np.transpose(np.transpose(dL_dA, (0, 2, 1)) @ dAttention_dSoftmax, (0, 2, 1)) @ dQKscaled_dK,\n",
    "                         (0, 2, 1)) @ self.Vval, axis=0)\n",
    "    \n",
    "        # Gradient clipping\n",
    "        clip_value = 15.0\n",
    "        dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = np.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "    \n",
    "        self.UpdateParams(dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias)\n",
    "    \n",
    "    \n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.Q -= self.learning_rate * dLoss_dQ\n",
    "        self.K -= self.learning_rate * dLoss_dK\n",
    "        self.V -= self.learning_rate * dLoss_dV\n",
    "        self.linearlayer -= self.learning_rate * dlinear_dW\n",
    "        self.linear_bias -= self.learning_rate * d_bias\n",
    "    \n",
    "    \n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "    \n",
    "            total_loss = 0\n",
    "    \n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "    \n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "    \n",
    "                yi = self.forward(X_batch)\n",
    "    \n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "    \n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "    \n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "    \n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}\")\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    \n",
    "def pad_sequences(sequences, max_len):\n",
    "    padded_sequences = np.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = min(seq.shape[0], max_len)\n",
    "        padded_sequences[i, :length] = seq[:length]\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "word_len = 300\n",
    "word_per_phrase = 70\n",
    "dk = 64\n",
    "dv = 200\n",
    "batch_size = 64\n",
    "num_classes = 5\n",
    "max_seq_length = 70\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "X_train_padded = pad_sequences(X_train, max_seq_length)\n",
    "\n",
    "model = QKVAttentionClassifier(word_len, word_per_phrase, batch_size, dk, dv, num_classes)\n",
    "model.train(X_train_padded, y_train, num_epochs=125, learning_rate=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97374499-092c-43ea-9e6a-9c3421c02137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8983f54-01c5-4290-b658-6dfd4621957c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68c3a014-7c52-47d6-b0f0-4aab54cf6c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125, Loss: 10.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/125, Loss: 11.1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/125, Loss: 9.6620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/125, Loss: 4.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/125, Loss: 1.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/125, Loss: 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/125, Loss: 0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/125, Loss: 0.4868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/125: 100%|█████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/125, Loss: 0.3955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/125, Loss: 0.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/125, Loss: 0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/125, Loss: 0.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/125, Loss: 0.2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/125, Loss: 0.2825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/125, Loss: 0.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/125, Loss: 0.2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/125, Loss: 0.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/125, Loss: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/125, Loss: 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/125, Loss: 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/125, Loss: 0.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/125, Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/125, Loss: 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/125, Loss: 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/125, Loss: 0.1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/125, Loss: 0.0940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/125, Loss: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/125, Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/125, Loss: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/125, Loss: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/125, Loss: 0.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/125, Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/125, Loss: 0.0634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/125, Loss: 0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/125, Loss: 0.0586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/125, Loss: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/125, Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/125, Loss: 0.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/125, Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/125, Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/125, Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/125, Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/125, Loss: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/125, Loss: 0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/125, Loss: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/125, Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/125, Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/125, Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/125, Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/125, Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/125, Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/125, Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/125, Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/125, Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/125, Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/125, Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/125, Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/125, Loss: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/125, Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/125, Loss: 0.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125, Loss: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/125, Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/125, Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/125, Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/125, Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/125, Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/125, Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/125, Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/125, Loss: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/125, Loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/125, Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/125, Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/125, Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/125, Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/125, Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/125, Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/125, Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/125, Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/125, Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/125, Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/125, Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/125, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/125, Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/125, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/125, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/125, Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/125, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/125, Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/125, Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/125, Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/125, Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/125, Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/125, Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/125, Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/125, Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/125, Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/125, Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/125, Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/125: 100%|████████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/125, Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/125, Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/125, Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/125, Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/125, Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/125, Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/125, Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/125, Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/125, Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/125, Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/125, Loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/125, Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/125, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/125, Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/125, Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/125, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/125, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/125, Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/125, Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/125, Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/125, Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/125, Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/125, Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/125, Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/125, Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/125, Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/125: 100%|███████████████████████████████████████████████████████████████████| 26/26 [00:06<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/125, Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class QKVAttentionClassifier:\n",
    "    def __init__(self, word_len, words_per_phrase, batch_size, dk, dv, num_classes):\n",
    "\n",
    "        self.word_len = word_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.num_classes = num_classes\n",
    "        self.words_per_phrase = words_per_phrase\n",
    "        \n",
    "        # Initialize weights with Xavier/Glorot initialization\n",
    "        self.Q = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.K = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "        self.V = np.random.randn(self.word_len, self.dk) / np.sqrt(self.word_len)  # * 0.01\n",
    "\n",
    "        # Initialize linear layer weights\n",
    "        self.linearlayer = np.random.randn(self.dk, self.num_classes) / np.sqrt(self.dk)\n",
    "        self.linear_bias = np.zeros(self.num_classes)\n",
    "\n",
    "    def softmax(self, x, axis=-1):\n",
    "        x = np.clip(x, -1e4, 1e4)  # Clip for numerical stability\n",
    "        e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, predictions, target):\n",
    "        # Cross-entropy loss for a batch of predictions and targets\n",
    "        batch_loss = -np.sum(target * np.log(predictions + 1e-9), axis=1)\n",
    "        return np.mean(batch_loss)\n",
    "\n",
    "    def AttentionHead(self, Inputs):\n",
    "        self.Qval = np.dot(Inputs, self.Q)\n",
    "        self.Kval = np.dot(Inputs, self.K)\n",
    "        self.Vval = np.dot(Inputs, self.V)\n",
    "\n",
    "        QKscaled = np.matmul(self.Qval, np.transpose(self.Kval, (0, 2, 1))) / np.sqrt(self.K.shape[1])\n",
    "        # QKscaled = np.clip(QKscaled, -1e2, 1e2)\n",
    "        self.Attention_weights = self.softmax(QKscaled)\n",
    "\n",
    "        return np.matmul(self.Attention_weights, self.Vval)\n",
    "\n",
    "    def LinearLayer(self):\n",
    "        output = np.matmul(self.phrase_representation, self.linearlayer) + self.linear_bias\n",
    "        return output\n",
    "\n",
    "    def forward(self, Inputs):\n",
    "\n",
    "        Attention = self.AttentionHead(Inputs)\n",
    "\n",
    "        self.phrase_representation = np.mean(Attention, axis=1)\n",
    "\n",
    "        Zout = self.LinearLayer()\n",
    "\n",
    "        Sigma_Zout = self.softmax(Zout)\n",
    "\n",
    "        return Sigma_Zout\n",
    "        \n",
    "    def BackPropagation(self, dLoss_dSigma_Zout, inputs):\n",
    "        \n",
    "        # Gradient for linear layer\n",
    "        dlinear_dW = np.dot(self.phrase_representation.T, dLoss_dSigma_Zout)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_bias = np.sum(dLoss_dSigma_Zout, axis=0)\n",
    "        \n",
    "         # Gradient for phrase representation\n",
    "        d_phrase_rep = np.dot(dLoss_dSigma_Zout, self.linearlayer.T)\n",
    "\n",
    "        # Gradient for attention\n",
    "        dL_dA = np.array([np.outer(np.ones(self.words_per_phrase), d_phrase_rep[i, :]) for i in range(d_phrase_rep.shape[0])])\n",
    "\n",
    "        # Gradient for V\n",
    "        d_Vval=np.matmul(np.transpose(dL_dA,(0,2,1)), self.Attention_weights) \n",
    "        dLoss_dV = np.mean(np.matmul(d_Vval,inputs),axis=0).T\n",
    "        \n",
    "        #Gradient of softmax\n",
    "        dAttention_dSoftmax=np.matmul(self.Attention_weights,(1-self.Attention_weights))\n",
    "        \n",
    "        #Gradient of Q\n",
    "        dQKscaled_dQ=np.matmul(np.transpose(inputs,(0,2,1)),self.Kval)/np.sqrt(self.dk)\n",
    "        dLoss_dQ=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@np.transpose( dQKscaled_dQ,(0,2,1)),(0,2,1))@self.Vval,axis=0)\n",
    "        \n",
    "        #Gradient of K\n",
    "        dQKscaled_dK=np.transpose(self.Qval,(0,2,1))@inputs/np.sqrt(self.dk) \n",
    "        dLoss_dK=np.mean(np.transpose(np.transpose(np.transpose(dL_dA,(0,2,1))@dAttention_dSoftmax,(0,2,1))@dQKscaled_dK,(0,2,1))@self.Vval,axis=0)\n",
    "        \n",
    "        #Gradient clipping\n",
    "        clip_value = 15.0\n",
    "        dLoss_dQ = np.clip(dLoss_dQ, -clip_value, clip_value)\n",
    "        dLoss_dK = np.clip(dLoss_dK, -clip_value, clip_value)\n",
    "        dLoss_dV = np.clip(dLoss_dV, -clip_value, clip_value)\n",
    "        dlinear_dW = np.clip(dlinear_dW, -clip_value, clip_value)\n",
    "        d_bias = np.clip(d_bias, -clip_value, clip_value)\n",
    "\n",
    "        self.UpdateParams(dLoss_dQ,dLoss_dK,dLoss_dV,dlinear_dW,d_bias)\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    def UpdateParams(self, dLoss_dQ, dLoss_dK, dLoss_dV, dlinear_dW, d_bias):\n",
    "        self.Q -= self.learning_rate * dLoss_dQ\n",
    "        self.K -= self.learning_rate * dLoss_dK\n",
    "        self.V -= self.learning_rate * dLoss_dV\n",
    "        self.linearlayer -= self.learning_rate * dlinear_dW\n",
    "        self.linear_bias -= self.learning_rate * d_bias\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs, learning_rate=0.01):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            num_batches_per_epoch = len(X_train) // self.batch_size\n",
    "\n",
    "            for i in tqdm(range(num_batches_per_epoch), desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "                start = i * self.batch_size\n",
    "                end = start + self.batch_size\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                yi = self.forward(X_batch)\n",
    "\n",
    "                Loss = self.cross_entropy_loss(yi, y_batch)\n",
    "                total_loss += Loss\n",
    "\n",
    "                dLoss_dSigma_Zout = yi - y_batch\n",
    "\n",
    "                self.BackPropagation(dLoss_dSigma_Zout, X_batch)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {(total_loss / num_batches_per_epoch):.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    " \n",
    "\n",
    "\n",
    "def pad_sequences(sequences, max_len):\n",
    "    padded_sequences = np.zeros((len(sequences), max_len, sequences[0].shape[1]))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = min(seq.shape[0], max_len)\n",
    "        padded_sequences[i, :length] = seq[:length]\n",
    "    return padded_sequences\n",
    "\n",
    "word_len = 300\n",
    "word_per_phrase=70\n",
    "dk = 64\n",
    "dv = 200\n",
    "batch_size = 64\n",
    "num_classes = 5\n",
    "max_seq_length = 70\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "X_train_padded = pad_sequences(X_train, max_seq_length)\n",
    " \n",
    "\n",
    "model = QKVAttentionClassifier(word_len, word_per_phrase, batch_size, dk, dv, num_classes)\n",
    "model.train(X_train_padded, y_train, num_epochs=125, learning_rate=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389c7910-755c-4c1e-8add-6bd7ddde5f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c494b7e-bc42-4def-8cec-a5a87318e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01641a4a-e67b-49a4-ac2e-a022304ec8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test= pad_sequences(X_test, max_seq_length)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "y_true = np.argmax(y_test, axis=1) \n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=np.arange(5))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(5), yticklabels=np.arange(5))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5108cc7-e1cc-4928-a3a8-6cb5d74502de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89824561, 0.94565217, 0.89130435, 0.96      , 0.9478673 ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "388d96c7-4198-444a-a879-38dfd1527902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91320755, 0.95384615, 0.90640394, 0.97991968, 0.95049505])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_true,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e7ceaa2-e90f-4522-a6eb-5c3fabb752cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test= pad_sequences(X_test, max_seq_length)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "y_true = np.argmax(y_test, axis=1) \n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=np.arange(5))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(5), yticklabels=np.arange(5))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1638f-fa3c-48aa-8314-e5f934c8c0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a3e38-6051-49da-afda-adc678a81f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2c4570-5df9-4b65-bc33-3b71cef36eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "#df=pd.read_csv(\"data/bbc-text.csv\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    " \n",
    "# def preprocess_text(text, max_words=70):\n",
    "#     # Process the text using SpaCy\n",
    "#     doc = nlp(text)\n",
    "    \n",
    "#     # Filter out stopwords, punctuation, and spaces\n",
    "#     tokens = [token.text for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    \n",
    "#     # Limit to the top 'max_words' words and pad if necessary\n",
    "#     if len(tokens) > max_words:\n",
    "#         tokens = tokens[:max_words]  # Keep the first max_words words\n",
    "#     else:\n",
    "#         tokens += ['<PAD>'] * (max_words - len(tokens))  # Pad the list with '<PAD>' token\n",
    "    \n",
    "#     # Join the tokens back into a string or return a list\n",
    "#     return tokens\n",
    "# df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "# df['processed_text']\n",
    "\n",
    "\n",
    "# inputs = [] \n",
    "# # Process each phrase in the 'category' column\n",
    "# for phrase in list(df['processed_text']):\n",
    "#     doc = nlp(\" \".join(phrase))  # Process the phrase with SpaCy\n",
    "#     # Extract word vectors\n",
    "#     matrix = np.array([token.vector for token in doc])\n",
    "#     inputs.append(matrix)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9407be-9310-49e9-b752-cf53e432c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(data_dir):\n",
    "    # Get the train data\n",
    "    train_data = pd.read_json(f\"{data_dir}/train.json\")\n",
    "    train_data.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "    # Get the test data\n",
    "    test_data = pd.read_json(f\"{data_dir}/test.json\")\n",
    "    test_data.drop(['id'], axis=1, inplace=True)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "data_dir = \"corpus\"\n",
    "\n",
    "df_train, df_test = get_train_test_data(data_dir)\n",
    "\n",
    "# Take one example from the dataset and print it\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701a663c-3638-4c2a-b20f-5b046d809291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>Romeo is trying to get Greta to add him to her...</td>\n",
       "      <td>Romeo: You are on my ‘People you may know’ lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14728</th>\n",
       "      <td>Theresa is at work. She gets free food and fre...</td>\n",
       "      <td>Theresa: &lt;file_photo&gt;\\r\\nTheresa: &lt;file_photo&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14729</th>\n",
       "      <td>Japan is going to hunt whales again. Island an...</td>\n",
       "      <td>John: Every day some bad news. Japan will hunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14730</th>\n",
       "      <td>Celia couldn't make it to the afternoon with t...</td>\n",
       "      <td>Jennifer: Dear Celia! How are you doing?\\r\\nJe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>Georgia and Juliette are looking for a hotel i...</td>\n",
       "      <td>Georgia: are you ready for hotel hunting? We n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14732 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary  \\\n",
       "0      Amanda baked cookies and will bring Jerry some...   \n",
       "1      Olivia and Olivier are voting for liberals in ...   \n",
       "2      Kim may try the pomodoro technique recommended...   \n",
       "3      Edward thinks he is in love with Bella. Rachel...   \n",
       "4      Sam is confused, because he overheard Rick com...   \n",
       "...                                                  ...   \n",
       "14727  Romeo is trying to get Greta to add him to her...   \n",
       "14728  Theresa is at work. She gets free food and fre...   \n",
       "14729  Japan is going to hunt whales again. Island an...   \n",
       "14730  Celia couldn't make it to the afternoon with t...   \n",
       "14731  Georgia and Juliette are looking for a hotel i...   \n",
       "\n",
       "                                                dialogue  \n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...  \n",
       "1      Olivia: Who are you voting for in this electio...  \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...  \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....  \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...  \n",
       "...                                                  ...  \n",
       "14727  Romeo: You are on my ‘People you may know’ lis...  \n",
       "14728  Theresa: <file_photo>\\r\\nTheresa: <file_photo>...  \n",
       "14729  John: Every day some bad news. Japan will hunt...  \n",
       "14730  Jennifer: Dear Celia! How are you doing?\\r\\nJe...  \n",
       "14731  Georgia: are you ready for hotel hunting? We n...  \n",
       "\n",
       "[14732 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b2430d-9fe8-4326-ac52-4b533747ccfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Calculate word count for each dialogue\n",
    "df_train['word_count'] = df_train['dialogue'].apply(lambda x: len(x.split()))\n",
    "df_test['word_count'] = df_test['dialogue'].apply(lambda x: len(x.split()))\n",
    "\n",
    "maxlen=200\n",
    "# Filter out rows where word count is less than 300\n",
    "df_train = df_train[df_train['word_count'] <  maxlen]\n",
    "df_test = df_test[df_test['word_count'] <  maxlen]\n",
    "# Plot histogram using Seaborn or Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_train['word_count'], bins=20, kde=False)\n",
    "plt.title('Histogram of Dialogue Lengths (Word Count)')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945ba48d-a220-4a51-a829-96b673e2058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14725</th>\n",
       "      <td>Czar's profile on Kakaotalk shows a text in a ...</td>\n",
       "      <td>Dakarai: What does that mean on your profile s...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14726</th>\n",
       "      <td>Barbara and Jess won't meet tonight, because B...</td>\n",
       "      <td>Jess: Hi, sorry but I can't come tonight :-(\\r...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>Romeo is trying to get Greta to add him to her...</td>\n",
       "      <td>Romeo: You are on my ‘People you may know’ lis...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14728</th>\n",
       "      <td>Theresa is at work. She gets free food and fre...</td>\n",
       "      <td>Theresa: &lt;file_photo&gt;\\r\\nTheresa: &lt;file_photo&gt;...</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14729</th>\n",
       "      <td>Japan is going to hunt whales again. Island an...</td>\n",
       "      <td>John: Every day some bad news. Japan will hunt...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13459 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary  \\\n",
       "0      Amanda baked cookies and will bring Jerry some...   \n",
       "1      Olivia and Olivier are voting for liberals in ...   \n",
       "2      Kim may try the pomodoro technique recommended...   \n",
       "3      Edward thinks he is in love with Bella. Rachel...   \n",
       "4      Sam is confused, because he overheard Rick com...   \n",
       "...                                                  ...   \n",
       "14725  Czar's profile on Kakaotalk shows a text in a ...   \n",
       "14726  Barbara and Jess won't meet tonight, because B...   \n",
       "14727  Romeo is trying to get Greta to add him to her...   \n",
       "14728  Theresa is at work. She gets free food and fre...   \n",
       "14729  Japan is going to hunt whales again. Island an...   \n",
       "\n",
       "                                                dialogue  word_count  \n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...          16  \n",
       "1      Olivia: Who are you voting for in this electio...          18  \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...          98  \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....          26  \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...         179  \n",
       "...                                                  ...         ...  \n",
       "14725  Dakarai: What does that mean on your profile s...          59  \n",
       "14726  Jess: Hi, sorry but I can't come tonight :-(\\r...         141  \n",
       "14727  Romeo: You are on my ‘People you may know’ lis...          56  \n",
       "14728  Theresa: <file_photo>\\r\\nTheresa: <file_photo>...         198  \n",
       "14729  John: Every day some bad news. Japan will hunt...         142  \n",
       "\n",
       "[13459 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a8c8e7-6896-4bc6-8779-a6951dd58ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dials\\AppData\\Local\\Temp\\ipykernel_52444\\1088077169.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['processed_text'] = df_train['dialogue'].apply(preprocess_text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [Amanda, I, baked, cookies, Do, you, want, som...\n",
       "1        [Olivia, Who, are, you, voting, for, in, this,...\n",
       "2        [Tim, Hi, what, 's, up, Kim, Bad, mood, tbh, I...\n",
       "3        [Edward, Rachel, I, think, I, 'm, in, ove, wit...\n",
       "4        [Sam, hey, overheard, rick, say, something, Sa...\n",
       "                               ...                        \n",
       "14725    [Dakarai, What, does, that, mean, on, your, pr...\n",
       "14726    [Jess, Hi, sorry, but, I, ca, n't, come, tonig...\n",
       "14727    [Romeo, You, are, on, my, People, you, may, kn...\n",
       "14728    [Theresa, <, file_photo, >, Theresa, <, file_p...\n",
       "14729    [John, Every, day, some, bad, news, Japan, wil...\n",
       "Name: processed_text, Length: 13459, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text, max_words=300):\n",
    "    # Process the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Filter out stopwords, punctuation, and spaces\n",
    "    tokens = [token.text for token in doc if  not token.is_punct and not token.is_space]\n",
    "    \n",
    "    # Limit to the top 'max_words' words and pad if necessary\n",
    "    if len(tokens) > max_words:\n",
    "        tokens = tokens[:max_words]  # Keep the first max_words words\n",
    "    else:\n",
    "        tokens += ['<PAD>'] * (max_words - len(tokens))  # Pad the list with '<PAD>' token\n",
    "    \n",
    "    # Join the tokens back into a string or return a list\n",
    "    return tokens\n",
    "df_train['processed_text'] = df_train['dialogue'].apply(preprocess_text)\n",
    "df_train['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07b395-53d7-4664-b661-15926630f012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f2ac808-2ecb-4fc0-9de6-e330fcd91a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dials\\AppData\\Local\\Temp\\ipykernel_52444\\1088077169.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['processed_text'] = df_train['dialogue'].apply(preprocess_text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [Amanda, I, baked, cookies, Do, you, want, som...\n",
       "1        [Olivia, Who, are, you, voting, for, in, this,...\n",
       "2        [Tim, Hi, what, 's, up, Kim, Bad, mood, tbh, I...\n",
       "3        [Edward, Rachel, I, think, I, 'm, in, ove, wit...\n",
       "4        [Sam, hey, overheard, rick, say, something, Sa...\n",
       "                               ...                        \n",
       "14725    [Dakarai, What, does, that, mean, on, your, pr...\n",
       "14726    [Jess, Hi, sorry, but, I, ca, n't, come, tonig...\n",
       "14727    [Romeo, You, are, on, my, People, you, may, kn...\n",
       "14728    [Theresa, <, file_photo, >, Theresa, <, file_p...\n",
       "14729    [John, Every, day, some, bad, news, Japan, wil...\n",
       "Name: processed_text, Length: 13459, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text, max_words=300):\n",
    "    # Process the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Filter out stopwords, punctuation, and spaces\n",
    "    tokens = [token.text for token in doc if  not token.is_punct and not token.is_space]\n",
    "    \n",
    "    # Limit to the top 'max_words' words and pad if necessary\n",
    "    if len(tokens) > max_words:\n",
    "        tokens = tokens[:max_words]  # Keep the first max_words words\n",
    "    else:\n",
    "        tokens += ['<PAD>'] * (max_words - len(tokens))  # Pad the list with '<PAD>' token\n",
    "    \n",
    "    # Join the tokens back into a string or return a list\n",
    "    return tokens\n",
    "df_train['processed_text'] = df_train['dialogue'].apply(preprocess_text)\n",
    "df_train['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7e7641-6eb1-4f9c-9c77-6c4772d814a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31546"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  [x for sublist in [word for word in df_train[\"processed_text\"]] for x in sublist]\n",
    "\n",
    "# Get the unique words by converting to a set, then back to a listdialogue\n",
    "unique_words = list(set(all_words))\n",
    "\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1c048-929f-4d6c-9e9c-28e6b1b0aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fc12c53c-699a-4444-b3f0-2fa03813f9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amanda:',\n",
       " 'I',\n",
       " 'baked',\n",
       " '',\n",
       " 'cookies.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'some?\\r\\nJerry:',\n",
       " 'Sure!\\r\\nAmanda:',\n",
       " \"I'll\",\n",
       " 'bring',\n",
       " 'you',\n",
       " 'tomorrow',\n",
       " ':-)',\n",
       " 'Olivia:',\n",
       " 'Who',\n",
       " 'are',\n",
       " 'you',\n",
       " 'voting',\n",
       " 'for',\n",
       " 'in',\n",
       " 'this',\n",
       " 'election?',\n",
       " '\\r\\nOliver:',\n",
       " 'Liberals',\n",
       " 'as',\n",
       " 'always.\\r\\nOlivia:',\n",
       " 'Me',\n",
       " 'too!!\\r\\nOliver:',\n",
       " 'Great',\n",
       " 'Tim:',\n",
       " 'Hi,',\n",
       " \"what's\",\n",
       " 'up?\\r\\nKim:',\n",
       " 'Bad',\n",
       " 'mood',\n",
       " 'tbh,',\n",
       " 'I',\n",
       " 'was',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'stuff',\n",
       " 'but',\n",
       " 'ended',\n",
       " 'up',\n",
       " 'procrastinating\\r\\nTim:',\n",
       " 'What',\n",
       " 'did',\n",
       " 'you',\n",
       " 'plan',\n",
       " 'on',\n",
       " 'doing?\\r\\nKim:',\n",
       " 'Oh',\n",
       " 'you',\n",
       " 'know,',\n",
       " 'uni',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'unfucking',\n",
       " 'my',\n",
       " 'room\\r\\nKim:',\n",
       " 'Maybe',\n",
       " 'tomorrow',\n",
       " \"I'll\",\n",
       " 'move',\n",
       " 'my',\n",
       " 'ass',\n",
       " 'and',\n",
       " 'do',\n",
       " 'everything\\r\\nKim:',\n",
       " 'We',\n",
       " 'were',\n",
       " 'going',\n",
       " 'to',\n",
       " 'defrost',\n",
       " 'a',\n",
       " 'fridge',\n",
       " 'so',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'shopping',\n",
       " \"I'll\",\n",
       " 'eat',\n",
       " 'some',\n",
       " 'defrosted',\n",
       " 'veggies\\r\\nTim:',\n",
       " 'For',\n",
       " 'doing',\n",
       " 'stuff',\n",
       " 'I',\n",
       " 'recommend',\n",
       " 'Pomodoro',\n",
       " 'technique',\n",
       " 'where',\n",
       " 'u',\n",
       " 'use',\n",
       " 'breaks',\n",
       " 'for',\n",
       " 'doing',\n",
       " 'chores\\r\\nTim:',\n",
       " 'It',\n",
       " 'really',\n",
       " 'helps\\r\\nKim:',\n",
       " 'thanks,',\n",
       " 'maybe',\n",
       " \"I'll\",\n",
       " 'do',\n",
       " 'that\\r\\nTim:',\n",
       " 'I',\n",
       " 'also',\n",
       " 'like',\n",
       " 'using',\n",
       " 'post-its',\n",
       " 'in',\n",
       " 'kaban',\n",
       " 'style',\n",
       " 'Edward:',\n",
       " 'Rachel,',\n",
       " 'I',\n",
       " 'think',\n",
       " \"I'm\",\n",
       " 'in',\n",
       " 'ove',\n",
       " 'with',\n",
       " 'Bella..\\r\\nrachel:',\n",
       " 'Dont',\n",
       " 'say',\n",
       " 'anything',\n",
       " 'else..\\r\\nEdward:',\n",
       " 'What',\n",
       " 'do',\n",
       " 'you',\n",
       " 'mean??\\r\\nrachel:',\n",
       " 'Open',\n",
       " 'your',\n",
       " 'fu**ing',\n",
       " 'door..',\n",
       " \"I'm\",\n",
       " 'outside',\n",
       " 'Sam:',\n",
       " 'hey',\n",
       " '',\n",
       " 'overheard',\n",
       " 'rick',\n",
       " 'say',\n",
       " 'something\\r\\nSam:',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'what',\n",
       " 'to',\n",
       " 'do',\n",
       " ':-/\\r\\nNaomi:',\n",
       " 'what',\n",
       " 'did',\n",
       " 'he',\n",
       " 'say??\\r\\nSam:',\n",
       " 'he',\n",
       " 'was',\n",
       " 'talking',\n",
       " 'on',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'with',\n",
       " 'someone\\r\\nSam:',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'who\\r\\nSam:',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'telling',\n",
       " 'them',\n",
       " 'that',\n",
       " 'he',\n",
       " \"wasn't\",\n",
       " 'very',\n",
       " 'happy',\n",
       " 'here\\r\\nNaomi:',\n",
       " 'damn!!!\\r\\nSam:',\n",
       " 'he',\n",
       " 'was',\n",
       " 'saying',\n",
       " 'he',\n",
       " \"doesn't\",\n",
       " 'like',\n",
       " 'being',\n",
       " 'my',\n",
       " 'roommate\\r\\nNaomi:',\n",
       " 'wow,',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'feel',\n",
       " 'about',\n",
       " 'it?\\r\\nSam:',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'i',\n",
       " 'was',\n",
       " 'a',\n",
       " 'good',\n",
       " 'rommate\\r\\nSam:',\n",
       " 'and',\n",
       " 'that',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'place\\r\\nNaomi:',\n",
       " \"that's\",\n",
       " 'true',\n",
       " 'man!!!\\r\\nNaomi:',\n",
       " 'i',\n",
       " 'used',\n",
       " 'to',\n",
       " 'love',\n",
       " 'living',\n",
       " 'with',\n",
       " 'you',\n",
       " 'before',\n",
       " 'i',\n",
       " 'moved',\n",
       " 'in',\n",
       " 'with',\n",
       " 'me',\n",
       " 'boyfriend\\r\\nNaomi:',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'why',\n",
       " \"he's\",\n",
       " 'saying',\n",
       " 'that\\r\\nSam:',\n",
       " 'what',\n",
       " 'should',\n",
       " 'i',\n",
       " 'do???\\r\\nNaomi:',\n",
       " 'honestly',\n",
       " 'if',\n",
       " \"it's\",\n",
       " 'bothering',\n",
       " 'you',\n",
       " 'that',\n",
       " 'much',\n",
       " 'you',\n",
       " 'should',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'him\\r\\nNaomi:',\n",
       " 'see',\n",
       " \"what's\",\n",
       " 'going',\n",
       " 'on\\r\\nSam:',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'get',\n",
       " 'in',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'confrontation',\n",
       " 'though\\r\\nSam:',\n",
       " 'maybe',\n",
       " \"i'll\",\n",
       " 'just',\n",
       " 'let',\n",
       " 'it',\n",
       " 'go\\r\\nSam:',\n",
       " 'and',\n",
       " 'see',\n",
       " 'how',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future\\r\\nNaomi:',\n",
       " \"it's\",\n",
       " 'your',\n",
       " 'choice',\n",
       " 'sam\\r\\nNaomi:',\n",
       " 'if',\n",
       " 'i',\n",
       " 'were',\n",
       " 'you',\n",
       " 'i',\n",
       " 'would',\n",
       " 'just',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'him',\n",
       " 'and',\n",
       " 'clear',\n",
       " 'the',\n",
       " 'air',\n",
       " 'Neville:',\n",
       " 'Hi',\n",
       " 'there,',\n",
       " 'does',\n",
       " 'anyone',\n",
       " 'remember',\n",
       " 'what',\n",
       " 'date',\n",
       " 'I',\n",
       " 'got',\n",
       " 'married',\n",
       " 'on?\\r\\nDon:',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'serious?\\r\\nNeville:',\n",
       " 'Dead',\n",
       " 'serious.',\n",
       " \"We're\",\n",
       " 'on',\n",
       " 'vacation,',\n",
       " 'and',\n",
       " \"Tina's\",\n",
       " 'mad',\n",
       " 'at',\n",
       " 'me',\n",
       " 'about',\n",
       " 'something.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'strange',\n",
       " 'suspicion',\n",
       " 'that',\n",
       " 'this',\n",
       " 'might',\n",
       " 'have',\n",
       " 'something',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'our',\n",
       " 'wedding',\n",
       " 'anniversary,',\n",
       " 'but',\n",
       " 'I',\n",
       " 'have',\n",
       " 'nowhere',\n",
       " 'to',\n",
       " 'check.\\r\\nWyatt:',\n",
       " 'Hang',\n",
       " 'on,',\n",
       " \"I'll\",\n",
       " 'ask',\n",
       " 'my',\n",
       " 'wife.\\r\\nDon:',\n",
       " 'Haha,',\n",
       " \"someone's\",\n",
       " 'in',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'trouble',\n",
       " ':D\\r\\nWyatt:',\n",
       " 'September',\n",
       " '17.',\n",
       " 'I',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'remember',\n",
       " 'the',\n",
       " 'year',\n",
       " ';)',\n",
       " 'Sarah:',\n",
       " 'I',\n",
       " 'found',\n",
       " 'a',\n",
       " 'song',\n",
       " 'on',\n",
       " 'youtube',\n",
       " 'and',\n",
       " 'I',\n",
       " 'think',\n",
       " \"you'll\",\n",
       " 'like',\n",
       " 'it\\r\\nJames:',\n",
       " 'What',\n",
       " 'song?\\r\\nSarah:',\n",
       " '<file_other>\\r\\nJames:',\n",
       " 'Oh.',\n",
       " 'I',\n",
       " 'know',\n",
       " 'it!',\n",
       " '\\r\\nJames:',\n",
       " 'I',\n",
       " 'heard',\n",
       " 'it',\n",
       " 'before',\n",
       " 'in',\n",
       " 'some',\n",
       " 'compilation\\r\\nSarah:',\n",
       " 'I',\n",
       " \"can't\",\n",
       " 'stop',\n",
       " 'playing',\n",
       " 'it',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over\\r\\nJames:',\n",
       " \"That's\",\n",
       " 'exactly',\n",
       " 'how',\n",
       " 'I',\n",
       " 'know',\n",
       " 'lyrics',\n",
       " 'to',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'songs',\n",
       " 'on',\n",
       " 'my',\n",
       " 'playlist',\n",
       " ':D\\r\\nSarah:',\n",
       " 'Haha.',\n",
       " 'No',\n",
       " 'lyrics',\n",
       " 'here',\n",
       " 'though.',\n",
       " 'Instrumental',\n",
       " ';D\\r\\nJames:',\n",
       " 'Instrumental',\n",
       " 'songs',\n",
       " 'are',\n",
       " 'different',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'music.',\n",
       " '\\r\\nJames:',\n",
       " 'But',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'remember',\n",
       " 'that',\n",
       " 'the',\n",
       " 'activity',\n",
       " 'you',\n",
       " 'do',\n",
       " 'when',\n",
       " 'you',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'song\\r\\nJames:',\n",
       " 'Is',\n",
       " 'the',\n",
       " 'actvity',\n",
       " 'your',\n",
       " 'brain',\n",
       " 'will',\n",
       " 'connect',\n",
       " 'to',\n",
       " 'the',\n",
       " 'song\\r\\nJames:',\n",
       " 'And',\n",
       " 'everytime',\n",
       " 'you',\n",
       " 'play',\n",
       " 'this',\n",
       " 'song',\n",
       " 'at',\n",
       " 'home\\r\\nJames:',\n",
       " \"You'll\",\n",
       " 'be',\n",
       " 'thinking',\n",
       " 'of',\n",
       " 'your',\n",
       " 'work\\r\\nSarah:',\n",
       " 'Yeah,',\n",
       " 'I',\n",
       " 'know',\n",
       " 'that.',\n",
       " \"That's\",\n",
       " 'why',\n",
       " 'we',\n",
       " 'sometimes',\n",
       " 'say',\n",
       " '-',\n",
       " 'I',\n",
       " 'used',\n",
       " 'to',\n",
       " 'like',\n",
       " 'that',\n",
       " 'song,',\n",
       " 'but',\n",
       " 'now',\n",
       " 'it',\n",
       " 'just',\n",
       " 'reminds',\n",
       " 'me',\n",
       " 'of',\n",
       " 'bad',\n",
       " 'memories\\r\\nJames:',\n",
       " 'Yup.',\n",
       " 'Everytime',\n",
       " 'you',\n",
       " 'change',\n",
       " 'your',\n",
       " 'partner,',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'get',\n",
       " 'rid',\n",
       " 'of',\n",
       " 'your',\n",
       " 'favorite',\n",
       " 'music',\n",
       " ':D\\r\\nSarah:',\n",
       " 'Hahaha.',\n",
       " 'True,',\n",
       " 'true.',\n",
       " 'Noah:',\n",
       " 'When',\n",
       " 'and',\n",
       " 'where',\n",
       " 'are',\n",
       " 'we',\n",
       " 'meeting?',\n",
       " ':)\\r\\nMadison:',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'you',\n",
       " 'were',\n",
       " 'busy...?\\r\\nNoah:',\n",
       " 'Yeah,',\n",
       " 'I',\n",
       " 'WAS.',\n",
       " 'I',\n",
       " 'quit',\n",
       " 'my',\n",
       " 'job.',\n",
       " '\\r\\nMadison:',\n",
       " 'No',\n",
       " 'way!',\n",
       " ':o',\n",
       " ':o',\n",
       " ':o',\n",
       " 'Why?',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'you',\n",
       " 'liked',\n",
       " 'it...?\\r\\nNoah:',\n",
       " 'Well,',\n",
       " 'I',\n",
       " 'used',\n",
       " 'to,',\n",
       " 'until',\n",
       " 'my',\n",
       " 'boss',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'a',\n",
       " 'complete',\n",
       " 'cock...',\n",
       " 'Long',\n",
       " 'story.',\n",
       " 'Matt:',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'for',\n",
       " 'date?\\r\\nAgnes:',\n",
       " 'Wow!',\n",
       " 'You',\n",
       " 'caught',\n",
       " 'me',\n",
       " 'out',\n",
       " 'with',\n",
       " 'this',\n",
       " 'question',\n",
       " 'Matt.\\r\\nMatt:',\n",
       " 'Why?\\r\\nAgnes:',\n",
       " 'I',\n",
       " 'simply',\n",
       " \"didn't\",\n",
       " 'expect',\n",
       " 'this',\n",
       " 'from',\n",
       " 'you.\\r\\nMatt:',\n",
       " 'Well,',\n",
       " 'expect',\n",
       " 'the',\n",
       " 'unexpected.\\r\\nAgnes:',\n",
       " 'Can',\n",
       " 'I',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it?\\r\\nMatt:',\n",
       " 'What',\n",
       " 'is',\n",
       " 'there',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about?\\r\\nAgnes:',\n",
       " 'Well,',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'really',\n",
       " 'know',\n",
       " 'you.\\r\\nMatt:',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'perfect',\n",
       " 'time',\n",
       " 'to',\n",
       " 'get',\n",
       " 'to',\n",
       " 'know',\n",
       " 'eachother\\r\\nAgnes:',\n",
       " 'Well',\n",
       " \"that's\",\n",
       " 'true.\\r\\nMatt:',\n",
       " 'So',\n",
       " \"let's\",\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Georgian',\n",
       " 'restaurant',\n",
       " 'in',\n",
       " 'Kazimierz.\\r\\nAgnes:',\n",
       " 'Now',\n",
       " 'your',\n",
       " 'convincing',\n",
       " 'me.\\r\\nMatt:',\n",
       " 'Cool,',\n",
       " 'saturday',\n",
       " 'at',\n",
       " '6pm?\\r\\nAgnes:',\n",
       " \"That's\",\n",
       " 'fine.\\r\\nMatt:',\n",
       " 'I',\n",
       " 'can',\n",
       " 'pick',\n",
       " 'you',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'the',\n",
       " 'restaurant.\\r\\nAgnes:',\n",
       " \"That's\",\n",
       " 'really',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'you.\\r\\nMatt:',\n",
       " 'No',\n",
       " 'problem.\\r\\nAgnes:',\n",
       " 'See',\n",
       " 'you',\n",
       " 'on',\n",
       " 'saturday.\\r\\nMatt:',\n",
       " 'Yes,',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'to',\n",
       " 'it.\\r\\nAgnes:',\n",
       " 'Me',\n",
       " 'too.',\n",
       " 'Lucas:',\n",
       " 'Hey!',\n",
       " 'How',\n",
       " 'was',\n",
       " 'your',\n",
       " 'day?\\r\\nDemi:',\n",
       " 'Hey',\n",
       " 'there!',\n",
       " '\\r\\nDemi:',\n",
       " 'It',\n",
       " 'was',\n",
       " 'pretty',\n",
       " 'fine,',\n",
       " 'actually,',\n",
       " 'thank',\n",
       " 'you!\\r\\nDemi:',\n",
       " 'I',\n",
       " 'just',\n",
       " 'got',\n",
       " 'promoted!',\n",
       " ':D\\r\\nLucas:',\n",
       " 'Whoa!',\n",
       " 'Great',\n",
       " 'news!\\r\\nLucas:',\n",
       " 'Congratulations!\\r\\nLucas:',\n",
       " 'Such',\n",
       " 'a',\n",
       " 'success',\n",
       " 'has',\n",
       " 'to',\n",
       " 'be',\n",
       " 'celebrated.\\r\\nDemi:',\n",
       " 'I',\n",
       " 'agree!',\n",
       " ':D\\r\\nDemi:',\n",
       " 'Tonight',\n",
       " 'at',\n",
       " 'Death',\n",
       " '&',\n",
       " 'Co.?\\r\\nLucas:',\n",
       " 'Sure!\\r\\nLucas:',\n",
       " 'See',\n",
       " 'you',\n",
       " 'there',\n",
       " 'at',\n",
       " '10pm?\\r\\nDemi:',\n",
       " 'Yeah!',\n",
       " 'See',\n",
       " 'you',\n",
       " 'there!',\n",
       " ':D',\n",
       " 'Mark:',\n",
       " 'I',\n",
       " 'just',\n",
       " 'shipped',\n",
       " 'the',\n",
       " 'goods\\r\\nMark:',\n",
       " 'Tomorrow',\n",
       " 'I’ll',\n",
       " 'send',\n",
       " 'you',\n",
       " 'the',\n",
       " 'tracking',\n",
       " 'number\\r\\nGeorge:',\n",
       " 'Thanks!',\n",
       " 'Anita:',\n",
       " \"I'm\",\n",
       " 'at',\n",
       " 'the',\n",
       " 'station',\n",
       " 'in',\n",
       " 'Bologna\\nJenny:',\n",
       " 'No',\n",
       " 'problems',\n",
       " 'so',\n",
       " 'far?\\nAnita:',\n",
       " 'no,',\n",
       " \"everything's\",\n",
       " 'going',\n",
       " 'smoothly\\nTomy:',\n",
       " 'good!',\n",
       " 'Leon:',\n",
       " 'did',\n",
       " 'you',\n",
       " 'find',\n",
       " 'the',\n",
       " 'job',\n",
       " 'yet?\\r\\nArthur:',\n",
       " 'no',\n",
       " 'bro,',\n",
       " 'still',\n",
       " 'unemployed',\n",
       " ':D\\r\\nLeon:',\n",
       " 'hahaha,',\n",
       " 'LIVING',\n",
       " 'LIFE\\r\\nArthur:',\n",
       " 'i',\n",
       " 'love',\n",
       " 'it,',\n",
       " 'waking',\n",
       " 'up',\n",
       " 'at',\n",
       " 'noon,',\n",
       " 'watching',\n",
       " 'sports',\n",
       " '-',\n",
       " 'what',\n",
       " 'else',\n",
       " 'could',\n",
       " 'a',\n",
       " 'man',\n",
       " 'want?\\r\\nLeon:',\n",
       " 'a',\n",
       " 'paycheck?',\n",
       " ';)\\r\\nArthur:',\n",
       " \"don't\",\n",
       " 'be',\n",
       " 'mean...',\n",
       " '\\r\\nLeon:',\n",
       " 'but',\n",
       " 'seriously,',\n",
       " 'my',\n",
       " 'mate',\n",
       " 'has',\n",
       " 'an',\n",
       " 'offer',\n",
       " 'as',\n",
       " 'a',\n",
       " 'junior',\n",
       " 'project',\n",
       " 'manager',\n",
       " 'at',\n",
       " 'his',\n",
       " 'company,',\n",
       " 'are',\n",
       " 'you',\n",
       " 'interested?\\r\\nArthur:',\n",
       " 'sure',\n",
       " 'thing,',\n",
       " 'do',\n",
       " 'you',\n",
       " 'have',\n",
       " 'any',\n",
       " 'details?\\r\\nLeon:',\n",
       " '<file_photo>\\r\\nArthur:',\n",
       " 'that',\n",
       " 'actually',\n",
       " 'looks',\n",
       " 'nice,',\n",
       " 'should',\n",
       " 'I',\n",
       " 'reach',\n",
       " 'out',\n",
       " 'directly',\n",
       " 'to',\n",
       " 'your',\n",
       " 'friend',\n",
       " 'or',\n",
       " 'just',\n",
       " 'apply',\n",
       " 'to',\n",
       " 'this',\n",
       " 'email',\n",
       " 'address',\n",
       " 'from',\n",
       " 'the',\n",
       " 'screenshot?\\r\\nLeon:',\n",
       " \"it's\",\n",
       " 'his',\n",
       " 'email,',\n",
       " 'you',\n",
       " 'can',\n",
       " 'send',\n",
       " 'your',\n",
       " 'resume',\n",
       " 'directly',\n",
       " 'and',\n",
       " 'I',\n",
       " 'will',\n",
       " 'mention',\n",
       " 'to',\n",
       " 'him',\n",
       " 'who',\n",
       " 'you',\n",
       " 'are',\n",
       " ':)',\n",
       " 'Macca:',\n",
       " \"i'm\",\n",
       " 'so',\n",
       " 'exited',\n",
       " 'today\\nAdrien:',\n",
       " 'why?\\nMacca:',\n",
       " \"I've\",\n",
       " 'never',\n",
       " 'done',\n",
       " 'ice',\n",
       " 'climbing',\n",
       " 'before\\nMark:',\n",
       " 'Are',\n",
       " 'you',\n",
       " 'ready?\\nMacca:',\n",
       " 'think',\n",
       " 'so\\nTobias:',\n",
       " 'where',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'this?\\nMacca:',\n",
       " 'not',\n",
       " 'far',\n",
       " 'from',\n",
       " 'Reykjavik\\nMacca:',\n",
       " 'Has',\n",
       " 'anybody',\n",
       " 'seriously',\n",
       " 'injured',\n",
       " 'themselves',\n",
       " 'doing',\n",
       " 'this?\\nMark:',\n",
       " 'not',\n",
       " 'seriously\\nAdrien:',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'know',\n",
       " \"you're\",\n",
       " 'in',\n",
       " 'Iceland!\\nMacca:',\n",
       " 'hahaha,',\n",
       " \"doesn't\",\n",
       " 'sound',\n",
       " 'so',\n",
       " 'good\\nMark:',\n",
       " 'no',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'afraid\\nMacca:',\n",
       " 'gosh,',\n",
       " 'it',\n",
       " 'was',\n",
       " 'such',\n",
       " 'a',\n",
       " 'rush\\nMark:',\n",
       " 'did',\n",
       " 'you',\n",
       " 'enjoy',\n",
       " 'it?\\nMacca:',\n",
       " 'every',\n",
       " 'second\\nMacca:',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'very',\n",
       " 'cold\\nMacca:',\n",
       " 'the',\n",
       " 'landscapes',\n",
       " 'were',\n",
       " 'magnificent\\nMark:',\n",
       " \"I'm\",\n",
       " 'glad',\n",
       " 'to',\n",
       " 'read',\n",
       " 'that\\nMacca:',\n",
       " 'Challenge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " 'done!',\n",
       " 'Isabella:',\n",
       " 'fuck',\n",
       " 'my',\n",
       " 'life,',\n",
       " \"I'm\",\n",
       " 'so',\n",
       " 'not',\n",
       " 'able',\n",
       " 'to',\n",
       " 'get',\n",
       " 'up',\n",
       " 'to',\n",
       " 'work',\n",
       " 'today\\r\\nIsabella:',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'call',\n",
       " 'in',\n",
       " 'sick',\n",
       " ':(\\r\\nOscar:',\n",
       " 'haha,',\n",
       " 'well',\n",
       " 'you',\n",
       " 'certainly',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'time',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Christmas',\n",
       " 'party',\n",
       " 'yesterday',\n",
       " 'XD\\r\\nIsabella:',\n",
       " 'shut',\n",
       " 'up,',\n",
       " \"you're\",\n",
       " 'a',\n",
       " 'traitor\\r\\nIsabella:',\n",
       " 'I',\n",
       " 'told',\n",
       " 'you',\n",
       " 'to',\n",
       " 'guard',\n",
       " 'my',\n",
       " 'glass\\r\\nIsabella:',\n",
       " 'and',\n",
       " 'my',\n",
       " 'sobriety.',\n",
       " 'You',\n",
       " 'clearly',\n",
       " 'failed!\\r\\nOscar:',\n",
       " 'but',\n",
       " 'you',\n",
       " ...]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b0bcd1c4-9732-461b-a7bd-5e00e52b38b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dialogue:  ['tim', 'hi', 'what', \"'s\", 'up', 'kim', 'bad', 'mood', 'tbh', 'i', 'was', 'going', 'to', 'do', 'lots', 'of', 'stuff', 'but', 'ended', 'up', 'procrastinating', 'tim', 'what', 'did', 'you', 'plan', 'on', 'doing', 'kim', 'oh', 'you', 'know', 'uni', 'stuff', 'and', 'unfucking', 'my', 'room', 'kim', 'maybe', 'tomorrow', 'i', \"'ll\", 'move', 'my', 'ass', 'and', 'do', 'everything', 'kim', 'we', 'were', 'going', 'to', 'defrost', 'a', 'fridge', 'so', 'instead', 'of', 'shopping', 'i', \"'ll\", 'eat', 'some', 'defrosted', 'veggies', 'tim', 'for', 'doing', 'stuff', 'i', 'recommend', 'pomodoro', 'technique', 'where', 'u', 'use', 'breaks', 'for', 'doing', 'chores', 'tim', 'it', 'really', 'helps', 'kim', 'thanks', 'maybe', 'i', \"'ll\", 'do', 'that', 'tim', 'i', 'also', 'like', 'using', 'post', 'its', 'in', 'kaban', 'style', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Binary Dialogue:  [0, 0, 'are', 0, 'voting', 'for', 'in', 'this', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Original summary:  ['kim', 'may', 'try', 'the', 'pomodoro', 'technique', 'recommended', 'by', 'tim', 'to', 'get', 'more', 'stuff', 'done.']\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "dialogue = train_data.iloc[n][\"dialogue\"]\n",
    "summary = train_data.iloc[n][\"summary\"]\n",
    "\n",
    "# Tokenize the dialogue and summary into words\n",
    "dialogue_words =[x.lower() for x in df_train[\"processed_text\"].iloc[n]] \n",
    "summary_words = [x.lower() for x in summary.split()] \n",
    "\n",
    "# Create a binary copy of dialogue where words in summary are 1, others are 0 \n",
    "# Show the binary representation\n",
    "print(\"Original Dialogue: \", dialogue_words)\n",
    "print(\"Binary Dialogue: \", binary_dialogue)\n",
    "print(\"Original summary: \", summary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "85411f4b-799c-481a-b5ee-50c0b5f20a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tim',\n",
       " 'hi',\n",
       " 'what',\n",
       " \"'s\",\n",
       " 'up',\n",
       " 'kim',\n",
       " 'bad',\n",
       " 'mood',\n",
       " 'tbh',\n",
       " 'i',\n",
       " 'was',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'stuff',\n",
       " 'but',\n",
       " 'ended',\n",
       " 'up',\n",
       " 'procrastinating',\n",
       " 'tim',\n",
       " 'what',\n",
       " 'did',\n",
       " 'you',\n",
       " 'plan',\n",
       " 'on',\n",
       " 'doing',\n",
       " 'kim',\n",
       " 'oh',\n",
       " 'you',\n",
       " 'know',\n",
       " 'uni',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'unfucking',\n",
       " 'my',\n",
       " 'room',\n",
       " 'kim',\n",
       " 'maybe',\n",
       " 'tomorrow',\n",
       " 'i',\n",
       " \"'ll\",\n",
       " 'move',\n",
       " 'my',\n",
       " 'ass',\n",
       " 'and',\n",
       " 'do',\n",
       " 'everything',\n",
       " 'kim',\n",
       " 'we',\n",
       " 'were',\n",
       " 'going',\n",
       " 'to',\n",
       " 'defrost',\n",
       " 'a',\n",
       " 'fridge',\n",
       " 'so',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'shopping',\n",
       " 'i',\n",
       " \"'ll\",\n",
       " 'eat',\n",
       " 'some',\n",
       " 'defrosted',\n",
       " 'veggies',\n",
       " 'tim',\n",
       " 'for',\n",
       " 'doing',\n",
       " 'stuff',\n",
       " 'i',\n",
       " 'recommend',\n",
       " 'pomodoro',\n",
       " 'technique',\n",
       " 'where',\n",
       " 'u',\n",
       " 'use',\n",
       " 'breaks',\n",
       " 'for',\n",
       " 'doing',\n",
       " 'chores',\n",
       " 'tim',\n",
       " 'it',\n",
       " 'really',\n",
       " 'helps',\n",
       " 'kim',\n",
       " 'thanks',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"'ll\",\n",
       " 'do',\n",
       " 'that',\n",
       " 'tim',\n",
       " 'i',\n",
       " 'also',\n",
       " 'like',\n",
       " 'using',\n",
       " 'post',\n",
       " 'its',\n",
       " 'in',\n",
       " 'kaban',\n",
       " 'style',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " ...]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a34ad962-484e-4781-85f3-ccc903d9cf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kim',\n",
       " 'may',\n",
       " 'try',\n",
       " 'the',\n",
       " 'pomodoro',\n",
       " 'technique',\n",
       " 'recommended',\n",
       " 'by',\n",
       " 'tim',\n",
       " 'to',\n",
       " 'get',\n",
       " 'more',\n",
       " 'stuff',\n",
       " 'done.']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d9cc3dd9-d72a-4b6b-a863-d7165b91efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kim', 'pomodoro', 'technique', 'tim', 'to', 'stuff']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in summary_words if x in dialogue_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a852e0ec-9278-4498-8672-22ebfc580d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e4189022-d75a-4224-be7f-91107df2d4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36898"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "789a1866-22c0-415f-9965-378451c3b4b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "list(set(df_train[\"processed_text\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "aaee3944-3628-4e77-a84b-b04a309978d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam: hey  overheard rick say something\n",
      "Sam: i don't know what to do :-/\n",
      "Naomi: what did he say??\n",
      "Sam: he was talking on the phone with someone\n",
      "Sam: i don't know who\n",
      "Sam: and he was telling them that he wasn't very happy here\n",
      "Naomi: damn!!!\n",
      "Sam: he was saying he doesn't like being my roommate\n",
      "Naomi: wow, how do you feel about it?\n",
      "Sam: i thought i was a good rommate\n",
      "Sam: and that we have a nice place\n",
      "Naomi: that's true man!!!\n",
      "Naomi: i used to love living with you before i moved in with me boyfriend\n",
      "Naomi: i don't know why he's saying that\n",
      "Sam: what should i do???\n",
      "Naomi: honestly if it's bothering you that much you should talk to him\n",
      "Naomi: see what's going on\n",
      "Sam: i don't want to get in any kind of confrontation though\n",
      "Sam: maybe i'll just let it go\n",
      "Sam: and see how it goes in the future\n",
      "Naomi: it's your choice sam\n",
      "Naomi: if i were you i would just talk to him and clear the air \n",
      "\n",
      "\n",
      "Sam is confused, because he overheard Rick complaining about him as a roommate. Naomi thinks Sam should talk to Rick. Sam is not sure what to do.\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "print(train_data.iloc[n][\"dialogue\"],\"\\n\\n\")\n",
    "print(train_data.iloc[n][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1b4a4432-2e5f-4395-a19e-75a583fb9822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76679b5-b008-416b-93a9-89d1dc76d321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
