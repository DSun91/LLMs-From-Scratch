{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9660920,"sourceType":"datasetVersion","datasetId":5902405},{"sourceId":9677788,"sourceType":"datasetVersion","datasetId":5915013}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"hello\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-22T08:01:22.982987Z","iopub.execute_input":"2024-10-22T08:01:22.983839Z","iopub.status.idle":"2024-10-22T08:01:22.996590Z","shell.execute_reply.started":"2024-10-22T08:01:22.983780Z","shell.execute_reply":"2024-10-22T08:01:22.995472Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport jax.numpy as jnp\nimport re\nimport cupy as cp\nimport pickle\nimport time\nimport numpy as np\nimport jax.numpy as jnp\nimport pandas as pd\nimport numpy as np\nimport jax\nimport spacy\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport json\n\nnp.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n\n\ndef log_time(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()  # Record start time\n        result = func(*args, **kwargs)  # Execute the wrapped function\n        end_time = time.time()  # Record end time\n        elapsed_time = end_time - start_time\n        # print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n        return result\n\n    return wrapper\n\n\ndef get_positional_encoding(seq_len, d_model):\n    \"\"\"\n    Returns a non-learnable (sinusoidal) positional encoding.\n\n\n    seq_len: Length of the input sequence.\n    d_model: Dimension of the embeddings.\n    \"\"\"\n    pos = cp.arange(seq_len)[:, cp.newaxis]  # Shape: [seq_len, 1]\n    i = cp.arange(d_model)[cp.newaxis, :]  # Shape: [1, d_model]\n\n    angle_rates = 1 / cp.power(10000, (2 * (i // 2)) / cp.float32(d_model))\n\n    # Apply sine to even indices, cosine to odd indices\n    pos_encoding = cp.zeros((seq_len, d_model))\n    pos_encoding[:, 0::2] = cp.sin(pos * angle_rates[:, 0::2])  # sine on even indices\n    pos_encoding[:, 1::2] = cp.cos(pos * angle_rates[:, 1::2])  # cosine on odd indices\n\n    return pos_encoding\n\n\ndef softmax(x, axis=-1):\n    # Subtract the max value for numerical stability\n    e_x = cp.exp(x - cp.max(x, axis=axis, keepdims=True))\n    return e_x / cp.sum(e_x, axis=axis, keepdims=True)\n\n\ndef layer_norm(x, epsilon=1e-6):\n    # Calculate the mean and variance\n    mean = cp.mean(x, axis=-1, keepdims=True)\n    var = cp.var(x, axis=-1, keepdims=True)\n\n    # Normalize the output\n    x_norm = (x - mean) / cp.sqrt(var + epsilon)\n    # print(x)\n    # print(mean)\n    # print(\"mean\",mean.shape)\n    # print(\"x_norm.shape\",x_norm.shape)\n    return x_norm, mean, var, x.shape[-1]\n\n\ndef relu(x):\n    return cp.maximum(0, x)\n\n\n# @log_time\ndef pad_sequence(seq, max_len, pad_value=0):\n    \"\"\"Pad a sequence with a given value up to max_len.\"\"\"\n    current_len = seq.shape[0]\n    pad_width = max_len - current_len\n    if pad_width > 0:\n        # Pad sequence with zeros (or any pad_value you provide)\n        seq = cp.pad(seq, ((0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n    return seq\n\n\n@log_time\ndef create_timestaped_input(input_d, words_per_phrase):\n    input_translation = []\n    for j in range(input_d.shape[0]):\n        # Create padded sequences\n        padded_sequences = [pad_sequence(input_d[j][0:i], words_per_phrase) for i in range(1, input_d.shape[1] + 1)]\n        input_translation.append(padded_sequences)\n    return cp.array(input_translation)\n\n\ndef cross_entropy_loss(predictions, target):\n    # Cross-entropy loss for a batch of predictions and targets\n    batch_loss = -cp.sum(target * cp.log(predictions + 1e-9), axis=1)\n    return cp.mean(batch_loss)\n\n\ndef diff_norm(X, var, mu, N):\n    epsilon = 1e-6\n    AA = ((1 - (1 / N)) * (1 / (cp.sqrt(var + epsilon))))\n    BB = (1 / N) * ((X - mu) ** 2)\n    CC = ((var + epsilon) ** (3 / 2))\n    result = (AA - (BB / CC))\n    return result\n\n\ndef redimension(X):\n    return cp.concatenate(cp.swapaxes(X, 0, 1), axis=-1)\n\n\ndef diffQKV(dAttention, Attention_weights, X1, X2, X3, dk, matrix=\"\"):\n    global num_heads\n    # print(\"----------------\")\n    # print(\"dAcr.shape\",dAttention.shape)\n    dAttention_weights = Attention_weights * (1 - Attention_weights)\n    # print(\"dW.shape\",dAttention_weights.shape)\n    # print(\"QC.shape\",X1.shape)\n    # print(\"VC.shape\",X2.shape)\n    # print(\"Ecout.shape\",X3.shape)\n\n    if matrix != \"k\":\n        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ (\n                    redimension(dAttention_weights @ (X1 * X2) / cp.sqrt(dk)) * X3)\n    else:\n        #  print(\"X1@cp.transpose(X2,(0,2,1))\",(dAttention_weights*(X1@cp.transpose(X2,(0,1,3,2)))).shape)\n        #  print(X3[0].shape)\n        ################################ check X3\n        X3 = cp.swapaxes(cp.array(cp.array_split(X3, num_heads, axis=2)), 0, 1)\n        #  print(X3[0].shape)\n        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ redimension(\n            (dAttention_weights * (X1 @ cp.transpose(X2, (0, 1, 3, 2))) @ X3) / cp.sqrt(dk))\n    # print(\"dLoss_dX.shape\",dLoss_dX.shape)\n\n    # V1=dAttention_weights@X1/cp.sqrt(dk)\n    # print(\"V1 shape\",V1.shape)\n    # V2=cp.transpose(X2,(0,1,3,2))\n    # print(\"V2 shape\",V2.shape)\n    # print(\"(V1@V2)\",(V1@V2).shape)\n    # V3=redimension(V1@V2)*X3\n\n    # V3=V1@cp.transpose(V2,(0,2,1))*X3\n\n    return dLoss_dX\n\n\n@log_time\ndef create_vocabulary(complete_text, name, nlp):\n    # Use re.findall to split considering punctuation\n    text = re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', complete_text)\n\n    words_list = list(set(text))\n\n    vocabulary = dict()\n\n    for i, j in enumerate(words_list):\n        # vocabulary[j]=(jax.random.uniform(jax.random.key(cp.random.randint(10000)),embedding_size),i)\n        vocabulary[j] = (cp.array(nlp(j).vector), i)\n        # print(j,len(cp.array(nlp(j).vector)))\n\n    # print(vocabulary)\n    # print(\"Vocabulary size: \", len(vocabulary))\n#     with open(f\"data/{name}.pkl\", 'wb') as handle:\n#         pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n    return vocabulary\n\n\n@log_time\ndef pad_sequences(sentences, lenght, pad_token='[PAD]', target_type=None):\n    \"\"\"\n    Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n    \"\"\"\n\n    if target_type == \"encoder\":\n        # Split each sentence into words\n        tokenized_sentences = [[\"[START]\"] + re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]\\n', sentence) + [\"[END]\"] for sentence in\n                               sentences]\n    elif target_type == \"decoder\":\n        tokenized_sentences = [[\"[START]\"] + re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', sentence) for sentence in sentences]\n    elif target_type == \"target\":\n        tokenized_sentences = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', sentence) + [\"[END]\"] for sentence in sentences]\n    # print(tokenized_sentences)\n    if lenght == 0:\n        # Find the maximum sentence length\n        max_len = max(len(sentence) for sentence in tokenized_sentences)\n    else:\n        max_len = lenght\n\n    # Pad each sentence with the [PAD] token to make them of equal length\n    padded_sentences = [\" \".join(sentence + [pad_token] * (max_len - len(sentence))) for sentence in\n                        tokenized_sentences]\n\n    return padded_sentences\n\n\n@log_time\ndef generate_input_encoder(x_batch, vocabulary_encoder, max_words_per_phrase):\n    x_train = pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n\n    xi = []\n    # print(x_batch)\n    phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n\n    phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x]\n\n    # print(phrase_vectors_x)\n    # a=cp.array(phrase_vectors_x).shape\n\n    # print(\"a\",a)\n    # print(\"len phrases:\\n\",[len(i) for i in phrase_vectors_x])\n\n    xi = cp.array([[vocabulary_encoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n\n    return xi\n\n\n# @log_time\ndef update_wembedding_encoder(x_batch, inputs_e, vocabulary, max_words_per_phrase):\n    x_train = pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n    # print(x_train)\n\n    phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n\n    phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x]\n    # print(\"inputs_e\",inputs_e.shape)\n    # print(\"(phrase_vectors_x).shape:\\n\",cp.array(phrase_vectors_x).shape)\n\n    for phrase in range(inputs_e.shape[0]):\n        # print(phrase)\n        for position, word in enumerate(phrase_vectors_x[phrase]):\n            #   print(\"word\",word)\n            #   print(\"original values\",vocabulary[word][0])\n            #   print(\"updated  values\",inputs_e[phrase][position])\n            #   print(\"index\",vocabulary[word][1])\n            vocabulary[word] = (inputs_e[phrase][position], vocabulary[word][1])\n\n    return vocabulary\n\n\n# @log_time\ndef update_wembedding_decoder(y_batch, inputs_decoder, max_words_per_phrase, vocabulary):\n    # print(\"inputs_decoder\",inputs_decoder.shape)\n    decoder_input = pad_sequences(y_batch, lenght=max_words_per_phrase, target_type=\"decoder\")\n    decoder_input = [i.split() for i in decoder_input]\n    # print(max_words_per_phrase)\n    if max_words_per_phrase == None:\n        max_words_per_phrase = len(decoder_input[0])\n\n    phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n    # for sentence in phrase_vectors_y:\n    #     print(sentence)\n    for phrase in range(inputs_decoder.shape[0]):\n        # print(phrase)\n        for position, word in enumerate(phrase_vectors_y[phrase]):\n            # print(\"word\",word)\n            # print(\"original values\",vocabulary[word][0])\n            # print(\"updated  values\",inputs_decoder[phrase][position])\n            #  print(\"delta input\",cp.sum(vocabulary[word][0]-inputs_decoder[phrase][position]))\n            # print(\"index\",vocabulary[word][1])\n            vocabulary[word] = (inputs_decoder[phrase][position], vocabulary[word][1])\n\n    return vocabulary\n\n\n@log_time\ndef create_input_encoder(X, vocabulary_encoder, max_words_per_phrase, embedding_size):\n    pos_encoding = get_positional_encoding(max_words_per_phrase, embedding_size)\n    inputs_e = generate_input_encoder(X, vocabulary_encoder, max_words_per_phrase)\n    inputs_e += pos_encoding\n    return inputs_e\n\n\n@log_time\ndef create_decoder_input(y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n    decoder_input = pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n    decoder_input = [i.split() for i in decoder_input]\n    # print(max_words_per_phrase)\n    if max_words_per_phrase == None:\n        max_words_per_phrase = len(decoder_input[0])\n\n    phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n    # for sentence in phrase_vectors_y:\n    #     print(sentence)\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n    pos_encoding = get_positional_encoding(max_words_per_phrase, embedding_size)\n    # print(pos_encoding.shape,yi.shape)\n    yi = yi + pos_encoding\n\n    decoder_inputs = cp.array(cp.swapaxes(create_timestaped_input(yi, max_words_per_phrase), 0, 1))\n\n    # decoder_inputs[zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n    for i in range(decoder_inputs.shape[0]):\n        for j in range(decoder_inputs[i].shape[0]):\n            zero_rows = cp.all(decoder_inputs[i][j] == 0, axis=1)\n\n            decoder_inputs[i][j][zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n\n    decoder_inputs = cp.array(decoder_inputs)\n    return decoder_inputs\n\n\n# @log_time\ndef get_one_hot(word, vocabulary_decoder):\n    # print(word)\n    vocab_size = len(vocabulary_decoder)\n    one_hot_vector = cp.zeros(vocab_size)\n    one_hot_vector[vocabulary_decoder[word][1]] = 1\n    return one_hot_vector\n\n\n@log_time\ndef create_target(y_train, max_words_per_phrase, vocabulary):\n    target_d = pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"target\")\n    target_d = [i.split() for i in target_d]\n    target_d = [[get_one_hot(word, vocabulary) for word in phrase] for phrase in target_d]\n    # print([len(i) for i in target_d])\n    target_d = cp.swapaxes(create_timestaped_input(cp.array(target_d), max_words_per_phrase), 0, 1)\n    targets_d = []\n\n    for i in range(target_d.shape[0]):\n        ff = []\n        # print(i,target_d[i].shape)\n        for j in range(target_d[i].shape[0]):\n            ff.append(target_d[i][j][i])\n            # print(targets_d[i][j][i])\n        targets_d.append(ff)\n        # print(ff)\n    targets_d = cp.array(targets_d)\n    return targets_d\n\n\ndef bucket_by_length(x_train, y_train, batch_size):\n    # Pair x_train and y_train together\n    paired_data = list(zip(x_train, y_train))\n\n    # Sort the pairs by the length of the x_train phrases\n    paired_data_sorted = sorted(paired_data, key=lambda pair: len(pair[1]))\n\n    # Initialize buckets for x_train and y_train\n    x_batches = []\n    y_batches = []\n\n    # Group phrases into batches of batch_size\n    for i in range(0, len(paired_data_sorted), batch_size):\n        batch = paired_data_sorted[i:i + batch_size]\n\n        # Split the batch back into x_train and y_train\n        x_batch, y_batch = zip(*batch)\n\n        x_batches.append(list(x_batch))\n        y_batches.append(list(y_batch))\n\n    return x_batches, y_batches\n\n\ndef pad_inputs(sentences, target_type):\n    if target_type == \"encoder\":\n        tokenized_sentences = [['[START]'] + sentence + ['[END]'] for sentence in sentences]\n    elif target_type == \"decoder\":\n        tokenized_sentences = [[\"[START]\"] + sentence for sentence in sentences]\n    elif target_type == \"target\":\n        tokenized_sentences = [sentence + [\"[END]\"] for sentence in sentences]\n    return tokenized_sentences\n\n\ndef generate_inputs(sentences, vocabulary, pad_token='[PAD]', target_type=None):\n    \"\"\"\n    Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n    \"\"\"\n\n    tokenized_sentences = pad_inputs(sentences, target_type)\n    max_len = max(len(sentence) for sentence in tokenized_sentences)\n    # Pad each sentence with the [PAD] token to make them of equal length\n    padded_sentences = [sentence + [pad_token] * (max_len - len(sentence)) for sentence in tokenized_sentences]\n\n    # print(padded_sentences)\n    xi = cp.array([[vocabulary[word][0] for word in phrase_vector] for phrase_vector in padded_sentences])\n    # print(xi.shape)\n    pos_encoding = get_positional_encoding(max_len, 300)\n    xi += pos_encoding\n\n    if target_type == \"decoder\":\n        xi = cp.array(cp.swapaxes(create_timestaped_input(xi, max_len), 0, 1))\n\n    return xi\n\n\ndef forward_attention_encoder(inputs_e):\n    global Qe, Ke, Ve, num_heads, batch_size, dk\n\n    Q_E = cp.swapaxes(cp.array(cp.array_split(cp.matmul(inputs_e, Qe), num_heads, axis=2)), 0, 1)\n    # print(\"Qval.shape: \",Q_E.shape)\n\n    K_E = cp.swapaxes(cp.array(cp.array_split(cp.matmul(inputs_e, Ke), num_heads, axis=2)), 0, 1)\n    # print(\"Kval.shape: \",K_E.shape)\n\n    V_E = cp.swapaxes(cp.array(cp.array_split(cp.matmul(inputs_e, Ve), num_heads, axis=2)), 0, 1)\n    # print(\"Vval.shape: \",V_E.shape)\n\n    QKscaled = cp.matmul(Q_E, cp.transpose(K_E, (0, 1, 3, 2))) / cp.sqrt(dk)\n\n    Attention_weights_e = softmax(QKscaled)\n    # print(\"Attention_weights shape:\",Attention_weights_e.shape)\n\n    Ae = cp.matmul(Attention_weights_e, V_E)\n    # print(\"Attention shape:\",Ae.shape)\n\n    Ae = cp.array([cp.concatenate(Ae[i], axis=1) for i in range(batch_size)])\n    # print(\"Attention encoder shape concat:\",Ae.shape)\n\n    return Ae, Attention_weights_e, K_E, V_E, Q_E\n\n\ndef encoder_first_residual_and_norm(Ae, inputs_e):\n    Xe = Ae + inputs_e\n    Ect1, mu_e, var_e, Ne = layer_norm(Xe)\n    # print(\"Ect1.shape\",Ect1.shape,Ne)\n    return Ect1, Xe, mu_e, var_e, Ne\n\n\ndef fully_connected_layers_encoder(Ect1):\n    global Wfl1e, bfl1e, Wfl2e, bfl2e\n\n    Xe1 = cp.matmul(Ect1, Wfl1e) + bfl1e\n    FLe1 = relu(Xe1)\n\n    FLe2 = cp.matmul(FLe1, Wfl2e) + bfl2e\n\n    Xe2 = FLe2 + Ect1\n    Ecout, mu_e2, var_e2, N_e2 = layer_norm(Xe2)\n    # print(\"Ecout.shape\",Ecout.shape)\n    return Ecout, mu_e2, var_e2, N_e2, FLe1, Xe1, Xe2\n\n\ndef cross_attention_encoder(Ecout):\n    global Kc, Vc\n    K_C = cp.swapaxes(cp.array(cp.array_split(cp.matmul(Ecout, Kc), num_heads, axis=2)), 0, 1)\n    # print(\"K_C.shape: \",K_C.shape)# shape is: num_phrases, numbheads, words_per_phrase, dv/num_heads\n    V_C = cp.swapaxes(cp.array(cp.array_split(cp.matmul(Ecout, Vc), num_heads, axis=2)), 0, 1)\n    # print(\"V_C.shape: \",V_C.shape)\n    return K_C, V_C\n\n\n########################################################DECODER\ndef forward_attention_decoder(input_decoder):\n    global Qd, Kd, Vd  # ,words_per_phrase\n\n    Q_D = cp.swapaxes(cp.array(cp.array_split(cp.matmul(input_decoder, Qd), num_heads, axis=2)), 0, 1)\n    # print(\"Qval.shape: \",Q_D.shape)# numwords, num_phrases, numheads, num_words, dv/num_heads\n\n    # K_D  = cp.swapaxes(cp.swapaxes(cp.array(cp.array_split(cp.matmul(inputs_d[step], Kd),num_heads,axis=3)), 0, 1),1,2)\n    K_D = cp.swapaxes(cp.array(cp.array_split(cp.matmul(input_decoder, Kd), num_heads, axis=2)), 0, 1)\n    # print(\"Kval.shape: \",K_D.shape)\n\n    # V_D  = cp.swapaxes(cp.swapaxes(cp.array(cp.array_split(cp.matmul(inputs_d[step], Vd),num_heads,axis=3)), 0, 1),1,2)\n    V_D = cp.swapaxes(cp.array(cp.array_split(cp.matmul(input_decoder, Vd), num_heads, axis=2)), 0, 1)\n\n    QKscaled_decoder = cp.matmul(Q_D, cp.transpose(K_D, (0, 1, 3, 2))) / cp.sqrt(dv)\n    # Step 1: Create a causal mask of shape (1, 1, 9, 9) to broadcast across heads and batch\n    mask_size = input_decoder.shape[1]  # words_per_phrase\n    # print(mask_size)\n    mask = cp.tril(cp.ones((mask_size, mask_size)))  # (9, 9) lower triangular matrix\n    mask[mask == 0]=-cp.inf  # Set future tokens to -inf\n    mask[mask == 1]=0 # Set allowed tokens to 0\n    mask = mask.reshape(1, 1, mask_size, mask_size)\n\n    # Step 2: Apply mask to QKscaled_decoder (it will broadcast across batch and heads)\n    QKscaled_decoder = QKscaled_decoder + mask\n\n    Attention_weights_masked = softmax(QKscaled_decoder)\n\n    A_mask = cp.matmul(Attention_weights_masked, V_D)\n    # print(\"A_mask.shape non concat: \",A_mask.shape)\n\n    # A_mask=cp.swapaxes(cp.concatenate(cp.swapaxes(A_mask,0,2),axis=-1),0,1)\n    A_mask = cp.concatenate(cp.swapaxes(A_mask, 0, 1), axis=-1)\n\n    # print(\"A_mask.shape concat: \",A_mask.shape)\n    # print(\"inputs_d.shape: \",input_decoder.shape)\n    # print(\"Dt1.shape: \",Dt1.shape)\n    return A_mask, Attention_weights_masked, Q_D, K_D, V_D\n\n\ndef decoder_first_residual_and_norm(A_mask, input_decoder):\n    Xd = input_decoder + A_mask\n    Dt1, mu_d, var_d, N_d = layer_norm(Xd)\n    return Xd, Dt1, mu_d, var_d, N_d\n\n\ndef cross_attention_decoder(Dt1):\n    global Qc\n    Q_C = cp.swapaxes(cp.array(cp.array_split(cp.matmul(Dt1, Qc), num_heads, axis=2)), 0, 1)\n    # print(\"Q_C.shape: \",Q_C.shape)\n    return Q_C\n\n\ndef cross_attention(Q_C, K_C, V_C, Dt1):\n    global dv\n    # print(\"Q_C.shape\",Q_C.shape)\n    # print(\"K_C.shape\",K_C.shape)\n    # print(\"V_C.shape\",V_C.shape)\n    QKscaled_cross_attention = cp.matmul(Q_C, cp.transpose(K_C, (0, 1, 3, 2))) / cp.sqrt(dv)\n    Attention_weights_cross = softmax(QKscaled_cross_attention)\n    Acr = cp.matmul(Attention_weights_cross, V_C)\n    # print(\"Acr.shape non concat\",Acr.shape)\n    Acr = cp.concatenate(cp.swapaxes(Acr, 0, 1), axis=-1)\n    # print(\"Acr.shape concat\",Acr.shape)\n\n    return Acr, Attention_weights_cross\n\n\ndef cross_attention_residual_and_norm(Acr, Dt1):\n    Res = Acr + Dt1\n    Dt2, mu_res, var_res, N_res = layer_norm(Res)\n    return Dt2, mu_res, var_res, N_res, Res\n\n\ndef fully_connected_layers_decoder(Dt2):\n    global Wfl1d, bfl1d, Wfl2d, bfl2d, num_phrases\n\n    Xd1 = cp.matmul(Dt2, Wfl1d) + bfl1d\n\n    FLd1 = relu(Xd1)\n\n    FLd2 = cp.matmul(FLd1, Wfl2d) + bfl2d\n    # print(\"FLd2.shape\",FLd2.shape)\n\n    Xd2 = FLd2 + Dt2\n    Dout, mu_d2, var_d2, N_d2 = layer_norm(Xd2)\n\n    # print(\"Dout.shape\",Dout.shape)\n    Dout = Dout.reshape(Dout.shape[0], Dout.shape[1] * Dout.shape[2])\n    # print(\"Dout.shape\",Dout.shape)\n    return Dout, mu_d2, var_d2, N_d2, Xd2, Xd1, FLd1\n\n\ndef output_layer(Dout):\n    global Wo, bo\n\n    Zout = cp.matmul(Dout, Wo) + bo\n\n    SigmaZout = softmax(Zout)\n    # print(\"SigmaZout.shape\",SigmaZout.shape)\n\n    return SigmaZout\n\n\ndef loss_calculation(SigmaZout, target):\n    # print(\"target.shape\",cp.array(target).shape)\n    Loss = cross_entropy_loss(SigmaZout, target)\n    # print(\"Loss:\",Loss)\n    return Loss\n\n\n##################################################################BACKPROPAGATION\ndef derivate_dout(SigmaZout, target, Dout):\n    global Wo, embedding_size, batch_size, words_per_phrase\n    dLoss_dZout = SigmaZout - target\n    # print(\"dLoss_dZout.shape\",dLoss_dZout.shape)\n    dLoss_W0 = cp.transpose(dLoss_dZout, (1, 0)) @ Dout\n    # print(\"dLoss_W0.shape\",dLoss_W0.shape,\"W0.shape\",W0.shape)\n    dLoss_b0 = cp.sum(dLoss_dZout, axis=0)\n    # print(\"dLoss_b0.shape\",dLoss_b0.shape,\"b0.shape\",b0.shape)\n    dLoss_Dout = dLoss_dZout @ Wo.T\n    dLoss_Dout = dLoss_Dout.reshape(batch_size, words_per_phrase, embedding_size)\n    # print(\"dLoss_Dout.shape\",dLoss_Dout.shape)\n    return dLoss_dZout, dLoss_Dout, dLoss_W0, dLoss_b0\n\n\ndef relu_backward(dA, Xd1):\n    # Create mask where Xd1 > 0\n    relu_mask = (Xd1 > 0).astype(float)  # This will give 1 where Xd1 > 0, else 0\n    # Multiply the incoming gradient dA by the mask\n    dXd1 = dA * relu_mask\n    return dXd1\n\n\ndef derivate_fully_connected_layers_decoder(dLoss_Dout, Dt2, Xd2, var_d2, mu_d2, N_d2, FLd1, Xd1):\n    global Wfl1d, Wfl2d\n\n    dLoss_FLd2 = dLoss_Dout * diff_norm(Xd2, var_d2, mu_d2, N_d2)\n    # print(\"dLoss_FLd2.shape\",dLoss_FLd2.shape)\n    dLoss_Dt2_a = dLoss_FLd2\n    # print(\"dLoss_Dt2_a.shape\",dLoss_Dt2_a.shape)\n    # print(\"Dt2.shape\",Dt2.shape)\n    dLoss_FLd1 = dLoss_FLd2 @ cp.transpose(Wfl2d, (1, 0))\n    # print(\"dLoss_FLd1.shape\",dLoss_FLd1.shape)\n    # print(\"FLd1.shape\",FLd1.shape)\n    dLoss_Wfl2d = cp.sum(cp.transpose(dLoss_FLd2, (0, 2, 1)) @ FLd1, axis=0).T\n    # print(\"dLoss_Wfl2d.shape\",dLoss_Wfl2d.shape) # do the mean here over each phrase\n    # print(\"Wfl2d.shape\",Wfl2d.shape)\n    dLoss_bfl2d = cp.sum(cp.sum(dLoss_FLd2, axis=0), axis=0)\n    # print(\"dLoss_bfl2d.shape\",dLoss_bfl2d.shape) # do the mean here over each phrase\n    # print(\"bfl2d.shape\",bfl2d.shape)\n\n    DLoss_Dt2_b = relu_backward(dLoss_FLd1, Xd1) @ cp.transpose(Wfl1d, (1, 0))\n    DLoss_Dt2 = dLoss_Dt2_a + DLoss_Dt2_b\n    # print(\"DLoss_Dt2.shape\",DLoss_Dt2.shape) # do the mean here over each phrase\n    # print(\"Dt2.shape\",Dt2.shape)\n\n    dLoss_Wfl1d = cp.sum(cp.transpose(relu_backward(dLoss_FLd1, Xd1), (0, 2, 1)) @ Dt2, axis=0).T\n    # print(\"dLoss_Wfl1d.shape\",dLoss_Wfl1d.shape) # do the mean here over each phrase\n    # print(\"Wfl1d.shape\",Wfl1d.shape)\n\n    dLoss_bfl1d = cp.sum(cp.sum(relu_backward(dLoss_FLd1, Xd1), axis=0), axis=0)\n\n    return dLoss_Wfl2d, dLoss_bfl2d, dLoss_Wfl1d, dLoss_bfl1d, DLoss_Dt2\n\n\ndef derivative_cross_attention(dLoss_Dt2, Res, var_res, mu_res, N_res, Attention_weights_cross, K_C, V_C, Q_C, Ecout,\n                               Dt1):\n    # print(\"dLoss_bfl1d.shape\",dLoss_bfl1d.shape) # do the mean here over each phrase\n    # print(\"bfl1d.shape\",bfl1d.shape)\n    global dk\n\n    dLoss_Acr = dLoss_Dt2 * diff_norm(Res, var_res, mu_res, N_res)\n    # print(\"dLoss_Acr.shape\",dLoss_Acr.shape) # do the mean here over each phrase\n    # print(\"Acr.shape\",Acr.shape)\n    dLoss_Dt1_a = dLoss_Dt2 * diff_norm(Res, var_res, mu_res, N_res)\n    # print(\"dLoss_Dt1.shape-------\",dLoss_Dt1_a.shape) # do the mean here over each phrase\n    # print(\"Dt1.shape\",Dt1.shape)\n\n    dLoss_Qc = diffQKV(dLoss_Acr, Attention_weights_cross, K_C, V_C, Dt1, dk)\n    # print(\"dLoss_dQc.shape\",dLoss_Qc.shape) # do the mean here over each phrase\n    # print(\"Qc.shape\",Qc.shape)\n    dLoss_Kc = diffQKV(dLoss_Acr, Attention_weights_cross, Q_C, V_C, Ecout, dk, matrix=\"k\")\n    # print(\"dLoss_dKc.shape\",dLoss_Kc.shape) # do the mean here over each phrase\n    # print(\"Kc.shape\",Kc.shape)\n    dLoss_Vc = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dLoss_Acr, axis=1), (0, 1, 3, 2)) @ (\n                Attention_weights_cross @ cp.expand_dims(Ecout, axis=1)), axis=1), axis=0)\n    # print(\"dLoss_dVc.shape\",dLoss_Vc.shape) # do the mean here over each phrase\n    # print(\"Vc.shape\",Vc.shape)\n    return dLoss_Qc, dLoss_Kc, dLoss_Vc, Attention_weights_cross, dLoss_Dt1_a, dLoss_Acr\n\n\ndef derivative_attention_decoder(dLoss_Acr, Attention_weights_cross, dLoss_Dt1_a, Attention_weights_masked, Q_D, V_D,\n                                 K_D, K_C, V_C, Xd, var_d, mu_d, N_d, input_d):\n    global Qc, dk\n\n    dAttention_weights_cross = Attention_weights_cross * (1 - Attention_weights_cross)\n    # print(\"dAttention_weights_cross.shape\",dAttention_weights_cross.shape)\n    # V1=redimension(dAttention_weights_cross@K_C/cp.sqrt(dk))\n    # print(\"K_C.shape\",K_C.shape)\n    # V2=redimension(V_C)\n    # print(\"V_C.shape\",V_C.shape)\n    # print(\"Qc.shape\",Qc.shape)\n\n    # print(\"dLoss_Dt1_b.shape\",dLoss_Dt1_a.shape)\n    # V3=V1*V2@Qc\n    # dLoss_Dt1_b=dLoss_Acr*V3\n    # V3=V1@cp.transpose(V2@Qc,(0,2,1))\n    # dLoss_Dt1_b=cp.transpose(dLoss_Acr,(0,2,1))@V3\n\n    V1 = dAttention_weights_cross\n    V2 = K_C * V_C / cp.sqrt(dk)\n    V3 = redimension(V1 @ V2) @ Qc\n\n    # print(\"V3.shape\",dLoss_Dt1_a.shape)\n    # print(\"dLoss_Acr.shape\",dLoss_Acr.shape)\n    dLoss_Dt1_b = dLoss_Acr * V3\n\n    dLoss_Dt1 = dLoss_Dt1_a + dLoss_Dt1_b\n\n    dLoss_Amask = dLoss_Dt1 * diff_norm(Xd, var_d, mu_d, N_d)\n    # print(\"dLoss_DAmask.shape\",dLoss_Amask.shape)\n    dLoss_inputd_a = dLoss_Amask\n    # print(\"dLoss_Dinputd_a.shape\",dLoss_inputd_a.shape)\n    dLoss_Kd = diffQKV(dLoss_Amask, Attention_weights_masked, Q_D, V_D, input_d, dk)\n    # print(\"dLoss_Kd.shape\",dLoss_Kd.shape)\n    dLoss_Qd = diffQKV(dLoss_Amask, Attention_weights_masked, K_D, V_D, input_d, dk)\n    # print(\"dLoss_Qd.shape\",dLoss_Qd.shape)\n    dLoss_Vd = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dLoss_Amask, axis=1), (0, 1, 3, 2)) @ (\n                Attention_weights_masked @ cp.expand_dims(input_d, axis=1)), axis=1), axis=0)\n    return dLoss_Kd, dLoss_Qd, dLoss_Vd, dLoss_inputd_a, dLoss_Amask\n\n\ndef derivative_input_decoder(dLoss_Amask, Attention_weights_masked, K_D, V_D, Q_D, dLoss_inputd_a, input_d):\n    global Qd, Kd, Vd, dk\n    dLoss_V_D = cp.transpose(\n        cp.sum(cp.transpose(cp.expand_dims(dLoss_Amask, axis=1), (0, 1, 3, 2)) @ Attention_weights_masked, axis=1),\n        (0, 2, 1))\n    dLoss_V_D.shape\n    dLoss_inputd_v = dLoss_V_D @ Vd\n\n    # print(\"dLoss_inputd_v.shape\",dLoss_inputd_v.shape) # do the mean here over each phrase\n    # print(\"input_d.shape\",input_d.shape)\n\n    dAttention_weights_masked = Attention_weights_masked * (1 - Attention_weights_masked)\n    V1 = redimension(dAttention_weights_masked @ K_D / cp.sqrt(dk))\n    V2 = redimension(V_D)\n    V3 = V1 * V2\n    dLoss_Q_D = dLoss_Amask * V3\n\n    dLoss_inputd_q = dLoss_Q_D @ Qd\n    # print(\"dLoss_inputd_q.shape\",dLoss_inputd_q.shape)\n\n    V1 = redimension(dAttention_weights_masked @ Q_D / cp.sqrt(dk))\n    V2 = redimension(V_D)\n    V3 = V1 * V2\n    dLoss_K_D = dLoss_Amask * V3\n    dLoss_inputd_k = dLoss_K_D @ Kd\n    # print(\"dLoss_inputd_k.shape\",dLoss_inputd_k.shape)\n    dLoss_inputd = dLoss_inputd_a + dLoss_inputd_k + dLoss_inputd_q + dLoss_inputd_v\n\n    dLoss_dWemb_decoder = dLoss_inputd * input_d\n\n    return dLoss_inputd, dLoss_dWemb_decoder\n\n\ndef derivative_Ecout(Attention_weights_cross, dLoss_Acr, Q_C, V_C):\n    global Kc, Vc, num_heads\n\n    dAttention_weights_cross = Attention_weights_cross * (1 - Attention_weights_cross)\n    # dLoss_Acr=cp.expand_dims(dLoss_Acr,axis=1)\n    # print(\"--------------\")\n    # print(\"dLoss_Acr.shape\",dLoss_Acr.shape)\n    # print(\"dAttention_weights_cross.shape\",dAttention_weights_cross.shape)\n    # print(\"Q_C.shape\",Q_C.shape)\n    # print(\"V_C.shape\",V_C.shape)\n    # print(\"Kc.shape\",Kc.shape)\n    # V1=redimension(dAttention_weights_cross@Q_C/cp.sqrt(dk))\n\n    # V2=redimension(V_C)\n\n    # V3=V1*V2\n\n    # dLoss_K_C=dLoss_Acr*V3\n    dLoss_Acr = cp.swapaxes(cp.array(cp.array_split(dLoss_Acr, num_heads, axis=2)), 0, 1)\n    V1 = Q_C @ cp.transpose(V_C, (0, 1, 3, 2)) / cp.sqrt(dk)\n    # print(\"V1.shape\",V1.shape)\n    V2 = dAttention_weights_cross * V1\n    # print(\"V2.shape\",V2.shape,\"dLoss_Acr.shape\",dLoss_Acr.shape)\n    dLoss_K_C = cp.transpose(cp.transpose(dLoss_Acr, (0, 1, 3, 2)) @ V2, (0, 1, 3, 2))\n    # print(\"dLoss_K_C.shape\",dLoss_K_C.shape)\n\n    dLoss_Ecout_k = redimension(dLoss_K_C) @ Kc\n    # print(\"dLoss_Ecout_k.shape\",dLoss_Ecout_k.shape)\n    # dLoss_K_C=dLoss_Acr@cp.transpose(redimension(V2),(0,2,1))\n    # print(\"dLoss_K_C.shape\",dLoss_K_C.shape)\n\n    # dLoss_Ecout_k=dLoss_K_C@Kc\n    # print(\"dLoss_Ecout_k.shape\",dLoss_Ecout_k.shape)\n    dLoss_V_C = cp.transpose(cp.transpose(dLoss_Acr, (0, 1, 3, 2)) @ Attention_weights_cross, (0, 1, 3, 2))\n    # print(\"dLoss_V_C.shape\",dLoss_V_C.shape)\n    # dLoss_V_C=cp.transpose(cp.sum(cp.transpose(cp.expand_dims(dLoss_Acr, axis=1),(0,1,3,2))@Attention_weights_cross,axis=1),(0,2,1))\n    # dLoss_V_C.shape\n    dLoss_Ecout_v = redimension(dLoss_V_C) @ Vc\n    # print(\"dLoss_Ecout_v.shape\",dLoss_Ecout_v.shape)\n    # print(\"dLoss_Ecout_v.shape\",dLoss_Ecout_v.shape) # do the mean here over each phrase\n    dLoss_Ecout = dLoss_Ecout_k + dLoss_Ecout_v\n    return dLoss_Ecout\n\n\ndef derivate_fully_connected_layers_encoder(dLoss_Ecout, Ect1, Xe2, var_e2, mu_e2, N_e2, FLe1, Xe1):\n    global Wfl2e, Wfl1e\n    dLoss_dFLe2 = dLoss_Ecout * diff_norm(Xe2, var_e2, mu_e2, N_e2)\n    dLoss_Ect1_a = dLoss_dFLe2\n    # print(Wfl2e.shape)\n    dLoss_dFLe1 = dLoss_dFLe2 @ cp.transpose(Wfl2e, (1, 0))\n    dLoss_dWfl2e = cp.transpose(dLoss_dFLe2, (0, 2, 1)) @ FLe1\n    # print(dLoss_dWfl2e)\n    dLoss_dbfl2e = cp.sum(dLoss_dFLe2, axis=1)\n\n    dLoss_Ect1_b = relu_backward(dLoss_dFLe1, Xe1) @ cp.transpose(Wfl1e, (1, 0))\n\n    dLoss_Ect1 = dLoss_Ect1_b + dLoss_Ect1_a\n\n    dLoss_Wfl1e = cp.transpose(relu_backward(dLoss_dFLe1, Xe1), (0, 2, 1)) @ Ect1\n\n    dLoss_bfl1e = cp.transpose(relu_backward(dLoss_dFLe1, Xe1), (0, 2, 1))\n\n    return dLoss_dWfl2e, dLoss_dbfl2e, dLoss_Wfl1e, dLoss_bfl1e, dLoss_Ect1\n\n\nimport warnings\n\n\ndef derivative_attention_encoder(dLoss_Ect1, Xe, var_e, mu_e, Ne, Attention_weights_e, K_E, V_E, Q_E, inputs_e):\n    global dk\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", RuntimeWarning)\n        try:\n            dLoss_Ae = dLoss_Ect1 * diff_norm(Xe, var_e, mu_e, Ne)\n\n            dLoss_inpute_a = dLoss_Ae\n\n            dLoss_dQe = diffQKV(dLoss_Ae, Attention_weights_e, K_E, V_E, inputs_e, dk)\n            # print(\"dLoss_dQe.shape\",dLoss_dQe.shape) # do the mean here over each phrase\n            # print(\"Qe.shape\",Qe.shape)\n            dLoss_dKe = diffQKV(dLoss_Ae, Attention_weights_e, Q_E, V_E, inputs_e, dk)\n            # print(\"dLoss_dKe.shape\",dLoss_dKe.shape) # do the mean here over each phrase\n            # print(\"Ke.shape\",Ke.shape)\n\n            dLoss_dVe = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dLoss_Ae, axis=1), (0, 1, 3, 2)) @ (\n                        Attention_weights_e @ cp.expand_dims(inputs_e, axis=1)), axis=1), axis=0)\n            # print(\"dLoss_dVe.shape\",dLoss_dVe.shape) # do the mean here over each phrase\n            return dLoss_dQe, dLoss_dKe, dLoss_dVe, dLoss_inpute_a, dLoss_Ae\n\n        except RuntimeWarning as rw:\n            # Check for NaN or inf values in inputs and matrices\n            # print(\"dLoss_Ae check \", dLoss_Ae)\n            # print(\"Attention_weights_e  \", Attention_weights_e)\n            # print(\"inputs_e  \", inputs_e)\n            print(f\"Caught a RuntimeWarning: {rw}\")\n            return None  # Return None if a warning occurs\n\n        except Exception as e:\n            # Additional checks in case of other exceptions\n            # print(\"inputs_e check \", cp.isnan(inputs_e).any(), cp.isinf(inputs_e).any())\n            # print(\"Attention_weights_e check \", cp.isnan(Attention_weights_e).any(), cp.isinf(Attention_weights_e).any())\n            # print(\"dLoss_Ae check \", cp.isnan(dLoss_Ae).any(), cp.isinf(dLoss_Ae).any())\n            # print(f\"Caught an error: {e}\")\n            return None\n\n\ndef derivative_input_encoder(dLoss_Ae, Attention_weights_e, K_E, V_E, Q_E, dLoss_inpute_a, inputs_e):\n    global Ve, Qe, Ke, dk\n\n    dLoss_V_E = cp.transpose(\n        cp.mean(cp.transpose(cp.expand_dims(dLoss_Ae, axis=1), (0, 1, 3, 2)) @ Attention_weights_e, axis=1), (0, 2, 1))\n    dLoss_inpute_v = dLoss_V_E @ Ve\n\n    dAttention_weights_e = Attention_weights_e * (1 - Attention_weights_e)\n    V1 = redimension(dAttention_weights_e @ K_E / cp.sqrt(dk))\n    V2 = redimension(V_E)\n    V3 = V1 * V2\n    dLoss_Q_E = dLoss_Ae * V3\n    dLoss_inpute_q = dLoss_Q_E @ Qe\n    # print(\"dLoss_inpute_q.shape\",dLoss_inpute_q.shape)\n\n    V1 = redimension(dAttention_weights_e @ Q_E / cp.sqrt(dk))\n    V2 = redimension(V_E)\n    V3 = V1 * V2\n    dLoss_K_E = dLoss_Ae * V3\n    dLoss_inpute_k = dLoss_K_E @ Ke\n    # print(\"dLoss_inpute_k.shape\",dLoss_inpute_k.shape)\n    dLoss_inpute = dLoss_inpute_a + dLoss_inpute_k + dLoss_inpute_q + dLoss_inpute_v\n    dLoss_dWemb_encoder = dLoss_inpute * inputs_e\n    return dLoss_inpute, dLoss_dWemb_encoder\n\n\ndef print_vocabs(ans, vocabulary):\n    for idx, values in enumerate(ans):\n        if(idx<3):\n            max_index = cp.argmax(values)\n\n            # Step 2: Find the word in the vocabulary with the corresponding position\n            matched_word = None\n            for word, (_, position) in vocabulary.items():\n                if position == max_index:\n                    matched_word = word\n                    break\n            print(f\"List {idx + 1}: Max value index: {max_index}, Matched word: {matched_word}\")\n\n\n \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T08:01:23.328991Z","iopub.execute_input":"2024-10-22T08:01:23.329624Z","iopub.status.idle":"2024-10-22T08:01:35.140249Z","shell.execute_reply.started":"2024-10-22T08:01:23.329565Z","shell.execute_reply":"2024-10-22T08:01:35.139479Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def print_vocabs(ans, vocabulary):\n    for idx, values in enumerate(ans):\n        if(idx<3):\n            max_index = cp.argmax(values)\n\n            # Step 2: Find the word in the vocabulary with the corresponding position\n            matched_word = None\n            for word, (_, position) in vocabulary.items():\n                if position == max_index:\n                    matched_word = word\n                    break\n            print(f\"List {idx + 1}: Max value index: {max_index}, Matched word: {matched_word}\")\n    print(f\"\\n\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T08:45:05.437718Z","iopub.execute_input":"2024-10-22T08:45:05.438098Z","iopub.status.idle":"2024-10-22T08:45:05.444388Z","shell.execute_reply.started":"2024-10-22T08:45:05.438061Z","shell.execute_reply":"2024-10-22T08:45:05.443407Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef load_x_y_train_plain():\n    with open('/kaggle/input/summaries-dataset/train.json', 'r', encoding='utf-8') as f:\n        try:\n            dataset = json.load(f)  # Load the JSON data\n        \n        except json.JSONDecodeError as e:\n            print(f\"Error decoding JSON: {e}\")\n    X_train = []\n    y_train = []\n\n    # #Loop through the list and process each dialogue and summary\n    for data in dataset:\n        dialogue = data['dialogue']  # Split dialogue into a list of lines\n        summary = data['summary']\n\n        X_train.append(dialogue)\n        y_train.append(summary)\n    return X_train,y_train\n\ndef split_x_y_train(X_train,y_train):\n    X_train=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n    y_train=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n    return X_train,y_train\n\n \n \n\n# with open('data/vocabolary_full.pkl', 'rb') as f:\n#     vocabulary=pickle.load(f)\ndef filter_train_data(X_train, y_train, to_eliminate):\n    filtered_X_train = []\n    filtered_y_train = []\n\n    for x, y in zip(X_train, y_train):\n        if not any(to_eliminate_str in x for to_eliminate_str in to_eliminate):\n            filtered_X_train.append(x)\n            filtered_y_train.append(y)\n    \n    return filtered_X_train, filtered_y_train\n\n\ndef create_complete_vocabulary(X_train, y_train):\n    nlp_model = spacy.load('en_core_web_lg')\n    nlp_model.disable_pipes([\"parser\", \"ner\"])\n    complete_text_target = ' '.join(y_train) \n    complete_text_origin = ' '.join(X_train)\n    complete_text = complete_text_target + \" [START] [PAD] [END] \" + complete_text_origin\n    \n    vocabulary = create_vocabulary(complete_text,\"vocabolary_full\", nlp_model)\n    print(\"vocabulary size\",len(vocabulary))\n    return vocabulary\n\n\nX_train,y_train=load_x_y_train_plain()\nto_eliminate=[\"[I hope I'm not coming off as rude - If I am, I'm sorry. I just thought it would be beneficial for the both of us...]\",\n    \"[pulls back the curtain and checks out the window]\",\n    \"[hopefully, masses of]\"]\nX_train,y_train = filter_train_data(X_train, y_train, to_eliminate)\n\n\nsample=np.random.randint(0, len(y_train), size=len(X_train))\nsample=[i for i in range(len(y_train))]\nmin_v=10\nmax_v=30\n\n\n\nX_train=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\ny_train=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n\nX_train=[X_train[i] for i in sample if len(y_train[i])<max_v and len(y_train[i])>min_v]\ny_train=[y_train[i] for i in sample if len(y_train[i])<max_v and len(y_train[i])>min_v]\n\n\nprint(len(y_train))\n\n# Calculate lengths of the tokenized phrases\nX_lengths = [len(x) for x in X_train]\ny_lengths = [len(y) for y in y_train]\n\n# Plot histograms\nplt.figure(figsize=(12, 6))\n\n# Histogram for X_train lengths\nplt.subplot(1, 2, 1)\nsns.histplot(X_lengths, bins=20, kde=False)\nplt.title('Histogram of X_train Phrase Lengths')\nplt.xlabel('Length of Phrases')\nplt.ylabel('Frequency')\n\n# Histogram for y_train lengths\nplt.subplot(1, 2, 2)\nsns.histplot(y_lengths, bins=20, kde=False)\nplt.title('Histogram of y_train Phrase Lengths')\nplt.xlabel('Length of Phrases')\nplt.ylabel('Frequency')\n\n# Display the plots\nplt.tight_layout()\nplt.show()\nX_train=[\" \".join(x) for x in X_train]\ny_train=[\" \".join(y) for y in y_train]\n\nprint(len(y_train),y_train[0])\n\nvocabulary=create_complete_vocabulary(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T08:01:35.141806Z","iopub.execute_input":"2024-10-22T08:01:35.142249Z","iopub.status.idle":"2024-10-22T08:02:53.779274Z","shell.execute_reply.started":"2024-10-22T08:01:35.142216Z","shell.execute_reply":"2024-10-22T08:02:53.778399Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"8673\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"8673 Olivia and Olivier are voting for liberals in this election .\nvocabulary size 25644\n","output_type":"stream"}]},{"cell_type":"code","source":"\nlearning_rate=0.001\n\nvocab_size=len(vocabulary)\nbatch_size=32\n\n\n#batch_size = len(X_train)\nwords_per_phrase = num_phrases= max_v+1\ndk = dv = embedding_size = 300 # constrain of transformer all embedding size both input embedding and attention embedding are the same encoder\nnum_heads=5\nQe = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nKe = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nVe = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nQc = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nKc = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nVc = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nQd = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nKd = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\nVd = cp.random.rand(embedding_size, embedding_size) / cp.sqrt(embedding_size)\n\nfl1_size=700\nWfl1e=cp.random.rand(embedding_size, fl1_size)\nbfl1e=cp.random.rand(fl1_size)\n\nWfl2e=cp.random.rand(fl1_size, dv)\nbfl2e=cp.random.rand(dv)\n\n\nWfl1d=cp.random.rand(embedding_size, fl1_size)\nbfl1d=cp.random.rand(fl1_size)\n\nWfl2d=cp.random.rand(fl1_size, dv)\nbfl2d=cp.random.rand(dv)\n\nWo=cp.random.rand(words_per_phrase*embedding_size,vocab_size)\nbo=cp.random.rand(vocab_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T08:21:23.079113Z","iopub.execute_input":"2024-10-22T08:21:23.079975Z","iopub.status.idle":"2024-10-22T08:21:23.093015Z","shell.execute_reply.started":"2024-10-22T08:21:23.079919Z","shell.execute_reply":"2024-10-22T08:21:23.092096Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import traceback","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:07:26.581486Z","iopub.execute_input":"2024-10-22T09:07:26.582176Z","iopub.status.idle":"2024-10-22T09:07:26.586041Z","shell.execute_reply.started":"2024-10-22T09:07:26.582135Z","shell.execute_reply":"2024-10-22T09:07:26.585119Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"\n#X_train,y_train=load_x_y_train_plain()\nnum_batches_per_epoch = len(X_train) // batch_size\nnum_epochs=30\nlearning_rate=0.00001\ntot_loss_epoch=0\n#num_batches_per_epoch=3\nfor epoch in range(num_epochs):\n    print(\"Loss per epoch\",tot_loss_epoch/num_batches_per_epoch)\n    tot_loss_epoch=0\n    for i in tqdm(range(0,num_batches_per_epoch),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n        try: \n            start = i * batch_size\n            end = start + batch_size\n            #print(\"start\",start,\"end\",end)\n            X_batch = X_train[start:end]\n            y_batch = y_train[start:end]\n            #print(\"start\",start,\"end\",end,i)\n            inputs_e=create_input_encoder(X_batch,vocabulary,80,embedding_size)\n            #print(\"inputs_e\",inputs_e.shape)\n            inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n            #print(\"inputs_d\",inputs_d.shape)\n            #targets_d=create_target(y_batch,words_per_phrase,vocabulary)\n            #print(\"targets_d\",targets_d)\n\n            Ae,Attention_weights_e,K_E,V_E,Q_E=forward_attention_encoder(inputs_e)\n\n            Ect1,Xe,mu_e,var_e,Ne=encoder_first_residual_and_norm(Ae,inputs_e) \n            #print(\"Ecout.shape\",Ect1.shape)\n            #Ecout,mu_e2,var_e2,N_e2,FLe1,Xe1,Xe2=fully_connected_layers_encoder(Ect1)\n            #K_C,V_C=cross_attention_encoder(Ecout)\n            K_C,V_C=cross_attention_encoder(Ect1)\n\n            clip_value = 15\n            threshold = 15\n            #print(\"K_C.shape\",K_C.shape)\n            #print(\"V_C.shape\",V_C.shape)\n            target_d=pad_sequences(y_batch,lenght=words_per_phrase,target_type=\"target\")\n            target_d=[i.split() for i in target_d] \n            tot_loss=0\n     \n            for step in range(inputs_d.shape[0]):\n                inputs_decoder=inputs_d[step]\n\n                target=cp.array([get_one_hot(x[step], vocabulary) for x in target_d])\n\n                A_mask,Attention_weights_masked,Q_D,K_D,V_D=forward_attention_decoder(inputs_decoder)\n\n                Xd,Dt1,mu_d,var_d,N_d=decoder_first_residual_and_norm(A_mask,inputs_decoder)\n\n                Q_C=cross_attention_decoder(Dt1)\n                #print(\"Q_C.shape\",Q_C.shape)\n                Acr,Attention_weights_cross=cross_attention(Q_C,K_C,V_C,Dt1)\n\n                Dt2, mu_res,var_res,N_res,Res= cross_attention_residual_and_norm(Acr ,Dt1)\n                #Dout,mu_d2,var_d2,N_d2,Xd2,Xd1,FLd1=fully_connected_layers_decoder(Dt2)\n\n                Dt2=Dt2.reshape(Dt2.shape[0],Dt2.shape[1]*Dt2.shape[2])\n                #print(Dout.shape,Dt2.shape)\n\n                SigmaZout=output_layer(Dt2)\n\n                #print_vocabs(SigmaZout[0:3],vocabulary)\n\n                Loss=loss_calculation(SigmaZout,target)\n\n\n                tot_loss+=Loss\n\n\n                #print(\"step\",step,\"Loss\",Loss)\n\n\n\n                #dLoss_Dout,dLoss_W0,dLoss_b0=derivate_dout(SigmaZout,target,Dout)\n                dLoss_dZout,dLoss_Dout,dLoss_W0,dLoss_b0=derivate_dout(SigmaZout,target,Dt2)\n                #dLoss_Wfl2d,dLoss_bfl2d,dLoss_Wfl1d,dLoss_bfl1d,DLoss_Dt2=derivate_fully_connected_layers_decoder(dLoss_Dout,Dt2,Xd2,var_d2,mu_d2,N_d2,FLd1,Xd1)\n                #dLoss_Qc,dLoss_Kc,dLoss_Vc,Attention_weights_cross,dLoss_Dt1_a,dLoss_Acr=derivative_cross_attention(DLoss_Dt2,Res,var_res,mu_res,N_res,Attention_weights_cross,K_C,V_C,Q_C,Ect1,Dt1)\n                dLoss_Qc,dLoss_Kc,dLoss_Vc,Attention_weights_cross,dLoss_Dt1_a,dLoss_Acr=derivative_cross_attention(dLoss_Dout,Res,var_res,mu_res,N_res,Attention_weights_cross,K_C,V_C,Q_C,Ect1,Dt1)\n\n                dLoss_Kd,dLoss_Qd,dLoss_Vd,dLoss_inputd_a,dLoss_Amask=derivative_attention_decoder(dLoss_Acr,Attention_weights_cross,dLoss_Dt1_a,Attention_weights_masked,Q_D,V_D,K_D,K_C,V_C,Xd,var_d,mu_d,N_d,inputs_decoder)\n                dLoss_inputd,dLoss_dWemb_decoder=derivative_input_decoder(dLoss_Amask,Attention_weights_masked,K_D,V_D,Q_D,dLoss_inputd_a,inputs_decoder)\n\n                all_losses_decoder=[dLoss_dZout,dLoss_Dout,dLoss_W0,dLoss_b0,\n                            dLoss_Qc,dLoss_Kc,dLoss_Vc,dLoss_Dt1_a,dLoss_Acr,\n                            dLoss_Kd,dLoss_Qd,dLoss_Vd,dLoss_inputd_a,dLoss_Amask,\n                            dLoss_inputd,dLoss_dWemb_decoder]\n                \n                \n                \n                for idx, loss in enumerate(all_losses_decoder):\n                    if loss.any() > threshold:\n                        print(f\"Element at index {idx} is higher than threshold: {loss}\")\n                        \n                dLoss_W0 = cp.clip(dLoss_W0, -clip_value, clip_value)\n                dLoss_b0 = cp.clip(dLoss_b0, -clip_value, clip_value)\n                # dLoss_Wfl2d = cp.clip(dLoss_Wfl2d, -clip_value, clip_value)\n                # dLoss_bfl2d = cp.clip(dLoss_bfl2d, -clip_value, clip_value)\n                # dLoss_Wfl1d = cp.clip(dLoss_Wfl1d, -clip_value, clip_value)\n                # dLoss_bfl1d = cp.clip(dLoss_bfl1d, -clip_value, clip_value)\n\n                dLoss_Qc = cp.clip(dLoss_Qc, -clip_value, clip_value)\n                dLoss_Kc = cp.clip(dLoss_Kc, -clip_value, clip_value)\n                dLoss_Vc = cp.clip(dLoss_Vc, -clip_value, clip_value)\n                dLoss_Qd = cp.clip(dLoss_Qd, -clip_value, clip_value)\n                dLoss_Kd = cp.clip(dLoss_Kd, -clip_value, clip_value)\n                dLoss_Vd = cp.clip(dLoss_Vd, -clip_value, clip_value)\n                dLoss_dWemb_decoder = cp.clip(dLoss_dWemb_decoder, -clip_value, clip_value)\n\n                Wo=Wo-learning_rate*dLoss_W0.T\n                bo=bo-learning_rate*dLoss_b0\n                # Wfl2d=Wfl2d-learning_rate*dLoss_Wfl2d\n                # bfl2d=bfl2d-learning_rate*dLoss_bfl2d\n                # Wfl1d=Wfl1d-learning_rate*dLoss_Wfl1d\n                # bfl1d=bfl1d-learning_rate*dLoss_bfl1d\n                Qc=Qc-learning_rate*dLoss_Qc\n                Kc=Kc-learning_rate*dLoss_Kc\n                Vc=Vc-learning_rate*dLoss_Vc\n                Qd=Qd-learning_rate*dLoss_Qd\n                Kd=Kd-learning_rate*dLoss_Kd\n                Vd=Vd-learning_rate*dLoss_Vd\n                inputs_decoder=inputs_decoder-learning_rate*dLoss_dWemb_decoder\n                vocabulary=update_wembedding_decoder(y_batch,inputs_decoder,words_per_phrase,vocabulary)\n\n\n            #print(\"Loss\",tot_loss/inputs_d.shape[0])\n\n            tot_loss_epoch+=tot_loss/inputs_d.shape[0]\n#             if (i%50==0):\n#                 print(\"temp tot loss\",tot_loss_epoch,i,tot_loss/inputs_d.shape[0])\n\n            dLoss_Ecout=derivative_Ecout(Attention_weights_cross,dLoss_Acr,Q_C,V_C)\n            #dLoss_dWfl2e,dLoss_dbfl2e,dLoss_Wfl1e,dLoss_bfl1e,dLoss_Ect1=derivate_fully_connected_layers_encoder(dLoss_Ecout,Ect1,Xe2,var_e2,mu_e2,N_e2,FLe1,Xe1)\n\n            #dLoss_dQe,dLoss_dKe,dLoss_dVe,dLoss_inpute_a,dLoss_Ae=derivative_attention_encoder(dLoss_Ect1,Xe,var_e,mu_e,Ne,Attention_weights_e,K_E,V_E,Q_E,inputs_e)\n            dLoss_dQe,dLoss_dKe,dLoss_dVe,dLoss_inpute_a,dLoss_Ae=derivative_attention_encoder(dLoss_Ecout,Xe,var_e,mu_e,Ne,Attention_weights_e,K_E,V_E,Q_E,inputs_e)\n\n            dLoss_inpute,dLoss_dWemb_encoder=derivative_input_encoder(dLoss_Ae,Attention_weights_e,K_E,V_E,Q_E,dLoss_inpute_a,inputs_e)\n            \n            all_losses_encoder=[dLoss_Ecout,dLoss_dQe,dLoss_dKe,dLoss_dVe,dLoss_inpute_a,dLoss_Ae,\n                            dLoss_inpute,dLoss_dWemb_encoder]\n                 \n\n           \n            for idx, loss in enumerate(all_losses_encoder):\n                if loss.any() > threshold:\n                    print(f\"Element at index {idx} is higher than threshold: {loss}\")\n            # dLoss_dWfl2e = cp.sum(cp.transpose(dLoss_dWfl2e ,(0,2,1)),axis=0) \n            # dLoss_dWfl2e = cp.clip(dLoss_dWfl2e, -clip_value, clip_value)\n            # dLoss_dbfl2e = cp.sum(dLoss_dbfl2e ,axis=0) \n            # dLoss_dbfl2e = cp.clip(dLoss_dbfl2e, -clip_value, clip_value)\n            # dLoss_Wfl1e = cp.sum(cp.transpose(dLoss_Wfl1e ,(0,2,1)),axis=0) \n            # dLoss_Wfl1e = cp.clip(dLoss_Wfl1e, -clip_value, clip_value)\n            # dLoss_bfl1e = cp.sum(cp.transpose(dLoss_bfl1e ,(0,2,1)),axis=0) \n            # dLoss_bfl1e = cp.clip(dLoss_bfl1e, -clip_value, clip_value)\n            dLoss_dQe = cp.clip(dLoss_dQe, -clip_value, clip_value)\n            dLoss_dKe = cp.clip(dLoss_dKe, -clip_value, clip_value)\n            dLoss_dVe = cp.clip(dLoss_dVe, -clip_value, clip_value)\n            dLoss_dWemb_encoder = cp.clip(dLoss_dWemb_encoder, -clip_value, clip_value)\n            # Wfl2e=Wfl2e-learning_rate*dLoss_dWfl2e\n            # bfl2e=bfl2e-learning_rate*dLoss_dbfl2e\n            # Wfl1e=Wfl1e-learning_rate*dLoss_Wfl1e  #print(dLoss_bfl1e.shape,cp.sum(dLoss_bfl1e,axis=0).shape,bfl1e.shape,cp.sum(cp.transpose(dLoss_bfl1e ,(0,2,1)),axis=0).shape)\n            # bfl1e=bfl1e-learning_rate*dLoss_bfl1e\n            Qe=Qe-learning_rate*dLoss_dQe\n            Ke=Ke-learning_rate*dLoss_dKe\n            Ve=Ve-learning_rate*dLoss_dVe\n            inputs_e=inputs_e-learning_rate*dLoss_dWemb_encoder\n            vocabulary=update_wembedding_encoder(X_batch,inputs_e,vocabulary,words_per_phrase)\n        except Exception as e:\n            print(e)\n            traceback.print_exc()\n            pass\n    #inputs_e=inputs_e-learning_rate*dLoss_dWemb_encoder","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:07:29.330520Z","iopub.execute_input":"2024-10-22T09:07:29.330908Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Loss per epoch 0.0\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30:  11%|         | 30/271 [01:27<11:41,  2.91s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30:  41%|     | 112/271 [05:23<07:41,  2.90s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30:  59%|    | 159/271 [07:37<05:26,  2.92s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30:  77%|  | 209/271 [09:59<03:00,  2.91s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30:  83%| | 226/271 [10:46<02:10,  2.90s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30: 100%|| 271/271 [12:54<00:00,  2.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss per epoch 9.852007011854921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30:  11%|         | 30/271 [01:27<11:57,  2.98s/it]Traceback (most recent call last):\n  File \"/tmp/ipykernel_30/1342680679.py\", line 20, in <module>\n    inputs_d=create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary)\n  File \"/tmp/ipykernel_30/1203802747.py\", line 23, in wrapper\n    result = func(*args, **kwargs)  # Execute the wrapped function\n  File \"/tmp/ipykernel_30/1203802747.py\", line 290, in create_decoder_input\n    yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n  File \"/opt/conda/lib/python3.10/site-packages/cupy/_creation/from_data.py\", line 53, in array\n    return _core.array(obj, dtype, copy, order, subok, ndmin, blocking)\n  File \"cupy/_core/core.pyx\", line 2408, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2435, in cupy._core.core.array\n  File \"cupy/_core/core.pyx\", line 2571, in cupy._core.core._array_default\n  File \"cupy/_core/core.pyx\", line 1481, in cupy._core.core._ndarray_base.__array__\nTypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stdout","text":"Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30:  28%|       | 76/271 [03:38<09:26,  2.91s/it]","output_type":"stream"}]}]}