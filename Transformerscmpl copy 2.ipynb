{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b060598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b89336dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import re\n",
    "import cupy as cp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "\n",
    "def log_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Execute the wrapped function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        # print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "class Helper: \n",
    "    \n",
    "    def get_positional_encoding(self,seq_len, d_model):\n",
    "        \"\"\"\n",
    "        Returns a non-learnable (sinusoidal) positional encoding.\n",
    "\n",
    "\n",
    "        seq_len: Length of the input sequence.\n",
    "        d_model: Dimension of the embeddings.\n",
    "        \"\"\"\n",
    "        pos = cp.arange(seq_len)[:, cp.newaxis]  # Shape: [seq_len, 1]\n",
    "        i = cp.arange(d_model)[cp.newaxis, :]  # Shape: [1, d_model]\n",
    "\n",
    "        angle_rates = 1 / cp.power(10000, (2 * (i // 2)) / cp.float32(d_model))\n",
    "\n",
    "        # Apply sine to even indices, cosine to odd indices\n",
    "        pos_encoding = cp.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = cp.sin(pos * angle_rates[:, 0::2])  # sine on even indices\n",
    "        pos_encoding[:, 1::2] = cp.cos(pos * angle_rates[:, 1::2])  # cosine on odd indices\n",
    "\n",
    "        return pos_encoding\n",
    "\n",
    "\n",
    "    def softmax(self,x):\n",
    "        # Subtract the max value for numerical stability\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp(x - max_logits)\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "\n",
    " \n",
    "    # @log_time\n",
    "    def pad_sequence(self,seq, max_len, pad_value=0):\n",
    "        \"\"\"Pad a sequence with a given value up to max_len.\"\"\"\n",
    "        current_len = seq.shape[0]\n",
    "        pad_width = max_len - current_len\n",
    "        if pad_width > 0:\n",
    "            # Pad sequence with zeros (or any pad_value you provide)\n",
    "            seq = cp.pad(seq, ((0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n",
    "        return seq\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_timestaped_input(self,input_d, words_per_phrase):\n",
    "        input_translation = []\n",
    "        for j in range(input_d.shape[0]):\n",
    "            # Create padded sequences\n",
    "            padded_sequences = [self.pad_sequence(input_d[j][0:i], words_per_phrase) for i in range(1, input_d.shape[1] + 1)]\n",
    "            input_translation.append(padded_sequences)\n",
    "        return cp.array(input_translation)\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self,predictions, targets):\n",
    "        epsilon = 1e-12  # Small constant to avoid log(0)\n",
    "        predictions = cp.clip(predictions, epsilon, 1 - epsilon)  # Clipping predictions\n",
    "        return -cp.sum(targets * cp.log(predictions), axis=1).mean()\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    def redimension(self,X):\n",
    "        return cp.concatenate(cp.swapaxes(X, 0, 1), axis=-1)\n",
    "    \n",
    "    @log_time\n",
    "    def create_vocabulary(self,complete_text, name, nlp):\n",
    "        # Use re.findall to split considering punctuation\n",
    "        text = re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', complete_text)\n",
    "\n",
    "        words_list = list(set(text))\n",
    "\n",
    "        vocabulary = dict()\n",
    "\n",
    "        for i, j in enumerate(words_list):\n",
    "            # vocabulary[j]=(jax.random.uniform(jax.random.key(cp.random.randint(10000)),embedding_size),i)\n",
    "            vocabulary[j] = (cp.array(nlp(j).vector), i)\n",
    "            # print(j,len(cp.array(nlp(j).vector)))\n",
    "\n",
    "        # print(vocabulary)\n",
    "        # print(\"Vocabulary size: \", len(vocabulary))\n",
    "        with open(f\"data/{name}.pkl\", 'wb') as handle:\n",
    "            pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def pad_sequences(self,sentences, lenght, pad_token='[PAD]', target_type=None):\n",
    "        \"\"\"\n",
    "        Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n",
    "        \"\"\"\n",
    "\n",
    "        if target_type == \"encoder\":\n",
    "            # Split each sentence into words\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]\\n', sentence) + [\"[END]\"] for sentence in\n",
    "                                sentences]\n",
    "        elif target_type == \"decoder\":\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', sentence) for sentence in sentences]\n",
    "        elif target_type == \"target\":\n",
    "            tokenized_sentences = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        # print(tokenized_sentences)\n",
    "        if lenght == 0:\n",
    "            # Find the maximum sentence length\n",
    "            max_len = max(len(sentence) for sentence in tokenized_sentences)\n",
    "        else:\n",
    "            max_len = lenght\n",
    "\n",
    "        # Pad each sentence with the [PAD] token to make them of equal length\n",
    "        padded_sentences = [\" \".join(sentence + [pad_token] * (max_len - len(sentence))) for sentence in\n",
    "                            tokenized_sentences]\n",
    "\n",
    "        return padded_sentences\n",
    "\n",
    "    def print_matrix(self,X):\n",
    "        for i in X:\n",
    "            print(i)\n",
    "\n",
    "    @log_time\n",
    "    def generate_input_encoder(self,x_batch, vocabulary_encoder, max_words_per_phrase):\n",
    "\n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")# here are string\n",
    "        \n",
    "        #print_matrix(x_train) \n",
    "    \n",
    "        xi = []\n",
    "        # print(x_batch)\n",
    "        phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x]\n",
    "\n",
    "        # print(phrase_vectors_x)\n",
    "        # a=cp.array(phrase_vectors_x).shape\n",
    "\n",
    "        # print(\"a\",a)\n",
    "        # print(\"len phrases:\\n\",[len(i) for i in phrase_vectors_x])\n",
    "\n",
    "        xi = cp.array([[vocabulary_encoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "\n",
    "        return xi\n",
    "\n",
    "\n",
    "    # @log_time\n",
    "    def update_wembedding_encoder(self,x_batch, inputs_e, vocabulary, max_words_per_phrase):\n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n",
    "        # print(x_train)\n",
    "\n",
    "        phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n",
    "\n",
    "        phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x]\n",
    "        # print(\"inputs_e\",inputs_e.shape)\n",
    "        # print(\"(phrase_vectors_x).shape:\\n\",cp.array(phrase_vectors_x).shape)\n",
    "\n",
    "        for phrase in range(inputs_e.shape[0]):\n",
    "            # print(phrase)\n",
    "            for position, word in enumerate(phrase_vectors_x[phrase]):\n",
    "                #   print(\"word\",word)\n",
    "                #   print(\"original values\",vocabulary[word][0])\n",
    "                #   print(\"updated  values\",inputs_e[phrase][position])\n",
    "                #   print(\"index\",vocabulary[word][1])\n",
    "                vocabulary[word] = (inputs_e[phrase][position], vocabulary[word][1])\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    # @log_time\n",
    "    def update_wembedding_decoder(self,y_batch, inputs_decoder, max_words_per_phrase, vocabulary):\n",
    "        # print(\"inputs_decoder\",inputs_decoder.shape)\n",
    "        decoder_input = self.pad_sequences(y_batch, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        decoder_input = [i.split() for i in decoder_input]\n",
    "        # print(max_words_per_phrase)\n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        # for sentence in phrase_vectors_y:\n",
    "        #     print(sentence)\n",
    "        for phrase in range(inputs_decoder.shape[0]):\n",
    "            # print(phrase)\n",
    "            for position, word in enumerate(phrase_vectors_y[phrase]):\n",
    "                # print(\"word\",word)\n",
    "                # print(\"original values\",vocabulary[word][0])\n",
    "                # print(\"updated  values\",inputs_decoder[phrase][position])\n",
    "                #  print(\"delta input\",cp.sum(vocabulary[word][0]-inputs_decoder[phrase][position]))\n",
    "                # print(\"index\",vocabulary[word][1])\n",
    "                vocabulary[word] = (inputs_decoder[phrase][position], vocabulary[word][1])\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_input_encoder(self,X, vocabulary_encoder, max_words_per_phrase, embedding_size):\n",
    "\n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        #print(pos_encoding)\n",
    "        inputs_e = self.generate_input_encoder(X, vocabulary_encoder, max_words_per_phrase)\n",
    "        \n",
    "        #print(inputs_e)\n",
    "\n",
    "        inputs_e += pos_encoding\n",
    "        return inputs_e\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_decoder_input(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        # for sentence in phrase_vectors_y:\n",
    "        #     print(sentence)\n",
    "        #print_matrix(phrase_vectors_y)\n",
    "        \n",
    "\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        # print(pos_encoding.shape,yi.shape)\n",
    "        yi = yi + pos_encoding\n",
    "        #print_matrix(yi)\n",
    "        decoder_inputs = cp.array(cp.swapaxes(self.create_timestaped_input(yi, max_words_per_phrase), 0, 1))\n",
    "        \n",
    "        # decoder_inputs[zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "        for i in range(decoder_inputs.shape[0]):\n",
    "            for j in range(decoder_inputs[i].shape[0]):\n",
    "                zero_rows = cp.all(decoder_inputs[i][j] == 0, axis=1)\n",
    "\n",
    "                decoder_inputs[i][j][zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "\n",
    "        decoder_inputs = cp.array(decoder_inputs)\n",
    "        #print(decoder_inputs[2])\n",
    "        #print(decoder_inputs)\n",
    "        return decoder_inputs\n",
    "\n",
    "    # @log_time\n",
    "    def get_one_hot(self,word, vocabulary_decoder):\n",
    "        # print(word)\n",
    "        vocab_size = len(vocabulary_decoder)\n",
    "        one_hot_vector = cp.zeros(vocab_size)\n",
    "        one_hot_vector[vocabulary_decoder[word][1]] = 1\n",
    "        # print(vocabulary_decoder[word][1])\n",
    "        # print(np.where(one_hot_vector== 1))\n",
    "        # print(cp.sum(one_hot_vector))\n",
    "        return one_hot_vector\n",
    " \n",
    "    def print_vocabs(self,ans, vocabulary,yy,step,target,counter_correct):\n",
    "        \n",
    "        #print(\"----DECODER-----\")\n",
    "        print(\"target\",target)\n",
    "        print(\"ans\",ans)\n",
    "        # yy=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in yy] \n",
    "        \n",
    "        # for idx, values in enumerate(ans):\n",
    "        #     max_index = cp.argmax(values)\n",
    "            \n",
    "        #     # Step 2: Find the word in the vocabulary with the corresponding position\n",
    "        #     predicted_word = None\n",
    "        #     for word, (_, position) in vocabulary.items():\n",
    "        #         if position == max_index:\n",
    "        #             predicted_word = word\n",
    "                 \n",
    "        #             if max_index==position:\n",
    "        #                 print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {matched_word}\")\n",
    "                         \n",
    "        #             break\n",
    "        #     #print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {matched_word}\")\n",
    "        # #print()\n",
    "    #def print_\n",
    "    def log_sparse_entropy(self,ans,target,y_batch,step):\n",
    "        #print(\"target\",target)\n",
    "        #print(\"ans\",ans)\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans)\n",
    "        print(f\"----DECODER--step {step}---\")\n",
    "        self.print_matrix(y_batch)\n",
    "        print(\"target\",target)\n",
    "        indexes=[]\n",
    "        yy=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in y_batch] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values)\n",
    "            indexes.append(max_index)\n",
    "             \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "            print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {max_index}\")\n",
    "        print(\"indexes\",indexes)\n",
    "        print(\"accuracy batch:\",round(counter_found/total_lenght,2))\n",
    "        \n",
    "    def accruacy_sparse_entropy(self,ans,target):\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans) \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values) \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "             \n",
    "        accuracy_batch_on_step=round(counter_found/total_lenght,2)\n",
    "        return accuracy_batch_on_step\n",
    "    \n",
    "\n",
    "    def print_target_vs_prediction_sparce_loss(self,ans,target):\n",
    "        \n",
    "         \n",
    "        indexes=[]\n",
    "       \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = np.argmax(values).item()\n",
    "            indexes.append(max_index)\n",
    "             \n",
    "        print(\"target\",target)\n",
    "        print(\"indexes\",indexes)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def sparse_categorical_crossentropy(self,probabilities, labels):\n",
    "        \"\"\"\n",
    "        Compute sparse categorical cross-entropy loss for next token prediction.\n",
    "        \n",
    "        Args:\n",
    "            logits: Numpy array of shape (batch_size, num_classes), raw model outputs.\n",
    "            labels: Numpy array of shape (batch_size,), integer-encoded labels of the next tokens.\n",
    "\n",
    "        Returns:\n",
    "            Scalar: The average cross-entropy loss across the batch.\n",
    "        \"\"\"\n",
    "        # Step 1: Apply softmax to logits to get probabilities\n",
    "        \n",
    "\n",
    "        # Step 2: Extract probabilities for the correct class (target labels)\n",
    "        batch_size = probabilities.shape[0]\n",
    "        correct_class_probs = probabilities[np.arange(batch_size), labels]\n",
    "\n",
    "        # Step 3: Compute the log of probabilities and then the negative log-likelihood\n",
    "        loss = -np.log(correct_class_probs + 1e-8)  # Add small epsilon for numerical stability\n",
    "\n",
    "        # Step 4: Return the average loss across the batch\n",
    "        return np.mean(loss)\n",
    "    \n",
    "    \n",
    "\n",
    "class layer_dropout: \n",
    "    def __init__(self,dropout_rate=0.1):\n",
    "        self.dropout_rate=dropout_rate \n",
    "    def forward(self,X, training=True):  \n",
    "        \n",
    "        mask = cp.random.rand(*X.shape) > self.dropout_rate \n",
    "        result = X * mask \n",
    "        return result\n",
    "\n",
    "class layer_normalization: \n",
    "    def __init__(self,epsilon=1e-6):\n",
    "        self.epsilon=epsilon\n",
    "        self.mu=0\n",
    "        self.var=0\n",
    "        self.N=0\n",
    "          \n",
    "\n",
    "    def forward(self,x):\n",
    "        self.X=x\n",
    "        self.N=x.shape[-1]\n",
    "        self.alpha = cp.ones(self.N)\n",
    "        self.bias = cp.zeros(self.N)\n",
    "        self.mu = cp.mean(x, axis=-1, keepdims=True)\n",
    "        self.std = cp.var(x, axis=-1, keepdims=True)  \n",
    "        x_norm = self.alpha*(x - self.mu)/cp.sqrt(self.var + self.epsilon) +self.bias\n",
    "        return x_norm\n",
    "    \n",
    "    def compute_derivative_A(self,X, mu,sqrVar,sqrVar_3_2):\n",
    "        A=1 /sqrVar\n",
    "        B=X*(X-mu)\n",
    "        result=A-(B/sqrVar_3_2)\n",
    "        return result\n",
    "    \n",
    "    def compute_derivative_B(self,X, mu,sqrVar,N,sqrVar_3_2):\n",
    "        A=-1/(N*sqrVar)\n",
    "        B=mu*(X-mu)\n",
    "        result=A+(B/sqrVar_3_2)\n",
    "        return result\n",
    "    \n",
    "    def backpropagation(self):\n",
    "        sqrVar=cp.sqrt(self.var+self.epsilon)\n",
    "        sqrVar_3_2=self.N*((self.var + self.epsilon) ** (3 / 2)) \n",
    "        A=self.compute_derivative_A(self.X, self.mu, sqrVar,sqrVar_3_2)\n",
    "        B=self.compute_derivative_B(self.X, self.mu,sqrVar,self.N,sqrVar_3_2)\n",
    "        result=A+B\n",
    "        return result\n",
    "\n",
    "class linear_layer: \n",
    "    def __init__(self,input_size,output_size,out=False,only_weights=False):\n",
    "        if out==True:\n",
    "            self.W=cp.random.rand(input_size, output_size)/cp.sqrt(input_size)\n",
    "        else:\n",
    "            self.W=cp.random.rand(input_size, output_size)\n",
    "        if only_weights==True:\n",
    "            pass\n",
    "        else: \n",
    "            self.b=cp.random.rand(output_size)\n",
    "      \n",
    "    def forward(self,X): \n",
    "        self.X=X\n",
    "        Xout = cp.matmul(X, self.W) + self.b \n",
    "        return Xout\n",
    "    \n",
    "    def forward_weights_only(self,X): \n",
    "        self.X=X\n",
    "        Xout = cp.matmul(X, self.W) \n",
    "        return Xout\n",
    "     \n",
    "    \n",
    "    def update_weights(self,dLoss_dW,dLoss_db,learning_rate):\n",
    "        self.W=self.W-learning_rate*dLoss_dW\n",
    "        self.b=self.b-learning_rate*dLoss_db\n",
    "\n",
    "    def update_weights_only(self,dLoss_dW,learning_rate):\n",
    "        self.W=self.W-learning_rate*dLoss_dW\n",
    "       \n",
    "class fully_connected_block:\n",
    "    def __init__(self,embedding_size,hidden_size):\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.linear_layer_1=linear_layer(self.embedding_size,self.hidden_size)\n",
    "        self.linear_layer_2=linear_layer(self.hidden_size,self.embedding_size)\n",
    "        self.dropout=layer_dropout()\n",
    "        self.ReLu=ReLu_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_1=self.dropout.forward(self.ReLu.forward_leaky(self.linear_layer_1.forward(x)))\n",
    "        x_2=self.linear_layer_2.forward(x_1)\n",
    "        return x_2\n",
    "    \n",
    "\n",
    " \n",
    "class ReLu_layer:\n",
    "    def __init__(self,alpha=0.01):\n",
    "        self.alpha=alpha \n",
    "    def forward_leaky(self,X):\n",
    "        self.X=X\n",
    "        return cp.where(X > 0, X, self.alpha * X)\n",
    "\n",
    "    def forward(self,X): \n",
    "        self.X=X\n",
    "        return cp.maximum(0,self.X)\n",
    "    \n",
    "    def backward(self, dLoss): \n",
    "        # Gradient of ReLU is 1 for x > 0, else 0\n",
    "        dx = dLoss * (self.X > 0)  # Only propagate gradients for inputs > 0\n",
    "        return dx\n",
    "    \n",
    "    def backward_leaky(self, dLoss): \n",
    "        dx = dLoss * cp.where(self.X > 0, 1, self.alpha)  # Gradient: 1 for x > 0, else alpha\n",
    "        return dx\n",
    "\n",
    "class residual_layer:\n",
    "    def __init__(self):\n",
    "        self.dropuot=layer_dropout()\n",
    "        self.normalization=layer_normalization()\n",
    "\n",
    "\n",
    "    def forward(self,x,sublayer_output):\n",
    "        result=self.dropuot.forward(self.normalization.forward(x+sublayer_output))\n",
    "        return result\n",
    "\n",
    "\n",
    "      \n",
    "class multihead_attention: \n",
    "    def __init__(self,embedding_size,num_heads,batch_size):\n",
    "        self.num_heads=num_heads\n",
    "        self.dk=embedding_size//num_heads\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.q=linear_layer(self.embedding_size,self.embedding_size,only_weights=True)\n",
    "        self.k=linear_layer(self.embedding_size,self.embedding_size,only_weights=True)\n",
    "        self.v=linear_layer(self.embedding_size,self.embedding_size,only_weights=True)\n",
    "        self.WO=linear_layer(self.embedding_size,self.embedding_size,only_weights=True)\n",
    "        self.dropout=layer_dropout()\n",
    "        self.helper=Helper()\n",
    "        \n",
    "    def reshape_heads(self,Q,K,V):\n",
    "        self.Q = cp.swapaxes(cp.array(np.array_split(Q, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Qval.shape: \",Q_E.shape)\n",
    "        self.K = cp.swapaxes(cp.array(np.array_split(K, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Kval.shape: \",K_E.shape)\n",
    "        self.V = cp.swapaxes(cp.array(np.array_split(V, self.num_heads, axis=2)), 0, 1)\n",
    "        #return self.Q,self.K,self.V\n",
    "\n",
    "    def QKV(self,input_q,input_k,input_v): \n",
    "        Q=self.q.forward_weights_only(input_q)\n",
    "        K=self.k.forward_weights_only(input_k)\n",
    "        V=self.v.forward_weights_only(input_v) \n",
    "        self.reshape_heads(Q,K,V)\n",
    "        \n",
    "\n",
    "    def attention_weights(self): \n",
    "        QKscaled =cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])  \n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "         \n",
    "\n",
    "    def forward_attention(self,input_q,input_k,input_v): \n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights()\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V)\n",
    "        # print(\"Attention shape:\",Ae.shape)\n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)])\n",
    "        #print(\"Attention encoder shape concat:\",Attention.shape)\n",
    "        #print(\"Attention encoder shape concat:\",self.WO.W.shape)\n",
    "        Output=self.dropout.forward(cp.matmul(Attention,self.WO.W))\n",
    "        print(\"Output encoder shape concat:\",Output.shape)\n",
    "        return Output\n",
    "    \n",
    "    def forward_masked_attention(self,input_q,input_k,input_v,mask_size):\n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights_masked(mask_size)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V)\n",
    "        # print(\"Attention shape:\",Ae.shape)\n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)])\n",
    "        # print(\"Attention encoder shape concat:\",Ae.shape)\n",
    "        Output=self.dropout.forward(cp.matmul(Attention,self.WO.W))\n",
    "        return Output\n",
    "    \n",
    "    def attention_weights_masked(self,mask_size):\n",
    "        #mask_size =  words_per_phrase \n",
    "\n",
    "        QKscaled = cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])\n",
    "        mask = cp.tril(cp.ones((mask_size, mask_size)))  # (9, 9) lower triangular matrix\n",
    "        mask[mask == 0]=-cp.inf  # Set future tokens to -inf\n",
    "        mask[mask == 1]=0  # Set allowed tokens to 0\n",
    "        mask = mask.reshape(1, 1, mask_size, mask_size)\n",
    "        QKscaled = QKscaled + mask\n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "         \n",
    "    \n",
    "    def diffQi(self,dAttention,X):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_dX=cp.transpose(dAttention, (0, 2, 1)) @ (self.helper.redimension(dAttention_weights @ (self.K * self.V) / cp.sqrt(self.K.shape[-1]))*X)\n",
    "        return cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffKi(self,dAttention,X):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        X = cp.swapaxes(cp.array(cp.array_split(X, self.num_heads, axis=2)), 0, 1) \n",
    "         \n",
    "        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ self.helper.redimension(\n",
    "            (dAttention_weights * (self.Q @ cp.transpose(self.V, (0, 1, 3, 2))) @ X) / cp.sqrt(self.K.shape[-1])) \n",
    "        return cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffVi(self,dAttention,X):\n",
    "        dLoss_Vc = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ (\n",
    "                self.Attention_weights @ cp.expand_dims(X, axis=1)), axis=1), axis=0)\n",
    "        return dLoss_Vc\n",
    "    \n",
    "    def diffKInput(self,dAttention,Ki):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_KI=dAttention*(self.helper.redimension(dAttention_weights @ self.Q / cp.sqrt(self.K.shape[-1]))*self.helper.redimension(self.V)@Ki)\n",
    "        return dLoss_KI\n",
    "    \n",
    "    def diffVInput(self,dAttention,Vi):\n",
    "        dLoss_V_E = cp.transpose(\n",
    "        cp.mean(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ self.Attention_weights, axis=1), (0, 2, 1))\n",
    "        dLoss_inpute_v = dLoss_V_E @ Vi\n",
    "        return dLoss_inpute_v\n",
    "    \n",
    "    def diffQInput(self,dAttention,Qi):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_KI=dAttention*(self.helper.redimension(dAttention_weights @ self.K / cp.sqrt(self.K.shape[-1]))*self.helper.redimension(self.V)@Qi)\n",
    "        return dLoss_KI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af4c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73351bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006 Amanda baked cookies and will bring Jerry some tomorrow .\n",
      "vocabulary size 2568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "min_v = 10\n",
    "max_v = 11\n",
    "helper=Helper()\n",
    "def load_x_y_train_plain():\n",
    "    with open('corpus/train.json', 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            dataset = json.load(f)  # Load the JSON data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # #Loop through the list and process each dialogue and summary\n",
    "    for data in dataset:\n",
    "        dialogue = data['dialogue']  # Split dialogue into a list of lines\n",
    "        summary = data['summary']\n",
    "\n",
    "        X_train.append(dialogue)\n",
    "        y_train.append(summary)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def split_x_y_train(X_train, y_train):\n",
    "    X_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n",
    "    y_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "# with open('data/vocabolary_full.pkl', 'rb') as f:\n",
    "#     vocabulary=pickle.load(f)\n",
    "def filter_train_data(X_train, y_train, to_eliminate):\n",
    "    filtered_X_train = []\n",
    "    filtered_y_train = []\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if not any(to_eliminate_str in x for to_eliminate_str in to_eliminate):\n",
    "            filtered_X_train.append(x)\n",
    "            filtered_y_train.append(y)\n",
    "\n",
    "    return filtered_X_train, filtered_y_train\n",
    "\n",
    "\n",
    "def create_complete_vocabulary(X_train, y_train):\n",
    "    nlp_model = spacy.load('en_core_web_lg')\n",
    "    nlp_model.disable_pipes([\"parser\", \"ner\"])\n",
    "    complete_text_target = ' '.join(y_train)\n",
    "    complete_text_origin = ' '.join(X_train)\n",
    "    complete_text = complete_text_target + \" [START] [PAD] [END] \" + complete_text_origin\n",
    "\n",
    "    vocabulary = helper.create_vocabulary(complete_text, \"vocabolary_full\", nlp_model)\n",
    "    print(\"vocabulary size\", len(vocabulary))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "X_train, y_train = load_x_y_train_plain()\n",
    "to_eliminate = [\n",
    "    \"[I hope I'm not coming off as rude - If I am, I'm sorry. I just thought it would be beneficial for the both of us...]\",\n",
    "    \"[pulls back the curtain and checks out the window]\",\n",
    "    \"[hopefully, masses of]\"]\n",
    "X_train, y_train = filter_train_data(X_train, y_train, to_eliminate)\n",
    "\n",
    "\n",
    "sample = [i for i in range(0,len(y_train))]\n",
    "\n",
    "\n",
    "X_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n",
    "y_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n",
    "\n",
    "\n",
    "X_train = [X_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "y_train = [y_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "\n",
    "\n",
    "# Calculate lengths of the tokenized phrases\n",
    "\n",
    "\n",
    "def plot_lenghts(X_train,y_train):\n",
    "    X_lengths = [len(x) for x in X_train]\n",
    "    y_lengths = [len(y) for y in y_train]\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for X_train lengths\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(X_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of X_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for y_train lengths\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(y_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of y_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "X_train=[i[::-1] for i in y_train]\n",
    "plot_lenghts(X_train,y_train)\n",
    " \n",
    "\n",
    "X_train=[\" \".join(x) for x in X_train]\n",
    "y_train=[\" \".join(y) for y in y_train]\n",
    "\n",
    "print(len(y_train),y_train[0])\n",
    "\n",
    "vocabulary=create_complete_vocabulary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d4c7d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase):\n",
    "        self.batch_size=batch_size\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.num_heads=num_heads\n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size)\n",
    "        self.multihead_attention_encoder=multihead_attention(num_heads=2,embedding_size=embedding_size,batch_size=batch_size)\n",
    "        self.residual_layer_1=residual_layer()\n",
    "        self.residual_layer_2=residual_layer() \n",
    "        self.learning_rate=learning_rate\n",
    "        self.helper=Helper()\n",
    "     \n",
    "\n",
    "    def forward(self,inputs_e):\n",
    "        self.inputs_e=inputs_e \n",
    "\n",
    "        Ae=self.multihead_attention_encoder.forward_attention(inputs_e,inputs_e,inputs_e)\n",
    "        \n",
    "        Ect1=self.residual_layer_1.forward(Ae,inputs_e) \n",
    "\n",
    "        FLe2=self.fully_connected_block.forward(Ect1) \n",
    "\n",
    "        Ecout=self.residual_layer_2.forward(FLe2,Ect1)\n",
    "\n",
    "        return Ecout\n",
    "\n",
    "\n",
    "    def backpropagation(self,dLoss_Ecout,vocabulary,X_batch):\n",
    "        \n",
    "        dLoss_dFLe2 = dLoss_Ecout * self.normalization_layer_encoder_2.backpropagation()\n",
    "        dLoss_Ect1_a = dLoss_dFLe2\n",
    "\n",
    "        dLoss_dFLe1 = dLoss_dFLe2 @ self.linear_layer_econder_2.W.T\n",
    "\n",
    "        dLoss_dWfl2e = cp.sum(cp.transpose(dLoss_dFLe2, (0, 2, 1)) @ self.linear_layer_econder_2.X,axis=0).T\n",
    " \n",
    "        dLoss_dbfl2e = cp.sum(cp.sum(dLoss_dFLe2, axis=1),axis=0)\n",
    "        \n",
    "\n",
    "        dLoss_Ect1_b = self.relu_layer_encoder.backward_leaky(dLoss_dFLe1) @ cp.transpose(self.linear_layer_econder_1.W, (1, 0))\n",
    "\n",
    "        dLoss_Ect1 = dLoss_Ect1_b + dLoss_Ect1_a\n",
    "        \n",
    "        dLoss_dWfl1e = cp.sum(cp.transpose(self.relu_layer_encoder.backward_leaky(dLoss_dFLe1), (0, 2, 1)) @ self.linear_layer_econder_1.X,axis=0).T\n",
    "        \n",
    "        dLoss_dbfl1e = cp.sum(cp.sum(self.relu_layer_encoder.backward_leaky(dLoss_dFLe1),axis=0),axis=0)\n",
    "\n",
    "        #print(dLoss_dbfl1e.shape,linear_layer_econder_1.b.shape)\n",
    "        dLoss_Ae = dLoss_Ect1 * self.normalization_layer_encoder_1.backpropagation()\n",
    "        \n",
    "        dLoss_inpute_a = dLoss_Ae\n",
    "\n",
    "        dLoss_dQe=self.multihead_attention_encoder.diffQi(dLoss_Ae,self.inputs_e)\n",
    "\n",
    "        dLoss_dKe=self.multihead_attention_encoder.diffKi(dLoss_Ae, self.inputs_e)\n",
    "\n",
    "        dLoss_dVe=self.multihead_attention_encoder.diffVi(dLoss_Ae,self.inputs_e)\n",
    "        \n",
    "        dLoss_inpute_k=self.multihead_attention_encoder.diffKInput(dLoss_Ae,self.Ke.W)\n",
    "        dLoss_inpute_q=self.multihead_attention_encoder.diffQInput(dLoss_Ae,self.Qe.W)\n",
    "        dLoss_inpute_v=self.multihead_attention_encoder.diffVInput(dLoss_Ae,self.Ve.W)\n",
    "        dLoss_input_e = dLoss_inpute_a + dLoss_inpute_k + dLoss_inpute_q + dLoss_inpute_v\n",
    "        dLoss_dWemb_encoder = dLoss_input_e * self.inputs_e\n",
    "\n",
    "        vocabulary=self.update_weights(dLoss_dWfl2e,\n",
    "                                       dLoss_dbfl2e,\n",
    "                                       dLoss_dWfl1e\n",
    "                                       ,dLoss_dbfl1e,\n",
    "                                       dLoss_dQe,\n",
    "                                       dLoss_dKe,\n",
    "                                       dLoss_dVe,dLoss_dWemb_encoder,vocabulary,X_batch)\n",
    "        return vocabulary\n",
    "    \n",
    "    def update_weights(self,dLoss_dWfl2e,dLoss_dbfl2e,dLoss_dWfl1e,dLoss_dbfl1e,dLoss_dQe,dLoss_dKe,dLoss_dVe,dLoss_dWemb_encoder,vocabulary,X_batch):\n",
    "        self.linear_layer_econder_2.update_weights(dLoss_dWfl2e,dLoss_dbfl2e,self.learning_rate)\n",
    "        self.linear_layer_econder_1.update_weights(dLoss_dWfl1e,dLoss_dbfl1e,self.learning_rate)\n",
    "\n",
    "        self.Qe.update_weights_only(dLoss_dQe,self.learning_rate)\n",
    "        self.Ke.update_weights_only(dLoss_dKe,self.learning_rate)\n",
    "        self.Ve.update_weights_only(dLoss_dVe,self.learning_rate)\n",
    "        self.inputs_e=self.inputs_e-self.learning_rate*dLoss_dWemb_encoder\n",
    "        vocabulary=self.helper.update_wembedding_encoder(X_batch,self.inputs_e,vocabulary,self.words_per_phrase)\n",
    "        return vocabulary\n",
    "    \n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase):\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.batch_size=batch_size\n",
    "        self.num_heads=num_heads \n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size  \n",
    "        self.multihead_cross_attention=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size)\n",
    "        self.multihead_attention_decoder=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size) \n",
    "        self.learning_rate=learning_rate\n",
    "        self.helper=Helper() \n",
    "        self.residual_layer_1=residual_layer()\n",
    "        self.residual_layer_2=residual_layer() \n",
    "        self.residual_layer_3=residual_layer() \n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size)\n",
    "\n",
    "    def forward(self,inputs_decoder,Ecout,step):\n",
    "        self.inputs_decoder=inputs_decoder \n",
    "        \n",
    "        A_mask=self.multihead_attention_decoder.forward_masked_attention(inputs_decoder,inputs_decoder,inputs_decoder,mask_size=inputs_decoder.shape[1])\n",
    "    \n",
    "        #Xd=self.inputs_decoder+A_mask\n",
    "\n",
    "        Dt1=self.residual_layer_1.forward(self.inputs_decoder,A_mask)\n",
    "\n",
    "\n",
    "        Acr=self.multihead_cross_attention.forward_attention(Dt1,Ecout,Ecout)\n",
    "         \n",
    "        #Res=Acr+Dt1\n",
    " \n",
    "        Dt2=self.residual_layer_2.forward(Acr,Dt1)\n",
    " \n",
    "        FLd2=self.fully_connected_block.forward(Dt2)\n",
    "        \n",
    "        \n",
    "        #Xd2=FLd2+Dt2 \n",
    "        \n",
    "        Dout=self.residual_layer_3.forward(FLd2,Dt2)\n",
    "        #print(Dout)\n",
    "        Dout = Dout[:, step, :]\n",
    "        #print(Dout)\n",
    "        return Dout\n",
    "\n",
    "\n",
    "    def backpropagation(self,dLoss_dDout,vocabulary,y_batch):\n",
    "        \n",
    "        \n",
    "        dLoss_dFLd2=cp.expand_dims(dLoss_dDout,axis=1)*self.normalization_layer_decoder_3.backpropagation()\n",
    "        dLoss_dDt2_a=dLoss_dFLd2\n",
    "        \n",
    "            \n",
    "        dLoss_dFLd1 = dLoss_dFLd2 @ self.linear_layer_decoder_2.W.T\n",
    "\n",
    "        \n",
    "        dLoss_dWfl2d = cp.sum(cp.transpose(dLoss_dFLd2, (0, 2, 1)) @ self.linear_layer_decoder_2.X, axis=0).T\n",
    "        dLoss_dbfl2d = cp.sum(cp.sum(dLoss_dFLd2, axis=0), axis=0)\n",
    "        \n",
    "        DLoss_dDt2_b =self.relu_layer_decoder.backward_leaky(dLoss_dFLd1) @ cp.transpose(self.linear_layer_decoder_1.W, (1, 0))\n",
    "        DLoss_dDt2 = DLoss_dDt2_b + dLoss_dDt2_a \n",
    "         \n",
    "        dLoss_dWfl1d = cp.sum(cp.transpose(self.relu_layer_decoder.backward_leaky(dLoss_dFLd1), (0, 2, 1)) @ self.linear_layer_decoder_1.X, axis=0).T\n",
    "        dLoss_dbfl1d = cp.sum(cp.sum(self.relu_layer_decoder.backward_leaky(dLoss_dFLd1), axis=0), axis=0)\n",
    "        # \n",
    "        dLoss_dAcr = DLoss_dDt2 * self.normalization_layer_decoder_2.backpropagation()\n",
    "        dLoss_dDt1_a = dLoss_dAcr\n",
    " \n",
    "        dLoss_dQc = self.multihead_cross_attention.diffQi(dLoss_dAcr,self.Qc.X)\n",
    "         \n",
    "        dLoss_dKc=self.multihead_cross_attention.diffKi(dLoss_dAcr,self.Kc.X)\n",
    "         \n",
    "        dLoss_dVc=self.multihead_cross_attention.diffVi(dLoss_dAcr,self.Vc.X)\n",
    "         \n",
    "        dAttention_weights_cross = self.multihead_cross_attention.Attention_weights * (1 - self.multihead_cross_attention.Attention_weights)\n",
    "\n",
    "        dLoss_dDt1_b= dLoss_dAcr * self.helper.redimension(dAttention_weights_cross @ (self.multihead_cross_attention.K * self.multihead_cross_attention.V / cp.sqrt(embedding_size))) @ self.Qc.W\n",
    "\n",
    "        dLoss_dDt1 =  dLoss_dDt1_b+ dLoss_dDt1_a\n",
    "           \n",
    "        dLoss_Amask = dLoss_dDt1 * self.normalization_layer_decoder_1.backpropagation() \n",
    "\n",
    "        dLoss_inputd_a = dLoss_Amask\n",
    "\n",
    "        dLoss_Kd=self.multihead_attention_decoder.diffKi(dLoss_Amask,self.inputs_decoder)\n",
    "        # \n",
    "        dLoss_Qd =self.multihead_attention_decoder.diffQi(dLoss_Amask,self.inputs_decoder)\n",
    "        #\n",
    "        dLoss_Vd =self.multihead_attention_decoder.diffVi(dLoss_Amask,self.inputs_decoder)\n",
    "        #\n",
    "        dLoss_inputd_k=self.multihead_attention_decoder.diffKInput(dLoss_Amask,self.Kd.W)\n",
    "        dLoss_inputd_q=self.multihead_attention_decoder.diffQInput(dLoss_Amask,self.Qd.W)\n",
    "        dLoss_inputd_v=self.multihead_attention_decoder.diffVInput(dLoss_Amask,self.Vd.W)\n",
    "        dLoss_input_d = dLoss_inputd_a + dLoss_inputd_k + dLoss_inputd_q + dLoss_inputd_v\n",
    "        dLoss_dWemb_decoder= dLoss_input_d * self.inputs_decoder\n",
    "\n",
    "        vocabulary=self.update_weights(dLoss_dWfl2d,\n",
    "                                        dLoss_dbfl2d,\n",
    "                                        dLoss_dWfl1d,\n",
    "                                        dLoss_dbfl1d,\n",
    "                                        dLoss_dQc,\n",
    "                                        dLoss_dKc,\n",
    "                                        dLoss_dVc,\n",
    "                                        dLoss_Kd,\n",
    "                                        dLoss_Qd,\n",
    "                                        dLoss_Vd,\n",
    "                                        dLoss_dWemb_decoder,\n",
    "                                        vocabulary,\n",
    "                                        y_batch)\n",
    "        return vocabulary,dLoss_dAcr\n",
    "    \n",
    "    def update_weights(self,dLoss_dWfl2d,\n",
    "                       dLoss_dbfl2d,\n",
    "                       dLoss_dWfl1d,\n",
    "                       dLoss_dbfl1d,\n",
    "                       dLoss_dQc,\n",
    "                       dLoss_dKc,\n",
    "                       dLoss_dVc,\n",
    "                       dLoss_Kd,\n",
    "                       dLoss_Qd,\n",
    "                       dLoss_Vd,\n",
    "                       dLoss_dWemb_decoder,\n",
    "                       vocabulary,\n",
    "                       y_batch):\n",
    "        self.linear_layer_decoder_2.update_weights(dLoss_dWfl2d,dLoss_dbfl2d,self.learning_rate)\n",
    "        self.linear_layer_decoder_1.update_weights(dLoss_dWfl1d,dLoss_dbfl1d,self.learning_rate)\n",
    "        self.Qc.update_weights_only(dLoss_dQc,self.learning_rate)\n",
    "        self.Kc.update_weights_only(dLoss_dKc,self.learning_rate)\n",
    "        self.Vc.update_weights_only(dLoss_dVc,self.learning_rate)\n",
    "        self.Kd.update_weights_only(dLoss_Kd,self.learning_rate)\n",
    "        self.Qd.update_weights_only(dLoss_Qd,self.learning_rate)\n",
    "        self.Vd.update_weights_only(dLoss_Vd,self.learning_rate)\n",
    "        self.inputs_decoder=self.inputs_decoder-self.learning_rate*dLoss_dWemb_decoder\n",
    "        vocabulary=self.helper.update_wembedding_decoder(y_batch,self.inputs_decoder,self.words_per_phrase,vocabulary) \n",
    "        return vocabulary\n",
    "embedding_size=300\n",
    "fl1_size=2048\n",
    "learning_rate=0.0001\n",
    "batch_size=64\n",
    "num_heads=10\n",
    "dropout_rate=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107b0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b1c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "024879bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550:   0%|          | 0/15 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n",
      "Output encoder shape concat: (64, 11, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#target_i = cp.array([helper.get_one_hot(x[step], vocabulary) for x in target_d])\u001b[39;00m\n\u001b[0;32m     41\u001b[0m target_i\u001b[38;5;241m=\u001b[39mcp\u001b[38;5;241m.\u001b[39marray([vocabulary[x[step]][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m target_d])\n\u001b[1;32m---> 42\u001b[0m Dout \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerDecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEcout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m Zout \u001b[38;5;241m=\u001b[39m output_linear_layer\u001b[38;5;241m.\u001b[39mforward(Dout)\n\u001b[0;32m     44\u001b[0m SigmaZout \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39msoftmax(Zout)\n",
      "Cell \u001b[1;32mIn[72], line 107\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, inputs_decoder, Ecout, step)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,inputs_decoder,Ecout,step):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs_decoder\u001b[38;5;241m=\u001b[39minputs_decoder \n\u001b[1;32m--> 107\u001b[0m     A_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attention_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_masked_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43minputs_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43minputs_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m#Xd=self.inputs_decoder+A_mask\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     Dt1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_layer_1\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs_decoder,A_mask)\n",
      "Cell \u001b[1;32mIn[71], line 542\u001b[0m, in \u001b[0;36mmultihead_attention.forward_masked_attention\u001b[1;34m(self, input_q, input_k, input_v, mask_size)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_masked_attention\u001b[39m(\u001b[38;5;28mself\u001b[39m,input_q,input_k,input_v,mask_size):\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQKV\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_weights_masked(mask_size)\n\u001b[0;32m    544\u001b[0m     Attention \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAttention_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV)\n",
      "Cell \u001b[1;32mIn[71], line 521\u001b[0m, in \u001b[0;36mmultihead_attention.QKV\u001b[1;34m(self, input_q, input_k, input_v)\u001b[0m\n\u001b[0;32m    519\u001b[0m K\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\u001b[38;5;241m.\u001b[39mforward_weights_only(input_k)\n\u001b[0;32m    520\u001b[0m V\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv\u001b[38;5;241m.\u001b[39mforward_weights_only(input_v) \n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[71], line 514\u001b[0m, in \u001b[0;36mmultihead_attention.reshape_heads\u001b[1;34m(self, Q, K, V)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mswapaxes(cp\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39marray_split(K, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# print(\"Kval.shape: \",K_E.shape)\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dials\\Desktop\\LLMs from scratch\\spacy_env\\Lib\\site-packages\\cupy\\_creation\\from_data.py:53\u001b[0m, in \u001b[0;36marray\u001b[1;34m(obj, dtype, copy, order, subok, ndmin, blocking)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray\u001b[39m(obj, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m      8\u001b[0m           blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an array on the current device.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    This function currently does not support the ``subok`` option.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "# inputs_e=cp.random.rand(4,11,300)\n",
    "# inputs_d=cp.random.rand(11,4,11,300)\n",
    "# target_i=cp.array([1, 2,3,4])\n",
    "TransformerEncoder=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size=batch_size,words_per_phrase=max_v)\n",
    "TransformerDecoder=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size=batch_size,words_per_phrase=max_v)\n",
    "words_per_phrase = num_phrases= max_v\n",
    "output_linear_layer=linear_layer(embedding_size,len(vocabulary),out=True)  \n",
    "num_batches_per_epoch = len(X_train) // batch_size\n",
    "num_epochs=550\n",
    "tot_loss_epoch=0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Loss\",tot_loss_epoch/num_batches_per_epoch)\n",
    "    tot_loss_epoch=0\n",
    "    total_accuracy_epoch=0\n",
    "    \n",
    "    for i in tqdm(range(0,num_batches_per_epoch),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        try: \n",
    "            start = i * batch_size\n",
    "            end = start + batch_size \n",
    "            X_batch = X_train[start:end]\n",
    "            y_batch = y_train[start:end] \n",
    "            #print(X_batch)\n",
    "            inputs_e=helper.create_input_encoder(X_batch,vocabulary,words_per_phrase,embedding_size) \n",
    "            inputs_d=helper.create_decoder_input(y_batch,embedding_size,words_per_phrase,vocabulary) \n",
    "            Ecout=TransformerEncoder.forward(inputs_e)\n",
    "            \n",
    "            #print(\"inputs_e.shape\",inputs_e.shape)\n",
    "            #print(\"inputs_d.shape\",inputs_d.shape,\"inputs_e.shape\",inputs_e.shape) \n",
    " \n",
    "            target_d=helper.pad_sequences(y_batch,lenght=words_per_phrase,target_type=\"target\") \n",
    "            target_d=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in target_d] \n",
    "            tot_loss=0\n",
    "            totdLoss_dAcr=0\n",
    "            counter_correct=0\n",
    "            total_accuracy_batch=0\n",
    "            for step in range(0, inputs_d.shape[0]):\n",
    "                inputs_decoder = inputs_d[step]\n",
    "                #target_i = cp.array([helper.get_one_hot(x[step], vocabulary) for x in target_d])\n",
    "                target_i=cp.array([vocabulary[x[step]][1] for x in target_d])\n",
    "                Dout = TransformerDecoder.forward(inputs_decoder, Ecout, step)\n",
    "                Zout = output_linear_layer.forward(Dout)\n",
    "                SigmaZout = helper.softmax(Zout)\n",
    "                \n",
    "                # Calculate loss\n",
    "                #Loss = helper.cross_entropy_loss(SigmaZout, target_i)\n",
    "                #dLoss_dZout = SigmaZout - target_i \n",
    "                Loss = helper.sparse_categorical_crossentropy(SigmaZout, target_i)  \n",
    "                dLoss_dZout = SigmaZout.copy()  # Create a copy of the softmax output \n",
    "                dLoss_dZout[np.arange(target_i.shape[0]), target_i] -= 1 \n",
    "\n",
    "                #helper.log_sparse_entropy(SigmaZout, target_i,y_batch,step)\n",
    "                #print(Loss)\n",
    "                # Backpropagation\n",
    "                \n",
    "                # clip_value = 1.0\n",
    "                # dLoss_dZout = cp.clip(dLoss_dZout, -clip_value, clip_value)\n",
    "                \n",
    "                dLoss_dDout = dLoss_dZout @ output_linear_layer.W.T\n",
    "                \n",
    "                # Backpropagation through decoder\n",
    "                # vocabulary, dLoss_dAcr = TransformerDecoder.backpropagation(dLoss_dDout, vocabulary, y_batch)\n",
    "                # tot_loss+=Loss \n",
    "                # batch_acc=helper.accruacy_sparse_entropy(SigmaZout,target_i)\n",
    "                # total_accuracy_batch+=batch_acc\n",
    "                # if batch_acc>0:\n",
    "                #     helper.print_target_vs_prediction_sparce_loss(SigmaZout,target_i)\n",
    "            #print(\"total_accuracy_batch\",total_accuracy_batch)\n",
    "            \n",
    "            # dLoss_dAcr = cp.clip(dLoss_dAcr, -clip_value, clip_value)\n",
    "            # dLoss_Ecout=cp.clip(dLoss_dAcr, -clip_value, clip_value)\n",
    "            # After decoder, calculate gradients for encoder\n",
    "            # dLoss_Ecout_k = TransformerDecoder.multihead_cross_attention.diffKInput(dLoss_dAcr, TransformerDecoder.Kc.W)\n",
    "            # dLoss_Ecout_v = TransformerDecoder.multihead_cross_attention.diffVInput(dLoss_dAcr, TransformerDecoder.Vc.W)\n",
    "            # dLoss_Ecout = dLoss_Ecout_k + dLoss_Ecout_v\n",
    "            \n",
    "            #     # Backpropagation through encoder\n",
    "            # vocabulary = TransformerEncoder.backpropagation(dLoss_Ecout, vocabulary, X_batch)\n",
    "            \n",
    "            # tot_loss_epoch+=tot_loss/inputs_d.shape[0] \n",
    "            # total_accuracy_epoch+=total_accuracy_batch\n",
    " \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            traceback.print_exc()  \n",
    "    print(\"total_accuracy_epoch\",total_accuracy_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb80648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
