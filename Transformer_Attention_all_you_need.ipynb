{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b89336dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re\n",
    "import cupy as cp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "\n",
    "def log_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record start time\n",
    "        result = func(*args, **kwargs)  # Execute the wrapped function\n",
    "        end_time = time.time()  # Record end time\n",
    "        elapsed_time = end_time - start_time\n",
    "        # print(f\"Function '{func.__name__}' executed in {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Helper: \n",
    "    \n",
    "    def get_positional_encoding(self,seq_len, d_model):\n",
    "        \"\"\"\n",
    "        Returns a non-learnable (sinusoidal) positional encoding.\n",
    "\n",
    "\n",
    "        seq_len: Length of the input sequence.\n",
    "        d_model: Dimension of the embeddings.\n",
    "        \"\"\"\n",
    "        pos = cp.arange(seq_len)[:, cp.newaxis]  # Shape: [seq_len, 1]\n",
    "        i = cp.arange(d_model)[cp.newaxis, :]  # Shape: [1, d_model]\n",
    "\n",
    "        angle_rates = 1 / cp.power(10000, (2 * (i // 2)) / cp.float32(d_model))\n",
    "\n",
    "        # Apply sine to even indices, cosine to odd indices\n",
    "        pos_encoding = cp.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = cp.sin(pos * angle_rates[:, 0::2])  # sine on even indices\n",
    "        pos_encoding[:, 1::2] = cp.cos(pos * angle_rates[:, 1::2])  # cosine on odd indices\n",
    "\n",
    "        return pos_encoding\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        # Subtract the max value for numerical stability\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp(x - max_logits)\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "\n",
    " \n",
    "    # @log_time\n",
    "    def pad_sequence(self,seq, max_len, pad_value=0):\n",
    "        \"\"\"Pad a sequence with a given value up to max_len.\"\"\"\n",
    "        current_len = seq.shape[0]\n",
    "        pad_width = max_len - current_len\n",
    "        if pad_width > 0:\n",
    "            # Pad sequence with zeros (or any pad_value you provide)\n",
    "            seq = cp.pad(seq, ((0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n",
    "        return seq\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def create_timestaped_input(self,input_d, words_per_phrase):\n",
    "        input_translation = []\n",
    "        for j in range(input_d.shape[0]):\n",
    "            # Create padded sequences\n",
    "            padded_sequences = [self.pad_sequence(input_d[j][0:i], words_per_phrase) for i in range(1, input_d.shape[1] + 1)]\n",
    "            input_translation.append(padded_sequences)\n",
    "        return cp.array(input_translation)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    def redimension(self,X):\n",
    "        return cp.concatenate(cp.swapaxes(X, 0, 1), axis=-1)\n",
    "    \n",
    "    @log_time\n",
    "    def create_vocabulary(self,complete_text, name, nlp):\n",
    "        vocabulary_file = f\"data/{name}.pkl\"\n",
    "        try:\n",
    "            with open(vocabulary_file, 'rb') as handle:\n",
    "                vocabulary = pickle.load(handle)\n",
    "                print(\"Vocabulary loaded from file.\")\n",
    "                return vocabulary\n",
    "        except FileNotFoundError:\n",
    "            print(\"Vocabulary file not found, creating a new one.\")\n",
    "        # Use re.findall to split considering punctuation\n",
    "        text = re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', complete_text)\n",
    "\n",
    "        words_list = list(set(text))\n",
    "\n",
    "        vocabulary = dict()\n",
    "\n",
    "        for i, j in enumerate(words_list):\n",
    "            # vocabulary[j]=(jax.random.uniform(jax.random.key(cp.random.randint(10000)),embedding_size),i)\n",
    "            vocabulary[j] = (cp.array(nlp(j).vector), i)\n",
    "             # print(j,len(cp.array(nlp(j).vector)))\n",
    "\n",
    "        # print(vocabulary)\n",
    "        # print(\"Vocabulary size: \", len(vocabulary))\n",
    "        with open(vocabulary_file, 'wb') as handle:\n",
    "            pickle.dump(vocabulary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "    @log_time\n",
    "    def pad_sequences(self,sentences, lenght, pad_token='[PAD]', target_type=None):\n",
    "        \"\"\"\n",
    "        Pads the input sentences to have the same length by adding [PAD] tokens at the end.\n",
    "        \"\"\"\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        if target_type == \"encoder\":\n",
    "            # Split each sentence into words\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        elif target_type == \"decoder\":\n",
    "            tokenized_sentences = [[\"[START]\"] + re.findall(regex_str, sentence) for sentence in sentences]\n",
    "        elif target_type == \"target\":\n",
    "            tokenized_sentences = [re.findall(regex_str, sentence) + [\"[END]\"] for sentence in sentences]\n",
    "        # print(tokenized_sentences)\n",
    "        if lenght == 0:\n",
    "            # Find the maximum sentence length\n",
    "            max_len = max(len(sentence) for sentence in tokenized_sentences)\n",
    "        else:\n",
    "            max_len = lenght\n",
    "\n",
    "        # Pad each sentence with the [PAD] token to make them of equal length\n",
    "        padded_sentences = [\" \".join(sentence + [pad_token] * (max_len - len(sentence))) for sentence in\n",
    "                            tokenized_sentences]\n",
    "\n",
    "        return padded_sentences\n",
    "\n",
    "    def print_matrix(self,text=\"\",X=None):\n",
    "        for i in X:\n",
    "            print(text,i)\n",
    "    \n",
    "    def create_padding_mask(self,seq):\n",
    "    # Create a mask with 0 for padded tokens and 1 for real tokens\n",
    "        return (seq != 0).astype(cp.float32)[..., None]\n",
    "\n",
    "    @log_time\n",
    "    def generate_input_encoder(self,x_batch, vocabulary_encoder, max_words_per_phrase):\n",
    "\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")# here are string\n",
    "        \n",
    "        #print_matrix(x_train) \n",
    "        \n",
    "        xi = []\n",
    "        # print(x_batch)\n",
    "        phrase_vectors_x_i = [re.findall(regex_str, x) for x in x_train]\n",
    "        \n",
    "        phrase_vectors_x = [i[0:max_words_per_phrase] for i in phrase_vectors_x_i]\n",
    "\n",
    "\n",
    "        indices = cp.array([[vocabulary_encoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "        mask = (indices != vocabulary_encoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        #print(phrase_vectors_x) \n",
    "       \n",
    "        # print(\"input_encoder:\")\n",
    "        # self.print_matrix(phrase_vectors_x)\n",
    "        xi = cp.array([[vocabulary_encoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_x])\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "        return xi,phrase_vectors_x_i,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_input_encoder(self,X, vocabulary_encoder, max_words_per_phrase, embedding_size):\n",
    "\n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        #print(pos_encoding)\n",
    "        inputs_e,input_e_words,mask = self.generate_input_encoder(X, vocabulary_encoder, max_words_per_phrase)\n",
    "        \n",
    "        #print(inputs_e)\n",
    "\n",
    "        inputs_e =inputs_e + pos_encoding\n",
    "        return inputs_e,input_e_words,mask\n",
    "    \n",
    "    def generate_target(self,x_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "        target_vector = cp.array([[self.get_one_hot(i,vocabulary) for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    def generate_target_sparse_categorical(self,y_batch, vocabulary, max_words_per_phrase):\n",
    "\n",
    "        regex_str=r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n'\n",
    "\n",
    "        y_target = self.pad_sequences(y_batch, max_words_per_phrase, target_type=\"target\")# here are one string with the padd\n",
    "        \n",
    "        \n",
    "        target_vector = [re.findall(regex_str, x) for x in y_target]\n",
    "\n",
    "        #print(target_vector)\n",
    "        #print_matrix(phrase_vectors_x) \n",
    "        #target_vector = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "        target_vector_i = [i[0:max_words_per_phrase] for i in target_vector]\n",
    "\n",
    "        indices = cp.array([[vocabulary[word][1] for word in phrase_vector] for phrase_vector in target_vector_i])\n",
    "        mask = (indices != vocabulary[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "\n",
    "\n",
    "        target_vector = cp.array([[vocabulary[i][1] for i in phrase] for phrase in target_vector_i])\n",
    "    \n",
    "        return target_vector,target_vector_i,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    \n",
    "    @log_time\n",
    "    def create_target_sparse(self,X, vocabulary_encoder, max_words_per_phrase): \n",
    "        target,target_words,mask = self.generate_target_sparse_categorical(X, vocabulary_encoder, max_words_per_phrase) \n",
    "        return target,target_words,mask\n",
    "    @log_time\n",
    "    def create_decoder_input(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        indices = cp.array([[vocabulary_decoder[word][1] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        mask = (indices != vocabulary_decoder[\"[PAD]\"][1]).astype(cp.float32)[..., None]\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "   \n",
    "        yi = yi + pos_encoding\n",
    "      \n",
    "        return yi,phrase_vectors_y,mask\n",
    "    @log_time\n",
    "    def create_decoder_input_teacher_forcing(self,y_train, embedding_size, max_words_per_phrase, vocabulary_decoder):\n",
    "\n",
    "        decoder_input = self.pad_sequences(y_train, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        #print_matrix(decoder_input)\n",
    "        decoder_input = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', i) for i in decoder_input]\n",
    "        \n",
    "        if max_words_per_phrase == None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[0:max_words_per_phrase] for i in decoder_input]\n",
    "        # for sentence in phrase_vectors_y:\n",
    "        #     print(sentence)\n",
    "        #print_matrix(phrase_vectors_y)\n",
    "        \n",
    "       \n",
    "\n",
    "        # print(\"decoder_input:\")\n",
    "        # self.print_matrix(decoder_input)\n",
    "        yi = cp.array([[vocabulary_decoder[word][0] for word in phrase_vector] for phrase_vector in phrase_vectors_y])\n",
    "        \n",
    "        pos_encoding = self.get_positional_encoding(max_words_per_phrase, embedding_size)\n",
    "        # print(pos_encoding.shape,yi.shape)\n",
    "        yi = yi + pos_encoding\n",
    "        #print_matrix(yi)\n",
    "        # decoder_inputs = cp.array(cp.swapaxes(self.create_timestaped_input(yi, max_words_per_phrase), 0, 1))\n",
    "        \n",
    "        # # decoder_inputs[zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "        # for i in range(decoder_inputs.shape[0]):\n",
    "        #     for j in range(decoder_inputs[i].shape[0]):\n",
    "        #         zero_rows = cp.all(decoder_inputs[i][j] == 0, axis=1)\n",
    "\n",
    "        #         decoder_inputs[i][j][zero_rows] = vocabulary_decoder[\"[PAD]\"][0]\n",
    "\n",
    "        # decoder_inputs = cp.array(decoder_inputs)\n",
    "        #print(decoder_inputs[2])\n",
    "        #print(decoder_inputs)\n",
    "        return yi,phrase_vectors_y\n",
    "    # @log_time\n",
    "    def update_wembedding_encoder(self,learning_rate, x_batch, dLoss_dWemb_encoder, vocabulary, max_words_per_phrase):\n",
    "        \n",
    "        x_train = self.pad_sequences(x_batch, max_words_per_phrase, target_type=\"encoder\")\n",
    "\n",
    "        phrase_vectors_x = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in x_train]\n",
    "        phrase_vectors_x = [i[:max_words_per_phrase] for i in phrase_vectors_x]\n",
    "\n",
    "        for phrase in range(dLoss_dWemb_encoder.shape[0]):\n",
    "            for position, word in enumerate(phrase_vectors_x[phrase]):\n",
    "                # Retrieve current embedding\n",
    "                current_embedding, index = vocabulary[word]\n",
    "\n",
    "                # Calculate the updated embedding using the gradient\n",
    "                updated_embedding = current_embedding - learning_rate * dLoss_dWemb_encoder[phrase][position]\n",
    "\n",
    "                # Update the vocabulary with the new embedding\n",
    "                vocabulary[word] = (updated_embedding, index)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "\n",
    "\n",
    "    # @log_time\n",
    "    def update_wembedding_decoder(self, learning_rate,y_batch, dLoss_dWemb_decoder, vocabulary,max_words_per_phrase):\n",
    "        decoder_input = self.pad_sequences(y_batch, lenght=max_words_per_phrase, target_type=\"decoder\")\n",
    "        decoder_input = [i.split() for i in decoder_input]\n",
    "\n",
    "        if max_words_per_phrase is None:\n",
    "            max_words_per_phrase = len(decoder_input[0])\n",
    "\n",
    "        phrase_vectors_y = [i[:max_words_per_phrase] for i in decoder_input]\n",
    "\n",
    "        for phrase in range(dLoss_dWemb_decoder.shape[0]):\n",
    "            for position, word in enumerate(phrase_vectors_y[phrase]):\n",
    "                # Retrieve current embedding for the word\n",
    "                current_embedding, index = vocabulary[word]\n",
    "\n",
    "                # Apply the gradient update\n",
    "                updated_embedding = current_embedding - learning_rate * dLoss_dWemb_decoder[phrase][position]\n",
    "\n",
    "                # Update the vocabulary with the new embedding\n",
    "                vocabulary[word] = (updated_embedding, index)\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "  \n",
    "    # @log_time\n",
    "    def get_one_hot(self,word, vocabulary_decoder):\n",
    "        # print(word)\n",
    "        vocab_size = len(vocabulary_decoder)\n",
    "        one_hot_vector = cp.zeros(vocab_size)\n",
    "        one_hot_vector[vocabulary_decoder[word][1]] = 1\n",
    "        # print(vocabulary_decoder[word][1])\n",
    "        # print(np.where(one_hot_vector== 1))\n",
    "        # print(cp.sum(one_hot_vector))\n",
    "        return one_hot_vector\n",
    " \n",
    "    \n",
    "    def log_sparse_entropy(self,ans,target,y_batch,step):\n",
    "        #print(\"target\",target)\n",
    "        #print(\"ans\",ans)\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans)\n",
    "        print(f\"----DECODER--step {step}---\")\n",
    "        self.print_matrix(y_batch)\n",
    "        print(\"target\",target)\n",
    "        indexes=[]\n",
    "        yy=[re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', xx) for xx in y_batch] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values)\n",
    "            indexes.append(max_index)\n",
    "             \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "            print(f\"{idx + 1} base: {' '.join(yy[idx][0:step+1])} -> {max_index}\")\n",
    "        print(\"indexes\",indexes)\n",
    "        print(\"accuracy batch:\",round(counter_found/total_lenght,2))\n",
    "        \n",
    "    def accruacy_sparse_entropy(self,ans,target):\n",
    "        counter_found=0\n",
    "        total_lenght=len(ans) \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = cp.argmax(values) \n",
    "            if max_index==target[idx]:\n",
    "                counter_found+=1\n",
    "             \n",
    "        accuracy_batch_on_step=round(counter_found/total_lenght,2)\n",
    "        return accuracy_batch_on_step\n",
    "    \n",
    "\n",
    "    def print_target_vs_prediction_sparce_loss(self,ans,target): \n",
    "        indexes=[] \n",
    "        for idx, values in enumerate(ans):\n",
    "            max_index = np.argmax(values).item()\n",
    "            indexes.append(max_index) \n",
    "        print(\"target\",target)\n",
    "        print(\"indexes\",indexes)\n",
    "        \n",
    "  \n",
    "def clip_gradient(gradient,threshold):\n",
    "    return cp.clip(gradient, -threshold, threshold)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class layer_dropout: \n",
    "\n",
    "    def __init__(self,dropout_rate=0.1):\n",
    "        self.dropout_rate=dropout_rate \n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self,X):   \n",
    "        self.mask = (cp.random.rand(*X.shape) > self.dropout_rate)#.astype(cp.float64)\n",
    "        result = X * self.mask \n",
    "        #print(self.mask )\n",
    "        return result\n",
    "    #\n",
    "    def grad(self, X):\n",
    "        # Only pass gradients through neurons that were not dropped out\n",
    "        grad_input = X * self.mask\n",
    "        grad_input = clip_gradient(grad_input, 1)\n",
    "        return grad_input\n",
    "\n",
    "class layer_normalization:\n",
    "    def __init__(self, threshold, epsilon=0.0001):\n",
    "        self.epsilon = epsilon\n",
    "        self.mu = 0\n",
    "        self.var = 0\n",
    "        self.N = None\n",
    "        self.beta = None\n",
    "        self.alpha = None\n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilonopt = 1e-8\n",
    "        self.t = 0 \n",
    "        \n",
    " \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.N = x.shape[-1]\n",
    "        \n",
    "        # Initialize parameters if not done\n",
    "        if self.alpha is None:\n",
    "            self.alpha = cp.ones(self.N)\n",
    "            self.beta = cp.zeros(self.N)\n",
    "            self.m_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.v_Wbeta = cp.zeros_like(self.beta)\n",
    "            self.m_Walpha = cp.zeros_like(self.alpha)\n",
    "            self.v_Walpha = cp.zeros_like(self.alpha)\n",
    "\n",
    "        # Forward computation\n",
    "        self.mu = cp.mean(x, axis=-1, keepdims=True)\n",
    "        self.var = cp.var(x, axis=-1, keepdims=True)\n",
    "        self.std = cp.sqrt(self.var + self.epsilon)\n",
    "        self.x_norm = (x - self.mu) / self.std\n",
    "        \n",
    "        return self.alpha * self.x_norm + self.beta\n",
    "\n",
    "    def dL_dNorm(self):\n",
    "        self.dL_dnorm_ = self.dLoss_dy * self.alpha\n",
    "        return self.dL_dnorm_\n",
    "\n",
    "    def dL_dsigma(self):\n",
    "        self.dL_dsigma_ = (-0.5)*cp.sum(self.dx_norm*(self.x-self.mu)*((self.var+self.epsilon)**(-1.5)),axis=-1,keepdims=True)\n",
    "        return self.dL_dsigma_\n",
    "    \n",
    "    def dSigma_dmu(self):\n",
    "        return (-2/self.N)*(self.x-self.mu)\n",
    "    \n",
    "    def dL_dmu(self):\n",
    "        a = -1*cp.sum(self.dx_norm*(1/cp.sqrt(self.var+self.epsilon)),axis=-1,keepdims=True)\n",
    "        b = -2*self.dL_dsigma_*cp.sum((1/self.N)*(self.x-self.mu),axis=-1,keepdims=True)\n",
    "        self.dL_dmu_=a+b\n",
    "        return self.dL_dmu_\n",
    "         \n",
    "    def dL_dx(self): \n",
    "        self.dL_dx_=self.dx_norm*self.dNorm_dx()+self.dL_dsigma()*self.dSigma_dx()+self.dL_dmu()*(1/self.N)\n",
    "        return self.dL_dx_\n",
    "    \n",
    "    def dNorm_dx(self):\n",
    "        return 1/cp.sqrt(self.var+self.epsilon)\n",
    "\n",
    "    def dSigma_dx(self):\n",
    "        return (2/self.N)*(self.x-self.mu)\n",
    "         \n",
    "    def backpropagation(self, dLoss_dy):\n",
    "        self.dLoss_dy = dLoss_dy\n",
    "        self.dx_norm = dLoss_dy * self.alpha \n",
    "        return self.dL_dx()\n",
    "    \n",
    "   \n",
    "    def dL_dalpha(self):\n",
    "        result = self.dLoss_dy * self.x_norm\n",
    "        result=cp.sum(cp.sum(result,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.alpha.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "\n",
    "    def dL_dbeta(self):\n",
    "        result = cp.sum(cp.sum(self.dLoss_dy,axis=0),axis=0)\n",
    "        #print(self.dLoss_dy.shape,self.beta.shape)\n",
    "        #result = clip_gradient(result, self.clipping_threshold)\n",
    "        return result\n",
    "     \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    def params_update(self, learning_rate):\n",
    "\n",
    "         \n",
    "        self.t += 1\n",
    "        \n",
    "        # Update beta\n",
    "        dbeta = self.dL_dbeta()\n",
    "        self.m_Wbeta = self.beta1 * self.m_Wbeta + (1 - self.beta1) * dbeta\n",
    "        self.v_Wbeta = self.beta2 * self.v_Wbeta + (1 - self.beta2) * cp.square(dbeta)\n",
    "        \n",
    "        m_W_hat = self.m_Wbeta / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wbeta / (1 - self.beta2 ** self.t)\n",
    "        self.beta -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "        \n",
    "        # Update alpha\n",
    "        dalpha = self.dL_dalpha()\n",
    "        self.m_Walpha = self.beta1 * self.m_Walpha + (1 - self.beta1) * dalpha\n",
    "        self.v_Walpha = self.beta2 * self.v_Walpha + (1 - self.beta2) * cp.square(dalpha)\n",
    "        \n",
    "        m_W_hat = self.m_Walpha / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Walpha / (1 - self.beta2 ** self.t)\n",
    "        self.alpha -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilonopt)\n",
    "\n",
    "       \n",
    "        \n",
    "class linear_layer: \n",
    "    def __init__(self,input_size,output_size,out=False,only_weights=False,threshold=1):\n",
    "\n",
    "        variance = 2 / (input_size + output_size)  # Variance for Glorot normal initializer\n",
    "       \n",
    "        self.W = cp.random.normal(0, cp.sqrt(variance), (input_size, output_size))\n",
    "          \n",
    "        if not only_weights:\n",
    "            self.b = cp.random.normal(0, cp.sqrt(variance), (output_size,))\n",
    "        \n",
    "        self.clipping_threshold = threshold\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0  # Time step for Adam updates\n",
    "        \n",
    "        # Initialize first (m) and second (v) moment vectors for weights and biases\n",
    "        self.m_W = cp.zeros_like(self.W)\n",
    "        self.v_W = cp.zeros_like(self.W)\n",
    "        if not only_weights:\n",
    "            self.m_b = cp.zeros_like(self.b)\n",
    "            self.v_b = cp.zeros_like(self.b)\n",
    "      \n",
    "    def forward(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) + self.b \n",
    "        return Xout\n",
    "    \n",
    "    def forward_weights_only(self,x): \n",
    "        self.x=x\n",
    "        Xout = cp.matmul(x, self.W) \n",
    "        return Xout\n",
    "     \n",
    "    def grad(self,dL_dy):\n",
    "        self.dL_dy = dL_dy\n",
    "        # print(\"self.dL_dy\",self.dL_dy)\n",
    "        return self.dL_dy@self.W.T\n",
    "    \n",
    "    def dLoss_dW(self):\n",
    "        return cp.mean(cp.transpose(self.dL_dy,(0,2,1))@self.x,axis=0).T\n",
    "    \n",
    "    def dLoss_db(self):\n",
    "        return cp.mean(cp.mean(self.dL_dy,axis=0))\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "        db = self.dLoss_db()  \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_b = self.beta1 * self.m_b + (1 - self.beta1) * db\n",
    "        self.v_b = self.beta2 * self.v_b + (1 - self.beta2) * cp.square(db)\n",
    "        # Correct bias in first and second moment for biases\n",
    "        m_b_hat = self.m_b / (1 - self.beta1 ** self.t)\n",
    "        v_b_hat = self.v_b / (1 - self.beta2 ** self.t)\n",
    "        # Update biases using Adam\n",
    "         \n",
    "        #print(up.shape,self.b.shape,db.shape)\n",
    "        self.b -= learning_rate * m_b_hat / (cp.sqrt(v_b_hat) + self.epsilon)\n",
    "\n",
    "    def update_weights_only(self,learning_rate):\n",
    "        dW = self.dLoss_dW()\n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights only\n",
    "        self.m_W = self.beta1 * self.m_W + (1 - self.beta1) * dW\n",
    "        self.v_W = self.beta2 * self.v_W + (1 - self.beta2) * cp.square(dW)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_W / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_W / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "class AdamOptimize:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_block:\n",
    "    def __init__(self,embedding_size,hidden_size,clipping_threshold):\n",
    "        self.embedding_size=embedding_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.linear_layer_1=linear_layer(self.embedding_size,self.hidden_size,threshold=clipping_threshold)\n",
    "        self.linear_layer_2=linear_layer(self.hidden_size,self.embedding_size,threshold=clipping_threshold)\n",
    "        self.dropout=layer_dropout()\n",
    "        self.ReLu=ReLu_layer()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_1=self.linear_layer_1.forward(x)\n",
    "        x_1_r=self.ReLu.forward(x_1)\n",
    "        #x_1_rd=self.dropout.forward(x_1_r)\n",
    "        x_2=self.linear_layer_2.forward(x_1_r)\n",
    "        return x_2\n",
    "    \n",
    "    def grad(self,dL_dy):\n",
    "        dL_dx_1_rd=self.linear_layer_2.grad(dL_dy)\n",
    "        #dL_dx_1_r=self.dropout.grad(dL_dx_1_rd)\n",
    "        dL_dx_1=self.ReLu.backward(dL_dx_1_rd)\n",
    "        dL_dx=self.linear_layer_1.grad(dL_dx_1)\n",
    "        return dL_dx\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.linear_layer_1.update_weights(learning_rate)\n",
    "        self.linear_layer_2.update_weights(learning_rate)\n",
    "        \n",
    " \n",
    "class ReLu_layer:\n",
    "    def __init__(self,alpha=0.0001):\n",
    "        self.alpha=alpha \n",
    "    def forward_leaky(self,X):\n",
    "        self.X=X\n",
    "        return cp.where(X > 0, X, self.alpha * X)\n",
    "\n",
    "    def forward(self,X): \n",
    "        self.X=X\n",
    "        return cp.maximum(0,self.X)\n",
    "    \n",
    "    def backward(self, dLoss): \n",
    "        # Gradient of ReLU is 1 for x > 0, else 0\n",
    "        dx = dLoss * (self.X > 0)  # Only propagate gradients for inputs > 0\n",
    "        return dx\n",
    "    \n",
    "    def backward_leaky(self, dLoss): \n",
    "        dx = dLoss * cp.where(self.X > 0, 1, self.alpha)  # Gradient: 1 for x > 0, else alpha\n",
    "        return dx\n",
    "\n",
    "class residual_layer:\n",
    "    def __init__(self,threshold):\n",
    "        self.dropout=layer_dropout()\n",
    "        self.normalization=layer_normalization(threshold=threshold)\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "\n",
    "    def forward(self,x,sublayer_output): \n",
    "        residual=self.dropout.forward(sublayer_output)+x\n",
    "        result=self.normalization.forward(residual)\n",
    "        return result\n",
    "    \n",
    "    def grad(self, dL_dy):\n",
    "        dl_dNorm = self.normalization.backpropagation(dL_dy) \n",
    "        scaling_factor = 1.0 #/ np.sqrt(2.0)\n",
    "        sublayer_grad = self.dropout.grad(dl_dNorm) * scaling_factor\n",
    "        residual_grad = dl_dNorm * scaling_factor\n",
    "        \n",
    "        return sublayer_grad, residual_grad\n",
    "    \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.normalization.params_update(learning_rate)\n",
    "\n",
    "\n",
    "      \n",
    "class multihead_attention: \n",
    "    def __init__(self,embedding_size,num_heads,batch_size,threshold):\n",
    "        self.num_heads=num_heads\n",
    "        self.dk=embedding_size//num_heads\n",
    "        self.batch_size=batch_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.q=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.k=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.v=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold)\n",
    "        self.projection_layer=linear_layer(self.embedding_size,self.embedding_size,only_weights=True,threshold=threshold) \n",
    "        self.helper=Helper()\n",
    "        self.clipping_threshold=threshold\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.t = 0 \n",
    "        self.m_Wq = cp.zeros_like(self.q.W)\n",
    "        self.v_Wq = cp.zeros_like(self.q.W)\n",
    "\n",
    "        self.m_Wk = cp.zeros_like(self.k.W)\n",
    "        self.v_Wk = cp.zeros_like(self.k.W)\n",
    "\n",
    "        self.m_Wv = cp.zeros_like(self.v.W)\n",
    "        self.v_Wv = cp.zeros_like(self.v.W)\n",
    "         \n",
    "    def reshape_heads(self,Q,K,V):\n",
    "        self.Q = cp.swapaxes(cp.array(np.array_split(Q, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Qval.shape: \",Q_E.shape)\n",
    "        self.K = cp.swapaxes(cp.array(np.array_split(K, self.num_heads, axis=2)), 0, 1)\n",
    "        # print(\"Kval.shape: \",K_E.shape)\n",
    "        self.V = cp.swapaxes(cp.array(np.array_split(V, self.num_heads, axis=2)), 0, 1)\n",
    "        #return self.Q,self.K,self.V\n",
    "\n",
    "    def QKV(self,input_q,input_k,input_v): \n",
    "        Q=self.q.forward_weights_only(input_q)\n",
    "        K=self.k.forward_weights_only(input_k)\n",
    "        V=self.v.forward_weights_only(input_v) \n",
    "        self.reshape_heads(Q,K,V)\n",
    "        \n",
    "\n",
    "    def attention_weights(self,mask): \n",
    "         \n",
    "        QKscaled =cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])  \n",
    "        #print(QKscaled)\n",
    "        if mask is not None:\n",
    "            \n",
    "            # Ensure mask has shape [batch_size, 1, 1, seq_len] for broadcasting\n",
    "            mask = mask[:, cp.newaxis, :]  # Shape: (batch_size, 1, 1, seq_len)\n",
    "            #print(\"mask padding in attention_weights\",mask)\n",
    "            #print(\"mask.shape-------->\",mask.shape)\n",
    "            # Add a large negative value to masked positions\n",
    "            QKscaled = QKscaled + (mask - 1) * 1e9\n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "        #print(\"attention weights\")\n",
    "        #print(self.Attention_weights)\n",
    "         \n",
    "\n",
    "    def forward_attention(self,input_q,input_k,input_v,mask_padding): \n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v\n",
    "        #print(\"input_q.shape\",input_q.shape)\n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights(mask_padding)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def forward_masked_attention(self,input_q,input_k,input_v,mask_size,mask_padding):\n",
    "        self.input_q=input_q\n",
    "        self.input_k=input_k\n",
    "        self.input_v=input_v \n",
    "        self.QKV(input_q,input_k,input_v)\n",
    "        self.attention_weights_masked(mask_size,mask_padding)\n",
    "        Attention = cp.matmul(self.Attention_weights, self.V) \n",
    "        Attention = cp.array([cp.concatenate(Attention[i], axis=1) for i in range(self.batch_size)]) \n",
    "        Output=self.projection_layer.forward_weights_only(Attention) \n",
    "        return Output\n",
    "    \n",
    "    def attention_weights_masked(self,mask_size,mask_padding):\n",
    "        #mask_size =  words_per_phrase \n",
    "\n",
    "        QKscaled = cp.matmul(self.Q, cp.transpose(self.K, (0, 1, 3, 2))) / cp.sqrt(self.K.shape[-1])\n",
    "        mask = cp.tril(cp.ones((mask_size, mask_size)))  # (9, 9) lower triangular matrix\n",
    "        mask[mask == 0]=-cp.inf  # Set future tokens to -inf\n",
    "        mask[mask == 1]=0  # Set allowed tokens to 0\n",
    "        self.mask = mask.reshape(1, 1, mask_size, mask_size)\n",
    "        if mask_padding is not None:\n",
    "            \n",
    "            # Ensure mask has shape [batch_size, 1, 1, seq_len] for broadcasting\n",
    "            maskpad = mask_padding[:, cp.newaxis, :]  # Shape: (batch_size, 1, 1, seq_len)\n",
    "            #print(\"mask padding in masked attention\",mask_padding)\n",
    "            #print(\"mask.shape-------->\",maskpad.shape)\n",
    "            # Add a large negative value to masked positions\n",
    "            QKscaled = QKscaled + (maskpad - 1) * 1e9\n",
    "        QKscaled = QKscaled + self.mask\n",
    "       \n",
    "        self.Attention_weights = self.helper.softmax(QKscaled)\n",
    "        \n",
    "    \n",
    "    def diffQi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        dLoss_dX=cp.transpose(dAttention, (0, 2, 1)) @ (self.helper.redimension(dAttention_weights @ (self.K * self.V) / cp.sqrt(self.K.shape[-1]))*self.input_q)\n",
    "        self.dLoss_Qi= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffKi(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        X = cp.swapaxes(cp.array(cp.array_split(self.input_k, self.num_heads, axis=2)), 0, 1) \n",
    "         \n",
    "        dLoss_dX = cp.transpose(dAttention, (0, 2, 1)) @ self.helper.redimension(\n",
    "            (dAttention_weights * (self.Q @ cp.transpose(self.V, (0, 1, 3, 2))) @ X) / cp.sqrt(self.K.shape[-1])) \n",
    "        self.dLoss_Ki= cp.sum(dLoss_dX,axis=0)\n",
    "    \n",
    "    def diffVi(self,dAttention):\n",
    "        self.dLoss_Vi = cp.sum(cp.sum(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ (\n",
    "                self.Attention_weights @ cp.expand_dims(self.input_v, axis=1)), axis=1), axis=0)\n",
    "       \n",
    "\n",
    "\n",
    "    def diffKInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "         \n",
    "        \n",
    "        A = self.helper.redimension(self.V)@self.k.W\n",
    "         \n",
    "        B = self.helper.redimension(dAttention_weights@self.K)\n",
    "         \n",
    "        C=cp.transpose(dAttention,(0,2,1))@B\n",
    "       \n",
    "        dLoss_KI=cp.transpose((C@cp.transpose(A,(0,2,1))),(0,2,1))\n",
    "        #print(\"dLoss_KI.shape\",dLoss_KI.shape)\n",
    "        \n",
    "        return dLoss_KI\n",
    "    \n",
    "    def diffVInput(self,dAttention):\n",
    "        dLoss_V_E = cp.transpose(\n",
    "        cp.mean(cp.transpose(cp.expand_dims(dAttention, axis=1), (0, 1, 3, 2)) @ self.Attention_weights, axis=1), (0, 2, 1))\n",
    "        dLossVI = dLoss_V_E @ self.v.W\n",
    "        #print(\"dLossVI.shape\",dLossVI.shape)\n",
    "        return dLossVI\n",
    "    \n",
    "    def diffQInput(self,dAttention):\n",
    "        dAttention_weights = self.Attention_weights * (1 - self.Attention_weights) \n",
    "        \n",
    "         \n",
    "        A1=self.helper.redimension(dAttention_weights @ (self.K*self.V / cp.sqrt(self.K.shape[-1])))@self.q.W\n",
    "   \n",
    "        dLoss_QI=dAttention*A1\n",
    "        #print(\"dLoss_QI.shape\",dLoss_QI.shape)\n",
    "        return dLoss_QI\n",
    "    \n",
    "    def grad(self,dL_dy): \n",
    "        self.dLoss_dAcr=self.projection_layer.grad(dL_dy)\n",
    "        self.diffQi(self.dLoss_dAcr)\n",
    "        self.diffVi(self.dLoss_dAcr)\n",
    "        self.diffKi(self.dLoss_dAcr)\n",
    "\n",
    "        dLoss_KI=self.diffKInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_QI=self.diffQInput(self.dLoss_dAcr)\n",
    "        \n",
    "        dLoss_VI=self.diffVInput(self.dLoss_dAcr)\n",
    "       \n",
    "        return dLoss_QI,dLoss_KI,dLoss_VI\n",
    "\n",
    "    def update_weights(self,learning_rate):\n",
    "        \n",
    "\n",
    "        # Increment time step\n",
    "        self.t += 1\n",
    "\n",
    "        # Update first moment (m) and second moment (v) for weights\n",
    "        self.m_Wq = self.beta1 * self.m_Wq + (1 - self.beta1) * self.dLoss_Qi\n",
    "        self.v_Wq = self.beta2 * self.v_Wq + (1 - self.beta2) * cp.square(self.dLoss_Qi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wq / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wq / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.q.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "        \n",
    "        \n",
    "        self.m_Wk = self.beta1 * self.m_Wk + (1 - self.beta1) * self.dLoss_Ki\n",
    "        self.v_Wk = self.beta2 * self.v_Wk + (1 - self.beta2) * cp.square(self.dLoss_Ki)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wk / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wk / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.k.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "        self.m_Wv = self.beta1 * self.m_Wv + (1 - self.beta1) * self.dLoss_Vi\n",
    "        self.v_Wv = self.beta2 * self.v_Wv + (1 - self.beta2) * cp.square(self.dLoss_Vi)\n",
    "        # Correct bias in first and second moment for weights\n",
    "        m_W_hat = self.m_Wv / (1 - self.beta1 ** self.t)\n",
    "        v_W_hat = self.v_Wv / (1 - self.beta2 ** self.t)\n",
    "        # Update weights using Adam\n",
    "        self.v.W -= learning_rate * m_W_hat / (cp.sqrt(v_W_hat) + self.epsilon)\n",
    "\n",
    "\n",
    "        self.projection_layer.update_weights_only(learning_rate)\n",
    "        # self.q.W= self.q.W-self.dLoss_Qi*learning_rate\n",
    "        # self.k.W= self.k.W-self.dLoss_Ki*learning_rate\n",
    "        # self.v.W= self.v.W-self.dLoss_Vi*learning_rate\n",
    "        # print(\"self.q.W\",self.q.W)\n",
    "        # print(\"self.k.W\",self.k.W)\n",
    "        # print(\"self.v.W\",self.v.W)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_punctuation(input_str):\n",
    "    return re.sub(r'[^\\w\\s]', '', input_str)\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.batch_size=batch_size\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.num_heads=num_heads\n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size\n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        self.multihead_attention_encoder=multihead_attention(num_heads=2,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.residual_layer_1=residual_layer(clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "         \n",
    "        self.helper=Helper()\n",
    "     \n",
    "\n",
    "    def forward(self,inputs_e,mask_e):\n",
    "        self.inputs_e=inputs_e \n",
    "\n",
    "        PrjAe=self.multihead_attention_encoder.forward_attention(inputs_e,inputs_e,inputs_e,mask_e)\n",
    "        #print(\"PrjAe\",PrjAe.shape)\n",
    "        Ect1=self.residual_layer_1.forward(PrjAe,inputs_e) \n",
    "\n",
    "        FLe2=self.fully_connected_block.forward(Ect1) \n",
    "\n",
    "        Ecout=self.residual_layer_2.forward(FLe2,Ect1)\n",
    "\n",
    "        return Ecout\n",
    "    \n",
    "    def backpropagation(self,dL_Ecout): \n",
    "        \n",
    "        dL_dFLe2,dL_dEct1_residual=self.residual_layer_2.grad(dL_Ecout)\n",
    "        \n",
    "        #print(\"dL_dFLe2\",dL_dFLe2)\n",
    "        #print(\"dL_dEct1_residual\",dL_dFLe2)\n",
    "        \n",
    "\n",
    "        dL_dEct1=self.fully_connected_block.grad(dL_dFLe2)+dL_dEct1_residual\n",
    "        #print(\"dL_dEct1\",dL_dEct1)\n",
    "        \n",
    "        dL_dPrjAe,dL_inputs_e_residual=self.residual_layer_1.grad(dL_dEct1)\n",
    "        #print(\"dL_dPrjAe\",dL_dPrjAe)\n",
    "        #print(\"dL_inputs_e_residual\",dL_inputs_e_residual)\n",
    "        dL_inputs_e_q,dL_inputs_e_k,dL_inputs_e_v=self.multihead_attention_encoder.grad(dL_dPrjAe)\n",
    "        \n",
    "        dL_inputs_e=dL_inputs_e_residual+dL_inputs_e_q+dL_inputs_e_k+dL_inputs_e_v\n",
    "\n",
    "        #dL_inputs_e=clip_gradient(dL_inputs_e,self.clipping_threshold)\n",
    "        #print(\"dL_inputs_e\",dL_inputs_e_residual)\n",
    "        dLoss_dWemb_encoder = dL_inputs_e * self.inputs_e\n",
    "        return dL_inputs_e,dLoss_dWemb_encoder\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate,vocabulary):\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_encoder.update_weights(learning_rate)\n",
    "        \n",
    "        # input_e=self.inputs_e-learning_rate*dLoss_dWemb_encoder\n",
    "        # vocabulary=self.helper.update_wembedding_encoder(X_batch,input_e,vocabulary,self.words_per_phrase)\n",
    "        return vocabulary\n",
    "        \n",
    "\n",
    "  \n",
    "      \n",
    "     \n",
    "class Decoder:\n",
    "    def __init__(self,embedding_size,num_heads,linear_layer_size,learning_rate,batch_size,words_per_phrase,clipping_threshold):\n",
    "        self.words_per_phrase=words_per_phrase\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.batch_size=batch_size\n",
    "        self.num_heads=num_heads \n",
    "        self.linear_layer_size=linear_layer_size\n",
    "        self.embedding_size=embedding_size  \n",
    "        self.multihead_cross_attention=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold)\n",
    "        self.multihead_attention_decoder=multihead_attention(num_heads=num_heads,embedding_size=embedding_size,batch_size=batch_size,threshold=clipping_threshold) \n",
    "        self.learning_rate=learning_rate\n",
    "        self.helper=Helper() \n",
    "        self.residual_layer_1=residual_layer(threshold=clipping_threshold)\n",
    "        self.residual_layer_2=residual_layer(threshold=clipping_threshold) \n",
    "        self.residual_layer_3=residual_layer(threshold=clipping_threshold) \n",
    "        self.fully_connected_block=fully_connected_block(self.embedding_size,linear_layer_size,clipping_threshold=clipping_threshold)\n",
    "        \n",
    "\n",
    "    def forward(self,inputs_decoder,Ecout,mask_d,mask_e):\n",
    "        self.inputs_decoder=inputs_decoder \n",
    "        \n",
    "        PrjA_mask=self.multihead_attention_decoder.forward_masked_attention(inputs_decoder,inputs_decoder,inputs_decoder,mask_size=inputs_decoder.shape[1],mask_padding=mask_d)\n",
    " \n",
    "        Dt1=self.residual_layer_1.forward(self.inputs_decoder,PrjA_mask)\n",
    "        #print(\"cross attention multihead calc attention weights\")\n",
    "        PrjAcr=self.multihead_cross_attention.forward_attention(Dt1,Ecout,Ecout,mask_padding=mask_e)\n",
    "   \n",
    "        Dt2=self.residual_layer_2.forward(PrjAcr,Dt1)\n",
    " \n",
    "        FLd2=self.fully_connected_block.forward(Dt2)\n",
    "      \n",
    "        Dout=self.residual_layer_3.forward(FLd2,Dt2)  \n",
    "\n",
    "        return Dout\n",
    "    \n",
    "    # def output(self,Dout):\n",
    "    #     SigmaZout=self.helper.softmax(self.final_projection_layer.forward(Dout))\n",
    "    #     return SigmaZout\n",
    "\n",
    "\n",
    "    def backpropagation(self,dL_dDout): \n",
    "\n",
    "        dL_FLd2,dL_Dt2_residual=self.residual_layer_3.grad(dL_dDout)\n",
    "\n",
    "        dL_Dt2=self.fully_connected_block.grad(dL_FLd2)+dL_Dt2_residual\n",
    "\n",
    "        dL_PrjAcr,dL_Dt1_residual=self.residual_layer_2.grad(dL_Dt2)\n",
    "\n",
    "        dL_Dt1_q,dL_DEcout_k,dL_DEcout_v=self.multihead_cross_attention.grad(dL_PrjAcr)\n",
    "\n",
    "        dL_Dt1=dL_Dt1_residual+dL_Dt1_q\n",
    "\n",
    "        dL_PrjA_mask,dL_inputs_decoder_residual=self.residual_layer_1.grad(dL_Dt1)\n",
    "\n",
    "        dL_inputs_decoder_q,dL_inputs_decoder_k,dL_inputs_decoder_v=self.multihead_attention_decoder.grad(dL_PrjA_mask)\n",
    "\n",
    "        dL_inputs_decoder=dL_inputs_decoder_residual+dL_inputs_decoder_q+dL_inputs_decoder_k+dL_inputs_decoder_v\n",
    "        \n",
    "        dL_Ecout=dL_DEcout_k+dL_DEcout_v\n",
    "        #dL_inputs_decoder=clip_gradient(dL_inputs_decoder,self.clipping_threshold)\n",
    "        dLoss_dWemb_decoder= dL_inputs_decoder * self.inputs_decoder\n",
    "        \n",
    "        return dL_Ecout,dL_inputs_decoder,dLoss_dWemb_decoder\n",
    "\n",
    "\n",
    "    def update_weights(self,learning_rate,vocabulary):\n",
    "        self.residual_layer_3.update_weights(learning_rate)\n",
    "        self.fully_connected_block.update_weights(learning_rate)\n",
    "        self.residual_layer_2.update_weights(learning_rate)\n",
    "        self.multihead_cross_attention.update_weights(learning_rate)\n",
    "        self.residual_layer_1.update_weights(learning_rate)\n",
    "        self.multihead_attention_decoder.update_weights(learning_rate)\n",
    "        #dLoss_dWemb_decoder=clip_gradient(dLoss_dWemb_decoder,self.clipping_threshold)\n",
    "        # input_d=self.inputs_decoder-learning_rate*dLoss_dWemb_decoder\n",
    "        # vocabulary=self.helper.update_wembedding_decoder(y_batch,input_d,self.words_per_phrase,vocabulary) \n",
    "        return vocabulary\n",
    "\n",
    "class output_stack:\n",
    "    def __init__(self,embedding_size,vocabulary_size,threshold,temperature=1):\n",
    "        self.final_projection_layer=linear_layer(embedding_size,vocabulary_size,threshold=threshold,out=True)\n",
    "        self.clipping_threshold=threshold\n",
    "        self.temperature=temperature\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        max_logits = cp.max(x, axis=-1, keepdims=True)\n",
    "        exp_logits = cp.exp((x - max_logits) / self.temperature)  # Apply temperature\n",
    "        return exp_logits / cp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        SoftmaxOutput=self.softmax(self.final_projection_layer.forward(x)) \n",
    "        return SoftmaxOutput\n",
    "\n",
    "    \n",
    "    # def cross_entropy_loss(self,SigmaZout, target):\n",
    "    #     epsilon = 1e-12  # Small constant to avoid log(0)\n",
    "    #     SigmaZout = cp.clip(SigmaZout, epsilon, 1 - epsilon)  # Clipping predictions\n",
    "    #     return -cp.sum(target * cp.log(SigmaZout), axis=1).mean() \n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        epsilon = 1e-12\n",
    "        return -np.mean(np.sum(y_true * np.log(y_pred + epsilon), axis=-1))\n",
    "    \n",
    "    def grad_cross_entropy(self,softmax_output,target):\n",
    "        dL_dZ =softmax_output-target\n",
    "        dL_dDout=self.final_projection_layer.grad(dL_dZ)  \n",
    "        #dL_dDout=clip_gradient(dL_dDout,self.clipping_threshold)\n",
    "        return dL_dDout\n",
    "    \n",
    "    def sparse_categorical_crossentropy(self, probabilities, labels,padding_mask): \n",
    "        #print(\"probabilities.shape\", probabilities.shape)\n",
    "        #print(\"labels.shape\", labels.shape)\n",
    "        \n",
    "        # Unpack batch and sequence dimensions\n",
    "        batch_size, seq_length = labels.shape\n",
    "        \n",
    "        # Gather correct class probabilities for each position in the batch and sequence\n",
    "        correct_class_probs = probabilities[np.arange(batch_size)[:, None], np.arange(seq_length), labels] \n",
    "        \n",
    "        # Calculate the log loss and average it\n",
    "        loss = -np.log(correct_class_probs + 1e-8)\n",
    "\n",
    "        masked_loss = loss * padding_mask\n",
    "        print(\"loss shape\",loss.shape,\"mask shape\",padding_mask.shape)\n",
    "\n",
    "        return np.sum(masked_loss) / np.sum(padding_mask)#np.mean(loss)\n",
    "    \n",
    "    def grad(self,dl_dy):\n",
    "        return self.final_projection_layer.grad(dl_dy)\n",
    "\n",
    "\n",
    "    def grad_sparse_cross_entropy(self, softmax_output, target,mask):\n",
    "        dL_dZ = softmax_output.copy()  # Create a copy of the softmax output\n",
    "        \n",
    "        # Adjust indexing to handle both batch and sequence dimensions\n",
    "        batch_size, seq_length = target.shape\n",
    "        dL_dZ[np.arange(batch_size)[:, None], np.arange(seq_length), target] -= 1\n",
    "        expanded_mask = mask.reshape(batch_size, seq_length, 1)\n",
    "        dL_dZ *= expanded_mask\n",
    "        #print(\"expanded_mask\",expanded_mask.shape)\n",
    "        # Compute gradient through final projection layer\n",
    "        dL_dDout = self.final_projection_layer.grad(dL_dZ)  \n",
    "        # dL_dDout = clip_gradient(dL_dDout, self.clipping_threshold)\n",
    "        return dL_dDout\n",
    " \n",
    "    def update_weights(self,learning_rate):\n",
    "        self.final_projection_layer.update_weights(learning_rate)  \n",
    "\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "    def __init__(self,num_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,words_per_phrase_decoder,clipping_threshold,vocabulary):\n",
    "        self.vocabulary=vocabulary\n",
    "        self.clipping_threshold=clipping_threshold\n",
    "        self.EncoderStack = [Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_encoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.DecoderStack = [Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,words_per_phrase_decoder,clipping_threshold) for _ in range(num_layers)]\n",
    "        self.outout_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "\n",
    "    def forward(self,inputs_e,inputs_decoder,X_batch,y_batch,mask_e,mask_d):\n",
    "\n",
    "        self.X_batch=X_batch\n",
    "        self.y_batch=y_batch\n",
    "        #print(\"encoder stack\")\n",
    "        Ecout=self.forward_encoder(inputs_e,mask_e)\n",
    "        #print(\"Ecout.shape\",Ecout.shape)\n",
    "        #(\"decoder stack\")\n",
    "        Dout=self.forward_decoder(Ecout,inputs_decoder,mask_d,mask_e)\n",
    "        #SigmaZout=self.outout_stack.forward(Dout) \n",
    "        return Dout\n",
    "    \n",
    "    def backpropagation(self,dL_dDout):\n",
    "        dL_Ecout,dLoss_dWemb_decoder_tot=self.backpropagation_decoder(dL_dDout)\n",
    "        dL_Ecout,dLoss_dWemb_encoder_tot=self.backpropagation_encoder(dL_Ecout)\n",
    "        return dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot\n",
    "\n",
    "  \n",
    "\n",
    "    def forward_encoder(self,inputs_e,mask_e):\n",
    "        for encoder_i in self.EncoderStack:\n",
    "            inputs_e=encoder_i.forward(inputs_e,mask_e)\n",
    "        return inputs_e\n",
    "    \n",
    "    def forward_decoder(self,Ecout,inputs_decoder,mask_d,mask_e):\n",
    "        for decoder_i in self.DecoderStack:\n",
    "            inputs_decoder=decoder_i.forward(inputs_decoder,Ecout,mask_d,mask_e)\n",
    "        return inputs_decoder\n",
    "    \n",
    "    def backpropagation_decoder(self,dL_dDout):\n",
    "        tot_dL_dEcout=0\n",
    "        dLoss_dWemb_decoder_tot=0\n",
    "        for decoder_i in reversed(self.DecoderStack):\n",
    "            dL_Ecout_i,dL_dDout,dLoss_dWemb_decoder=decoder_i.backpropagation(dL_dDout)\n",
    "            tot_dL_dEcout+=dL_Ecout_i\n",
    "            dLoss_dWemb_decoder_tot+=dLoss_dWemb_decoder\n",
    "            self.vocabulary=decoder_i.update_weights(decoder_i.learning_rate,self.vocabulary)\n",
    "        return tot_dL_dEcout,dLoss_dWemb_decoder_tot\n",
    "    \n",
    "    def backpropagation_encoder(self,dL_Ecout): \n",
    "        dLoss_dWemb_encoder_tot=0\n",
    "        for encoder_i in reversed(self.EncoderStack):\n",
    "            dL_Ecout,dLoss_dWemb_encoder=encoder_i.backpropagation(dL_Ecout) \n",
    "            dLoss_dWemb_encoder_tot+=dLoss_dWemb_encoder \n",
    "            self.vocabulary=encoder_i.update_weights(encoder_i.learning_rate,self.vocabulary)\n",
    "        return dL_Ecout,dLoss_dWemb_encoder_tot\n",
    "   \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dae219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "978e23dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3175 Kim may try the pomodoro technique recommended by Tim to get more stuff done\n",
      "Vocabulary loaded from file.\n",
      "vocabulary size 14766\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "helper=Helper()\n",
    "def load_x_y_train_plain():\n",
    "    with open('corpus/train.json', 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            dataset = json.load(f)  # Load the JSON data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # #Loop through the list and process each dialogue and summary\n",
    "    for data in dataset:\n",
    "        dialogue = data['dialogue']  # Split dialogue into a list of lines\n",
    "        summary = data['summary']\n",
    "\n",
    "        X_train.append(remove_punctuation(dialogue))\n",
    "        y_train.append(remove_punctuation(summary))\n",
    "    return X_train, y_train\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# with open('data/vocabolary_full.pkl', 'rb') as f:\n",
    "#     vocabulary=pickle.load(f)\n",
    "def filter_train_data(X_train, y_train, to_eliminate):\n",
    "    filtered_X_train = []\n",
    "    filtered_y_train = []\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if not any(to_eliminate_str in x for to_eliminate_str in to_eliminate):\n",
    "             \n",
    "            filtered_X_train.append(remove_punctuation(x))\n",
    "            filtered_y_train.append(remove_punctuation(y))\n",
    "\n",
    "    return filtered_X_train, filtered_y_train\n",
    "\n",
    "\n",
    "def create_complete_vocabulary(X_train, y_train,max_v,name):\n",
    "    nlp_model = spacy.load('en_core_web_lg')\n",
    "    nlp_model.disable_pipes([\"parser\", \"ner\"])\n",
    "    complete_text_target = ' '.join(y_train)\n",
    "    complete_text_origin = ' '.join(X_train)\n",
    "    complete_text = complete_text_target + \" [START] [PAD] [END] \" + complete_text_origin\n",
    "\n",
    "    vocabulary = helper.create_vocabulary(complete_text, name, nlp_model)\n",
    "    print(\"vocabulary size\", len(vocabulary))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "X_train, y_train = load_x_y_train_plain()\n",
    "# to_eliminate = [\n",
    "#     \"[I hope I'm not coming off as rude - If I am, I'm sorry. I just thought it would be beneficial for the both of us...]\",\n",
    "#     \"[pulls back the curtain and checks out the window]\",\n",
    "#     \"[hopefully, masses of]\"]\n",
    "# X_train, y_train = filter_train_data(X_train, y_train, to_eliminate)\n",
    "\n",
    "\n",
    "sample = [i for i in range(0,len(y_train))]\n",
    "\n",
    "\n",
    "X_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', x) for x in X_train]\n",
    "y_train = [re.findall(r'\\[.*?\\]|\\w+|[^\\w\\s]|\\n', y) for y in y_train]\n",
    "\n",
    "\n",
    "min_v = 11\n",
    "max_v = 15\n",
    "\n",
    "\n",
    "\n",
    "X_train = [X_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "y_train = [y_train[i] for i in sample if len(y_train[i]) <= max_v and len(y_train[i]) >= min_v]\n",
    "\n",
    "\n",
    "# Calculate lengths of the tokenized phrases\n",
    "\n",
    "\n",
    "def plot_lenghts(X_train,y_train):\n",
    "    X_lengths = [len(x) for x in X_train]\n",
    "    y_lengths = [len(y) for y in y_train]\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for X_train lengths\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(X_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of X_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for y_train lengths\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(y_lengths, bins=20, kde=False)\n",
    "    plt.title('Histogram of y_train Phrase Lengths')\n",
    "    plt.xlabel('Length of Phrases')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#X_train=[i[::-1] for i in y_train]\n",
    "plot_lenghts(X_train,y_train)\n",
    " \n",
    "\n",
    "X_train=[\" \".join(x) for x in X_train]\n",
    "y_train=[\" \".join(y) for y in y_train]\n",
    "\n",
    "print(len(y_train),y_train[0])\n",
    "name=f\"vocabolary_full5i{max_v}{min_v}\"\n",
    "vocabulary=create_complete_vocabulary(X_train, y_train,max_v,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eb9a5cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Tim Hi whats up \\n Kim Bad mood tbh I was going to do lots of stuff but ended up procrastinating \\n Tim What did you plan on doing \\n Kim Oh you know uni stuff and unfucking my room \\n Kim Maybe tomorrow Ill move my ass and do everything \\n Kim We were going to defrost a fridge so instead of shopping Ill eat some defrosted veggies \\n Tim For doing stuff I recommend Pomodoro technique where u use breaks for doing chores \\n Tim It really helps \\n Kim thanks maybe Ill do that \\n Tim I also like using postits in kaban style',\n",
       "  'Noah When and where are we meeting \\n Madison I thought you were busy \\n Noah Yeah I WAS I quit my job \\n Madison No way o o o Why I thought you liked it \\n Noah Well I used to until my boss turned into a complete cock Long story',\n",
       "  'Lucas Hey How was your day \\n Demi Hey there \\n Demi It was pretty fine actually thank you \\n Demi I just got promoted D \\n Lucas Whoa Great news \\n Lucas Congratulations \\n Lucas Such a success has to be celebrated \\n Demi I agree D \\n Demi Tonight at Death Co \\n Lucas Sure \\n Lucas See you there at 10pm \\n Demi Yeah See you there D'],\n",
       " ['Kim may try the pomodoro technique recommended by Tim to get more stuff done',\n",
       "  'Noah wants to meet he quit his job because his boss was a dick',\n",
       "  'Demi got promoted She will celebrate that with Lucas at Death Co at 10 pm'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:3],y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9350b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3175, 14766)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a882c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "embedding_size=300\n",
    "fl1_size=2048\n",
    "batch_size=2\n",
    "num_heads=10\n",
    "dropout_rate=0.1 \n",
    "num_batches_per_epoch = len(X_train) // batch_size\n",
    "num_epochs=550\n",
    "tot_loss_epoch=0\n",
    "learning_rate=0.0001\n",
    "clipping_threshold=1e10\n",
    "tot_loss_epoch=0\n",
    "temperature=1\n",
    " \n",
    "decoder_seq_len=max_v\n",
    "encoder_seq_len=50\n",
    "\n",
    "n_layers=1\n",
    "Output_stack=output_stack(embedding_size,len(vocabulary),threshold=clipping_threshold,temperature=2)\n",
    "encoder=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "decoder=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "\n",
    "encoder_second=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "decoder_second=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "\n",
    "encoder_third=Encoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,clipping_threshold)\n",
    "decoder_third=Decoder(embedding_size,num_heads,fl1_size,learning_rate,batch_size,decoder_seq_len,clipping_threshold)\n",
    "#MyTransformer=Transformer(n_layers,embedding_size,num_heads,fl1_size,learning_rate,batch_size,encoder_seq_len,decoder_seq_len,clipping_threshold,vocabulary)\n",
    "output_linear_layer=linear_layer(embedding_size,len(vocabulary),out=True) \n",
    "accuracies=[0,0]\n",
    "mean_acc=0\n",
    "\n",
    "def print_word_from_vocabulary(word_index,vocabulary): \n",
    "    for word,(vector,position), in vocabulary.items():\n",
    "        if position==word_index:\n",
    "            return word\n",
    "        \n",
    "def training_accuracy_cross_entropy(SigmaZout,target_decoder):\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==np.argmax(target_decoder[n][l]): \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(target_decoder[n][l]),np.argmax(SigmaZout[n][l]))\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "    return np.mean(np.array(taccuracies))\n",
    "\n",
    "def training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder,vocabulary):\n",
    "    #print(SigmaZout.shape)\n",
    "    #print(target_decoder.shape)\n",
    "    taccuracies=[]\n",
    "    for n in range(SigmaZout.shape[0]): \n",
    "            len_phrase=SigmaZout.shape[1]\n",
    "            counter_beccate=0 \n",
    "            for l in range(SigmaZout.shape[1]): \n",
    "                if np.argmax(SigmaZout[n][l])==target_decoder[n][l]: \n",
    "                    counter_beccate+=1\n",
    "                    #print(np.argmax(SigmaZout[n][l]),target_decoder[n][l],print_word_from_vocabulary(np.argmax(SigmaZout[n][l]),vocabulary))\n",
    "            #print(\"-------------------------\")\n",
    "            phrase_accuracy=counter_beccate/len_phrase\n",
    "            taccuracies.append(phrase_accuracy)\n",
    "    return np.mean(np.array(taccuracies))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad1d29d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " ...]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x.split()) for x in y_train ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0fbf5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0 mean accuracy 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_e.shape (2, 50, 300)\n",
      "input_e_words ['[START]', 'Roberta', 'file_photo', '\\n', 'Roberta', 'look', 'what', 'I', 'found', '\\n', 'Makoto', 'my', 'dress', '\\n', 'Roberta', 'you', 'must', 'have', 'left', 'it', 'when', 'you', 'were', 'visiting', 'this', 'summer', '\\n', 'Makoto', 'could', 'you', 'send', 'it', 'to', 'me', '\\n', 'Roberta', 'sure', 'Ill', 'do', 'so', 'on', 'Friday', '[END]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "input_e_words ['[START]', 'Sam', 'Im', 'so', 'sorry', 'I', 'cant', 'make', 'it', 'on', 'time', '\\n', 'Sandra', 'Should', 'we', 'start', 'without', 'you', '\\n', 'Sam', 'Please', 'do', 'Ill', 'be', '30', 'min', 'late', '\\n', 'Sta', 'Ok', '[END]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "mask_e "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550: 100%|| 1/1 [00:00<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]]\n",
      "mask_e [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "inputs_decoder_words ['[START]', 'Roberta', 'found', 'Makotos', 'dress', 'and', 'will', 'send', 'it', 'to', 'Makoto', 'on', 'Friday', '[PAD]', '[PAD]']\n",
      "inputs_decoder_words ['[START]', 'Sam', 'will', 'be', '30', 'minutes', 'late', 'Sandra', 'and', 'Sta', 'will', 'start', 'without', 'Sam', '[PAD]']\n",
      "mask_d [[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]]\n",
      "mask_d [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n",
      "target_decoder_words ['Roberta', 'found', 'Makotos', 'dress', 'and', 'will', 'send', 'it', 'to', 'Makoto', 'on', 'Friday', '[END]', '[PAD]', '[PAD]']\n",
      "target_decoder_words ['Sam', 'will', 'be', '30', 'minutes', 'late', 'Sandra', 'and', 'Sta', 'will', 'start', 'without', 'Sam', '[END]', '[PAD]']\n",
      "mask_t [[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]]\n",
      "mask_t [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n",
      "mask_e.shape (2, 1, 50)\n",
      "mask_d.shape (2, 1, 15)\n",
      "mask_t.shape (2, 1, 15)\n",
      "loss shape (2, 15) mask shape (2, 1, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(\"Loss\",tot_loss_epoch/num_batches_per_epoch,\"mean accuracy\",np.mean(np.array(accuracies)))#np.mean(np.array(accuracies))\n",
    "    tot_loss_epoch=0\n",
    "    total_accuracy_epoch=0\n",
    "    mean_acc=0\n",
    "    accuracies=[]\n",
    "    for i in tqdm(range(7,8),desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        #try: \n",
    "        start = i * batch_size\n",
    "        end = start + batch_size \n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]  \n",
    "        \n",
    "        inputs_e,input_e_words,mask_e=helper.create_input_encoder(X_batch,vocabulary,encoder_seq_len,embedding_size) \n",
    "        inputs_decoder,inputs_decoder_words,mask_d=helper.create_decoder_input(y_batch,embedding_size,decoder_seq_len,vocabulary) \n",
    "        target_decoder,target_decoder_words,mask_t=helper.create_target_sparse(y_batch,vocabulary,decoder_seq_len) \n",
    "        mask_e=cp.transpose(mask_e,(0,2,1))\n",
    "        mask_d=cp.transpose(mask_d,(0,2,1))\n",
    "        mask_t=cp.transpose(mask_t,(0,2,1))\n",
    "        print(\"inputs_e.shape\",inputs_e.shape)\n",
    "        helper.print_matrix(\"input_e_words\",input_e_words)\n",
    "        helper.print_matrix(\"mask_e\",mask_e)\n",
    "        helper.print_matrix(\"inputs_decoder_words\",inputs_decoder_words)\n",
    "        helper.print_matrix(\"mask_d\",mask_d)\n",
    "        helper.print_matrix(\"target_decoder_words\",target_decoder_words)\n",
    "        helper.print_matrix(\"mask_t\",mask_t)\n",
    "        print(\"mask_e.shape\",mask_e.shape)\n",
    "        print(\"mask_d.shape\",mask_d.shape)\n",
    "        print(\"mask_t.shape\",mask_t.shape)\n",
    "        \n",
    "        \n",
    "        Ecout1=encoder.forward(inputs_e,mask_e)\n",
    "        Ecout2=encoder_second.forward(Ecout1,mask_e)\n",
    "        #Ecout3=encoder_third.forward(Ecout2,mask_e)\n",
    "\n",
    "        Dout1=decoder.forward(inputs_decoder,Ecout2,mask_d,mask_e) \n",
    "        Dout2=decoder_second.forward(Dout1,Ecout2,mask_d,mask_e)\n",
    "        #Dout3=decoder_third.forward(Dout2,Ecout2,mask_d,mask_e)\n",
    "        #Dout=MyTransformer.forward(inputs_e,inputs_decoder,X_batch,y_batch,mask_e,mask_d) \n",
    "\n",
    "        SigmaZout=Output_stack.forward(Dout2)\n",
    "        #print(SigmaZout.shape)\n",
    "        batch_accuracy=training_accuracy_sparse_cross_entropy(SigmaZout,target_decoder,vocabulary)\n",
    "        accuracies.append(batch_accuracy) \n",
    "        \n",
    " \n",
    "        Loss = Output_stack.sparse_categorical_crossentropy(SigmaZout,target_decoder,mask_t) \n",
    "        #print(\"Loss\",Loss,\"Batch accuracy\",batch_accuracy)\n",
    "        tot_loss_epoch+=Loss\n",
    " \n",
    "        dL_dDout = Output_stack.grad_sparse_cross_entropy(SigmaZout,target_decoder,mask_t) \n",
    "        \n",
    "        #dL_Ecout,dLoss_dWemb_encoder_tot,dLoss_dWemb_decoder_tot=MyTransformer.backpropagation(dL_dDout)\n",
    "        \n",
    "#         dL_Ecout3,dL_inputs_decoder3,dLoss_dWemb_decoder3=decoder_third.backpropagation(dL_dDout)\n",
    "#         _=decoder_third.update_weights(learning_rate,vocabulary) \n",
    "        \n",
    "        dL_Ecout2,dL_inputs_decoder2,dLoss_dWemb_decoder2=decoder_second.backpropagation(dL_dDout)\n",
    "        _=decoder_second.update_weights(learning_rate,vocabulary) \n",
    "        \n",
    "        dL_Ecout1,dL_inputs_decoder,dLoss_dWemb_decoder1=decoder.backpropagation(dL_inputs_decoder2)\n",
    "        _=decoder.update_weights(learning_rate,vocabulary) \n",
    "        \n",
    "        \n",
    "        dL_Ecout_tot=dL_Ecout1+dL_Ecout2\n",
    "\n",
    "        Output_stack.update_weights(learning_rate)\n",
    "        \n",
    "#         dL_inputs_e3,dLoss_dWemb_encoder3=encoder_third.backpropagation(dL_Ecout_tot)\n",
    "#         _=encoder_third.update_weights(learning_rate,vocabulary)\n",
    "        \n",
    "        dL_inputs_e2,dLoss_dWemb_encoder2=encoder_second.backpropagation(dL_Ecout_tot)\n",
    "        _=encoder_second.update_weights(learning_rate,vocabulary)\n",
    "        \n",
    "        dL_inputs_e1,dLoss_dWemb_encoder1=encoder.backpropagation(dL_inputs_e2)\n",
    "        _=encoder.update_weights(learning_rate,vocabulary)\n",
    "         \n",
    "        \n",
    "        #vocabulary=helper.update_wembedding_decoder(0.00001,y_batch, dLoss_dWemb_decoder_tot,vocabulary, decoder_seq_len)\n",
    "        #vocabulary=helper.update_wembedding_encoder(0.00001,X_batch, dLoss_dWemb_encoder_tot,vocabulary,encoder_seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a523cc",
   "metadata": {},
   "source": [
    "To identify where to place    values in   scaled QK scaled  , consider how the mask interacts with the sequence positions. Shape of   scaled QK scaled  : For a batch size of  N,   scaled QK scaled  typically has the shape (  , num_heads , seq_len , seq_len ) (N,num_heads,seq_len,seq_len), where seq_len seq_len is the length of the input sequence. Each element in   scaled [  ,  ,  ,  ] QK scaled  [i,h,j,k] represents the attention score between the  j-th query position and the  k-th key position for the  h-th attention head in the  i-th batch item. Mask Shape Alignment: The mask typically has shape (  , seq_len ) (N,seq_len) and marks each position with a 1 (for valid tokens) or a 0 (for padding tokens). To align with   scaled QK scaled  , you expand the mask to shape (  , 1 , 1 , seq_len ) (N,1,1,seq_len). After expansion, the mask will effectively broadcast over the query positions (dimension 2 of   scaled QK scaled  ) and attention heads (dimension 1). Applying    Masking: When broadcasting the mask, only key positions that correspond to padding tokens (mask=0) in the last dimension will be assigned   . This is why adding ( mask  1 )  1 0 9 (mask1)10 9 works; any position where the mask is 0 will add  1 0 9 10 9 to   scaled QK scaled  , effectively zeroing out the attention after the softmax. So, for every padding token position (where mask[i, k] = 0), every attention score   scaled [  , : , : ,  ] QK scaled  [i,:,:,k] will be set to a large negative value, ensuring no attention is paid to padding tokens across all queries and heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "426995db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4, dtype=int32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8e29d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swaying\n"
     ]
    }
   ],
   "source": [
    "for i,(j,k) in vocabulary.items():\n",
    "    #print(i,k)\n",
    "    if k==775:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb80648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.29, -4.52, 6.58, -2.67, -1.89, 1.38, 4.31, -3.22, -10.3, -1.86, -0.165, -2.48, 9.21, 0.397, 1.59, 7.13, -6.91, 4.72, -1.58, -0.172, 4.32, 3.8, 1.43, -5.23, -7.19, 1.69, 4.76, 6.03, -3.68, -4.43, -0.472, -1.38, 6.1, 2.23, 0.887, -5.05, -1.16, 0.472, 6.07, 6.63, 1.5, -2.8, -7.84, 8.3, 2.25, -13.7, 4.49, 1.6, 3.39, -6.48, -7.28, -0.184, -2.28, -3.54, -4.86, 4.98, 6.52, -3.3, 7.13, -2.69, -0.978, -2.03, -4.34, -0.0675, -4.21, 3.58, -9.06, 0.371, 0.468, 1.56, 0.745, -5.18, -5.34, -5.32, -0.718, 0.632, 1.63, 3.74, -2.94, 5.61, -0.722, -3.61, -3.2, -1.7, -5.03, -1.62, 1.89, -1.64, 6.58, 2.95, -10.6, 1.52, -6.33, -7.92, -5.77, 4.34, -0.0952, -1.63, -0.553, -0.957, 0.99, -2.37, 3.49, -3.04, 1.74, 4.95, 11.8, 0.265, -4.32, 5.9, 3.63, 0.339, 2.86, -1.67, -1.76, 0.766, -3.32, 4.36, -0.622, -1.46, 4.53, 1.96, 0.922, -0.981, 2.86, 2.27, 2.65, 1.67, 0.0472, -3.75, -6.28, -1.6, 2.4, -0.826, 4.83, -6, -0.0516, 1.95, -1.24, 4.48, -3.47, -0.587, -5.91, 3.51, -4.78, -0.428, -4.84, 0.476, 10.3, 1.23, -2.86, -1.37, -0.346, 3.42, -1.12, 4.54, -2.6, 0.17, -2.31, 5.26, 5.8, 8.39, -6.88, -3.1, -0.798, -1.88, -1.21, 7.81, 1.87, 4.69, 0.746, 7.02, 5.14, -2.88, 4.15, -2.83, 5.87, 1.71, 2.81, -3.75, 3.28, -11.9, -2.58, -5.91, 1.13, 2.79, 2.79, -2.02, -0.957, -1.8, 1.35, 4.26, 6.17, 3.6, 2.16, 3.13, -0.854, 10.2, -2.07, -9.68, 2.2, -0.799, 7.39, 8.04, 1.21, 6.69, -0.302, -4.33, 2.12, -0.99, -7.7, 0.765, 1.27, 0.75, -4.04, 8.9, -3.62, 2.47, 3.74, 4.85, 5.78, -1.26, -7.27, -3.62, 5.2, 9.79, 2.46, -6.25, 5.65, 2.95, -0.848, 2.27, 3.52, -3.82, -0.333, -5.25, 2.65, 3.7, -6.49, 0.463, 1.33, -6.31, 1.85, 0.486, 0.216, -1.13, 7.71, -3.44, 4.6, -8.98, 10.4, -3.87, -1.83, -2.21, -0.618, -1.18, -0.666, -3.63, 0.421, 5.58, 5.23, -0.541, 5.17, 4.31, -2.18, -2.06, -3.73, -0.0329, 5.45, -6.7, -0.49, 4.69, 0.407, 2.87, -1.45, -5.18, -3.36, -7.6, 5.32, -0.654, 2.86, 1.41, -1.81, 3.77, -0.498, 2.77, 4.2, 0.539, 3.52, -0.979, -2.79, 1.96, 0.588, -2.52, -1.21, -6.74, -1.87, -4.61, 0.664, 2.34], dtype=float32),\n",
       " 6628)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b495b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3,50,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7075bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300 #dAttention.shape \n",
    "3, 10, 15, 50 #dAttention_weights\n",
    "3, 10, 50, 30 #self.K\n",
    "3, 10, 50, 30 #self.V\n",
    "300, 300#k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ebeffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)\n",
    "300, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac02a010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 50\n",
    "3, 10, 50, 30\n",
    "3, 50, 300#self.helper.redimension(self.V)@self.k.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e36268ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 10, 15, 30#dAttention_weights@self.K\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c8da8522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 15, 300\n",
    "3, 15, 300#self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5f67c183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50, 300)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3, 300, 300#dAttention*self.helper.redimension(dAttention_weights@self.K)\n",
    "3, 50, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
